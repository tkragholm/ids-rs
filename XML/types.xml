<directory_structure>
src/
  error/
    context.rs
    conversion.rs
    macros.rs
    mod.rs
  family/
    mod.rs
    relations.rs
    store.rs
  models/
    covariate/
      builders.rs
      mod.rs
      types.rs
      values.rs
    family/
      mod.rs
      relations.rs
      store.rs
    mod.rs
    pnr.rs
    time_varying.rs
  storage/
    arrow/
      access.rs
      backend.rs
      convert.rs
      mod.rs
      utils.rs
      values.rs
    backends/
      memory.rs
      mod.rs
      time_varying.rs
    concurrency/
      mod.rs
    mod.rs
  store/
    arrow_backend.rs
    data_store.rs
    mod.rs
    time_varying_backend.rs
  traits/
    access.rs
    cacheable.rs
    mod.rs
    processing.rs
    utils.rs
  translation/
    mod.rs
  utils/
    logging.rs
    mod.rs
  config.rs
  lib.rs
  prelude.rs
Cargo.toml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/error/context.rs">
use super::{IdsError, Result};
use std::error::Error as StdError;
use std::fmt::Display;

/// Trait for adding context to errors
///
/// This trait provides methods for adding context to error results.
pub trait ErrorContext<T, E> {
    /// Add context to an error, explaining what was happening when the error occurred
    ///
    /// This method preserves the original error as the source, allowing for inspection
    /// of the error chain while providing better context about the operation that failed.
    ///
    /// # Example
    /// ```
    /// use types::error::ErrorContext;
    ///
    /// let result = std::fs::read_to_string("missing_file.txt")
    ///     .with_context(|| "Failed to read configuration file");
    /// ```
    ///
    /// # Errors
    /// Returns the original error wrapped with the provided context
    fn with_context<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display + Send + Sync + 'static;

    /// Add context with details to an error, allowing for formatted messages
    ///
    /// This method is particularly useful when you need to include specific details about the
    /// error context, such as file paths, ids, or parameters that would help diagnose the issue.
    ///
    /// # Example
    /// ```
    /// use types::error::ErrorContext;
    ///
    /// let file_path = "data/config.json";
    /// let result = std::fs::read_to_string(file_path)
    ///     .with_context_details(|| format!("Failed to read file at {file_path}"));
    /// ```
    ///
    /// # Errors
    /// Returns the original error replaced with the provided context
    fn with_context_details<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display + Send + Sync + 'static;
}

/// Legacy version of `ErrorContext` that doesn't require thread-safety bounds
///
/// This trait is provided for backwards compatibility with existing code.
pub trait LegacyErrorContext<T, E: Display + 'static> {
    /// Add context to an error
    fn with_context<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display;
}

/// Maps an error type to the appropriate `IdsError` variant based on common patterns
fn map_error_type<E: StdError + Send + Sync + 'static>(error: E, context: &str) -> IdsError {
    // Get the error as a trait object for pattern matching
    let error_ref = &error as &dyn StdError;

    // Check for common error types and map to appropriate variants
    if let Some(io_err) = error_ref.downcast_ref::<std::io::Error>() {
        // Preserve io::Error kind
        IdsError::Io(std::io::Error::new(
            io_err.kind(),
            format!("{context}: {error}"),
        ))
    } else if let Some(_arrow_err) = error_ref.downcast_ref::<arrow::error::ArrowError>() {
        // Arrow errors get special treatment with the ArrowWithContext variant
        IdsError::ArrowWithContext {
            source: Box::new(error),
            context: context.to_string(),
        }
    } else if let Some(_parquet_err) = error_ref.downcast_ref::<parquet::errors::ParquetError>() {
        // Parquet errors are also wrapped in ArrowWithContext
        IdsError::ArrowWithContext {
            source: Box::new(error),
            context: context.to_string(),
        }
    } else if let Some(_csv_err) = error_ref.downcast_ref::<csv::Error>() {
        // CSV errors get converted to CSV variant
        IdsError::Csv(csv::Error::from(std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("{context}: {error}"),
        )))
    } else if let Some(_date_err) = error_ref.downcast_ref::<chrono::format::ParseError>() {
        // Date parsing errors
        IdsError::InvalidDate(format!("{context}: {error}"))
    } else if let Some(_parse_int_err) = error_ref.downcast_ref::<std::num::ParseIntError>() {
        // Integer parsing errors
        IdsError::type_conversion(format!("{context}: {error}"))
    } else if let Some(_parse_float_err) = error_ref.downcast_ref::<std::num::ParseFloatError>() {
        // Float parsing errors
        IdsError::type_conversion(format!("{context}: {error}"))
    } else if let Some(_json_err) = error_ref.downcast_ref::<serde_json::Error>() {
        // JSON parsing errors - create a proper JSON error
        IdsError::invalid_format(format!("{context}: {error}"))
    } else {
        // For any other error type, use DataAccess with rich context
        IdsError::DataAccess {
            source: Box::new(error),
            context: context.to_string(),
        }
    }
}

/// Helper function to add context to Result types
///
/// This function preserves type information for known error types while adding context.
/// It's designed to be more intelligent about error conversion than a simple `map_err`.
#[inline]
pub fn with_context<T, E, C, F>(result: std::result::Result<T, E>, context_fn: F) -> Result<T>
where
    E: StdError + Send + Sync + 'static,
    F: FnOnce() -> C,
    C: Display,
{
    match result {
        Ok(value) => Ok(value),
        Err(e) => {
            // Get context value
            let ctx = context_fn().to_string();

            // Create a descriptive error message that combines all previous context
            let error_description = format!("{e}");

            // Create an appropriate IdsError that preserves context
            // Check if we're already dealing with an IdsError
            let new_error =
                if let Some(ids_err) = (&e as &dyn StdError).downcast_ref::<super::IdsError>() {
                    match ids_err {
                        // For Validation errors, preserve the error type with chained context
                        super::IdsError::Validation(_) => {
                            super::IdsError::Validation(format!("{ctx}: {error_description}"))
                        }
                        // For DataAccess errors, preserve their structure and source
                        super::IdsError::DataAccess {
                            source: _,
                            context: _,
                        } => {
                            // Create a new DataAccess error with updated context
                            let new_context = format!("{ctx}: {error_description}");
                            let boxed_error = Box::new(std::io::Error::new(
                                std::io::ErrorKind::Other,
                                error_description,
                            ));
                            super::IdsError::DataAccess {
                                source: boxed_error,
                                context: new_context,
                            }
                        }
                        // Use standard mapping for other IdsError types
                        _ => map_error_type(e, &ctx),
                    }
                } else {
                    // For non-IdsError types, use the standard mapping
                    map_error_type(e, &ctx)
                };

            Err(new_error)
        }
    }
}

/// Helper function to replace error with context for Result types
///
/// Unlike `with_context`, this function is designed to replace the error message entirely
/// with the provided context, rather than adding to it. This is useful when the original
/// error message isn't helpful or relevant.
#[inline]
pub fn with_context_details<T, E, C, F>(
    result: std::result::Result<T, E>,
    context_fn: F,
) -> Result<T>
where
    E: StdError + Send + Sync + 'static,
    F: FnOnce() -> C,
    C: Display,
{
    match result {
        Ok(value) => Ok(value),
        Err(e) => {
            // Get context value
            let ctx = context_fn().to_string();

            // Check for specific error types
            let error_ref = &e as &dyn StdError;

            if let Some(io_err) = error_ref.downcast_ref::<std::io::Error>() {
                // Preserve io::Error kind but use only our context
                Err(IdsError::Io(std::io::Error::new(io_err.kind(), ctx)))
            } else if let Some(_arrow_err) = error_ref.downcast_ref::<arrow::error::ArrowError>() {
                // For Arrow errors, use the DataAccess variant with context
                Err(IdsError::DataAccess {
                    source: Box::new(e),
                    context: ctx,
                })
            } else if error_ref
                .downcast_ref::<parquet::errors::ParquetError>()
                .is_some()
            {
                // For Parquet errors, create a generic DataAccess error with the source
                Err(IdsError::DataAccess {
                    source: Box::new(e),
                    context: ctx,
                })
            } else {
                // For most cases, use a validation error with just our context
                Err(IdsError::Validation(ctx))
            }
        }
    }
}

// Implement ErrorContext for all Result types using the helper functions
impl<T, E: StdError + Send + Sync + 'static> ErrorContext<T, E> for std::result::Result<T, E> {
    fn with_context<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display + Send + Sync + 'static,
    {
        with_context(self, context_fn)
    }

    fn with_context_details<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display + Send + Sync + 'static,
    {
        with_context_details(self, context_fn)
    }
}

// Add a simplified legacy context implementation
impl<T, E: Display + 'static> LegacyErrorContext<T, E> for std::result::Result<T, E> {
    fn with_context<C, F>(self, context_fn: F) -> Result<T>
    where
        F: FnOnce() -> C,
        C: Display,
    {
        match self {
            Ok(value) => Ok(value),
            Err(err) => {
                let context = context_fn().to_string();
                let message = format!("{context}: {err}");

                // Special case for io::Error to preserve behavior expected by the utils crate
                if let Some(io_err) = (&err as &dyn std::any::Any).downcast_ref::<std::io::Error>()
                {
                    return Err(IdsError::Io(std::io::Error::new(io_err.kind(), message)));
                }

                // For regular Display errors, create a Validation error to match expected behavior
                Err(IdsError::Validation(message))
            }
        }
    }
}
</file>

<file path="src/error/conversion.rs">
use super::IdsError;
use chrono::format::ParseError as ChronoParseError;
use std::convert::From;

// Convert from log::SetLoggerError to IdsError
impl From<log::SetLoggerError> for IdsError {
    fn from(_: log::SetLoggerError) -> Self {
        IdsError::Logger
    }
}

// Convert from Chrono's ParseError to IdsError
impl From<ChronoParseError> for IdsError {
    fn from(err: ChronoParseError) -> Self {
        IdsError::InvalidDate(format!("Failed to parse date: {err}"))
    }
}

// Convert from std::num::ParseIntError to IdsError
impl From<std::num::ParseIntError> for IdsError {
    fn from(err: std::num::ParseIntError) -> Self {
        IdsError::type_conversion(format!("Failed to parse integer: {err}"))
    }
}

// Convert from std::num::ParseFloatError to IdsError
impl From<std::num::ParseFloatError> for IdsError {
    fn from(err: std::num::ParseFloatError) -> Self {
        IdsError::type_conversion(format!("Failed to parse float: {err}"))
    }
}

// Convert from std::fmt::Error to IdsError
impl From<std::fmt::Error> for IdsError {
    fn from(_: std::fmt::Error) -> Self {
        IdsError::InvalidFormat("Formatting error".to_string())
    }
}

// Convert from std::string::FromUtf8Error to IdsError
impl From<std::string::FromUtf8Error> for IdsError {
    fn from(err: std::string::FromUtf8Error) -> Self {
        IdsError::InvalidFormat(format!("Invalid UTF-8 sequence: {err}"))
    }
}

// Convert from serde_yaml::Error to IdsError (if used in the project)
// We don't need to implement From<ArrowError> or From<ParquetError> for IdsError
// since they're already implemented with #[from] in the IdsError enum.

// Convert from std::sync::mpsc::RecvError to IdsError for parallel processing errors
impl From<std::sync::mpsc::RecvError> for IdsError {
    fn from(err: std::sync::mpsc::RecvError) -> Self {
        IdsError::DataLoading(format!("Channel receive error: {err}"))
    }
}

// Implementation for additional error types can be added as needed.
// If additional crate dependencies are added in the future,
// add their error conversions here with appropriate feature flags.

// Convert from std::path::StripPrefixError to IdsError
impl From<std::path::StripPrefixError> for IdsError {
    fn from(err: std::path::StripPrefixError) -> Self {
        IdsError::PathResolution(format!("Path prefix error: {err}"))
    }
}

// Add implementations for error types that don't have #[from] in the enum
// This file will be expanded as we identify more error types needing conversion
</file>

<file path="src/error/macros.rs">
/// Ensure a condition is true, otherwise return with an error
///
/// This macro is inspired by the `assert!` macro but returns an error instead of panicking.
/// It has three forms:
///
/// 1. With a direct `IdsError` instance: `ensure!(val >= 0, IdsError::validation("Invalid value"))`
/// 2. With a simple string message: `ensure!(val >= 0, "Value must be non-negative")`
/// 3. With a formatted message: `ensure!(val < 100, "Value {} exceeds maximum allowed (100)", val)`
///
/// # Examples
///
/// ```
/// use types::error::{ensure, IdsError, Result};
///
/// fn process_value(val: i32) -> Result<()> {
///     // Return early if val < 0 with direct error
///     ensure!(val >= 0, IdsError::validation("Value must be non-negative"));
///
///     // Using simple message version (creates a Validation error)
///     ensure!(val < 1000, "Value exceeds maximum allowed");
///
///     // Using formatted message version (creates a Validation error)
///     ensure!(val < 100, "Value {} exceeds maximum allowed (100)", val);
///
///     Ok(())
/// }
/// ```
///
/// The macro is particularly useful for validating input parameters and preconditions
/// with clear and descriptive error messages. This improves debugging and makes
/// the code more self-documenting.
///
/// # Error Types
///
/// When using the string message forms, a `Validation` error is created.
/// For more specific error types, use the direct error form.
#[macro_export]
macro_rules! ensure {
    // Condition with direct error expression form
    ($condition:expr, $error:expr $(,)?) => {
        if !($condition) {
            return Err($error);
        }
    };
    // Condition with simple string message form
    ($condition:expr, $message:literal) => {
        if !($condition) {
            return Err($crate::error::IdsError::validation($message));
        }
    };
    // Condition with formatted message form
    ($condition:expr, $fmt:expr, $($arg:tt)*) => {
        if !($condition) {
            return Err($crate::error::IdsError::validation(format!($fmt, $($arg)*)));
        }
    };
}

/// Try to run an operation, with context if it fails
///
/// This macro wraps an operation that returns a Result, adding context
/// if the operation fails. It uses the `with_context` implementation to
/// preserve error types where possible.
///
/// # Examples
///
/// ```
/// use types::error::{try_with_context, IdsError, Result};
///
/// fn read_config(path: &str) -> Result<String> {
///     let content = try_with_context!(
///         std::fs::read_to_string(path),
///         "Failed to read configuration file"
///     );
///
///     // Using formatted message version
///     let value = try_with_context!(
///         content.parse::<i32>(),
///         "Failed to parse '{}' as integer from config",
///         content.trim()
///     );
///
///     Ok(format!("Config value: {}", value))
/// }
/// ```
///
/// The macro is intelligent about error handling:
///
/// 1. For standard library errors (io, parse, etc.), it preserves their type info
/// 2. For Arrow errors, it uses the specialized `ArrowWithContext` variant
/// 3. For Parquet errors, it also uses `ArrowWithContext` for consistency
/// 4. For other errors, it creates a `DataAccess` error with the original as source
#[macro_export]
macro_rules! try_with_context {
    ($expr:expr, $context:expr) => {
        match $expr {
            Ok(val) => val,
            Err(err) => {
                return $crate::error::with_context(std::result::Result::Err(err), || $context);
            }
        }
    };
    ($expr:expr, $fmt:expr, $($arg:tt)*) => {
        match $expr {
            Ok(val) => val,
            Err(err) => {
                return $crate::error::with_context(
                    std::result::Result::Err(err),
                    || format!($fmt, $($arg)*)
                );
            }
        }
    };
}

/// Bail out of a function early with an error
///
/// This macro returns early with an error, similar to `return Err(...);`.
/// It can be used in three ways:
///
/// 1. With a direct `IdsError` instance: `bail!(IdsError::validation("Invalid data"))`
/// 2. With a simple string message: `bail!("No data provided")` (creates a Validation error)
/// 3. With a formatted message: `bail!("Empty data: expected at least {} characters", 1)`
///
/// # Examples
///
/// ```
/// use types::error::{bail, IdsError, Result};
///
/// fn process_data(data: Option<&str>) -> Result<()> {
///     let data = match data {
///         Some(d) => d,
///         None => bail!("No data provided"),
///     };
///
///     // Using formatted message version
///     if data.is_empty() {
///         bail!("Empty data: expected at least {} characters", 1);
///     }
///
///     // Using direct error instance
///     if data.len() > 1000 {
///         bail!(IdsError::validation("Data exceeds maximum allowed size"));
///     }
///
///     Ok(())
/// }
/// ```
///
/// The macro's behavior can be customized by which variant you choose:
///
/// - For validation and precondition errors, prefer the string message form
/// - For specific error types, use the direct error instance form
/// - For complex error messages, use the formatted message form
#[macro_export]
macro_rules! bail {
    // Direct error expression form
    ($error:expr $(,)?) => {
        return Err($error);
    };
    // Simple string message form (creates a Validation error)
    ($message:literal) => {
        return Err($crate::error::IdsError::validation($message));
    };
    // Formatted message form (creates a Validation error)
    ($fmt:expr, $($arg:tt)*) => {
        return Err($crate::error::IdsError::validation(format!($fmt, $($arg)*)));
    };
}

// Re-export macros for the prelude - macros are automatically public since they're defined at crate level
</file>

<file path="src/error/mod.rs">
pub use anyhow::{anyhow, Context, Result as AnyhowResultType};
pub use color_eyre::{eyre::Report, Result as EyreResult};
use std::error::Error as StdError;
use thiserror::Error;

// Submodules
mod context;
mod conversion;
#[cfg(doc)]
pub mod example; // Only included for documentation, not part of public API

mod macros;

// Re-export from submodules
pub use self::context::{with_context, with_context_details, ErrorContext, LegacyErrorContext};

/// The main error type for the IDS project
///
/// This error type has been designed to handle all errors from all crates in the project,
/// allowing for a unified error handling approach while maintaining domain-specific context.
#[derive(Error, Debug)]
pub enum IdsError {
    // Common external errors
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("CSV error: {0}")]
    Csv(#[from] csv::Error),

    #[error("Arrow error: {0}")]
    Arrow(#[from] arrow::error::ArrowError),

    /// Arrow error with detailed context information
    #[error("Arrow error: {context}")]
    ArrowWithContext {
        #[source]
        source: Box<dyn std::error::Error + Send + Sync>,
        context: String,
    },

    #[error("Parquet error: {0}")]
    Parquet(#[from] parquet::errors::ParquetError),

    #[error("JSON error: {0}")]
    Json(#[from] serde_json::Error),

    #[error("Logger error: failed to set logger")]
    Logger,

    // Domain-specific errors
    #[error("Configuration error: {0}")]
    Config(String),

    #[error("Data loading error: {0}")]
    DataLoading(String),

    /// Data access error with source and context
    #[error("Data access error: {context}. Source: {source}")]
    DataAccess {
        #[source]
        source: Box<dyn std::error::Error + Send + Sync>,
        context: String,
    },

    #[error("Balance calculation error: {0}")]
    BalanceCalculation(String),

    #[error("Sampling error: {0}")]
    Sampling(String),

    #[error("Register generation error: {0}")]
    Generation(String),

    #[error("Validation error: {0}")]
    Validation(String),

    #[error("Path resolution error: {0}")]
    PathResolution(String),

    #[error("CLI argument error: {0}")]
    CliArgument(String),

    // Data validation errors
    #[error("Invalid date: {0}")]
    InvalidDate(String),

    #[error("Missing data: {0}")]
    MissingData(String),

    #[error("Invalid format: {0}")]
    InvalidFormat(String),

    #[error("Invalid operation: {0}")]
    InvalidOperation(String),

    #[error("No eligible controls found for case")]
    NoEligibleControls,

    #[error("Invalid matching criteria: {0}")]
    InvalidCriteria(String),

    #[error("Covariate error: {0}")]
    Covariate(String),

    #[error("Plotting error: {0}")]
    Plotting(String),

    /// Schema-related errors (validation, mismatch, etc.)
    #[error("Schema error: {0}")]
    Schema(String),

    // Catch-all for other errors
    #[error("Other error: {0}")]
    Other(String),

    // Anyhow/Eyre integration
    #[error(transparent)]
    Anyhow(#[from] anyhow::Error),

    #[error(transparent)]
    Eyre(#[from] Report),

    // Boxed dynamic error for external errors
    #[error("External error: {0}")]
    External(#[from] Box<dyn StdError + Send + Sync>),
}

impl IdsError {
    /// Create a configuration error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Config` with the provided message
    #[must_use]
    pub fn config(msg: impl ToString) -> Self {
        Self::Config(msg.to_string())
    }

    /// Create a data loading error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::DataLoading` with the provided message
    #[must_use]
    pub fn data_loading(msg: impl ToString) -> Self {
        Self::DataLoading(msg.to_string())
    }

    /// Create a balance calculation error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::BalanceCalculation` with the provided message
    #[must_use]
    pub fn balance_calculation(msg: impl ToString) -> Self {
        Self::BalanceCalculation(msg.to_string())
    }

    /// Create a sampling error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Sampling` with the provided message
    #[must_use]
    pub fn sampling(msg: impl ToString) -> Self {
        Self::Sampling(msg.to_string())
    }

    /// Create a generation error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Generation` with the provided message
    #[must_use]
    pub fn generation(msg: impl ToString) -> Self {
        Self::Generation(msg.to_string())
    }

    /// Create a validation error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Validation` with the provided message
    #[must_use]
    pub fn validation(msg: impl ToString) -> Self {
        Self::Validation(msg.to_string())
    }

    /// Create a path resolution error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::PathResolution` with the provided message
    #[must_use]
    pub fn path_resolution(msg: impl ToString) -> Self {
        Self::PathResolution(msg.to_string())
    }

    /// Create a CLI argument error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::CliArgument` with the provided message
    #[must_use]
    pub fn cli_argument(msg: impl ToString) -> Self {
        Self::CliArgument(msg.to_string())
    }

    /// Create an invalid operation error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::InvalidOperation` with the provided message
    #[must_use]
    pub fn invalid_operation(msg: impl ToString) -> Self {
        Self::InvalidOperation(msg.to_string())
    }

    /// Create a missing data error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::MissingData` with the provided message
    #[must_use]
    pub fn missing_data(msg: impl ToString) -> Self {
        Self::MissingData(msg.to_string())
    }

    /// Create an invalid format error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::InvalidFormat` with the provided message
    #[must_use]
    pub fn invalid_format(msg: impl ToString) -> Self {
        Self::InvalidFormat(msg.to_string())
    }

    /// Create an invalid date error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::InvalidDate` with the provided message
    #[must_use]
    pub fn invalid_date(msg: impl ToString) -> Self {
        Self::InvalidDate(msg.to_string())
    }

    /// Create a plotting error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Plotting` with the provided message
    #[must_use]
    pub fn plotting(msg: impl ToString) -> Self {
        Self::Plotting(msg.to_string())
    }

    /// Create a covariate error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Covariate` with the provided message
    #[must_use]
    pub fn covariate(msg: impl ToString) -> Self {
        Self::Covariate(msg.to_string())
    }

    /// Create an invalid criteria error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::InvalidCriteria` with the provided message
    #[must_use]
    pub fn invalid_criteria(msg: impl ToString) -> Self {
        Self::InvalidCriteria(msg.to_string())
    }

    /// Create an invalid value error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::InvalidFormat` with the provided message about invalid values
    #[must_use]
    pub fn invalid_value(msg: impl ToString) -> Self {
        Self::InvalidFormat(format!("Invalid value: {}", msg.to_string()))
    }

    /// Create an IO error with a message
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Io` with the provided message
    #[must_use]
    pub fn io_error(msg: impl ToString) -> Self {
        Self::Io(std::io::Error::new(
            std::io::ErrorKind::Other,
            msg.to_string(),
        ))
    }

    /// Create a general error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new `IdsError::Other` with the provided message
    #[must_use]
    pub fn other(msg: impl ToString) -> Self {
        Self::Other(msg.to_string())
    }

    /// Create a logger error
    ///
    /// # Returns
    /// A new `IdsError::Logger` error
    #[must_use]
    pub fn logger() -> Self {
        Self::Logger
    }

    /// Create a new type conversion error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new error with type conversion context
    #[must_use]
    pub fn type_conversion(msg: impl ToString) -> Self {
        Self::DataLoading(format!("Type conversion: {}", msg.to_string()))
    }

    /// Create a new column not found error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new error with column not found context
    #[must_use]
    pub fn column_not_found(msg: impl ToString) -> Self {
        Self::DataLoading(format!("Column not found: {}", msg.to_string()))
    }

    /// Create a new index out of bounds error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new error with index out of bounds context
    #[must_use]
    pub fn index_out_of_bounds(msg: impl ToString) -> Self {
        Self::DataLoading(format!("Index out of bounds: {}", msg.to_string()))
    }

    /// Create a new date conversion error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new error with date conversion context
    #[must_use]
    pub fn date_conversion(msg: impl ToString) -> Self {
        Self::DataLoading(format!("Date conversion: {}", msg.to_string()))
    }

    /// Create a new missing value error
    ///
    /// # Arguments
    /// * `msg` - The error message
    ///
    /// # Returns
    /// A new error for missing values
    #[must_use]
    pub fn missing_value(msg: impl ToString) -> Self {
        Self::MissingData(format!("Missing value: {}", msg.to_string()))
    }

    /// Create a data access error with source and context
    ///
    /// # Arguments
    /// * `err` - The source error
    /// * `context` - The context describing what was happening when the error occurred
    ///
    /// # Returns
    /// A new `IdsError::DataAccess` with the provided source and context
    #[must_use]
    pub fn data_access<E, S>(err: E, context: S) -> Self
    where
        E: std::error::Error + Send + Sync + 'static,
        S: AsRef<str>,
    {
        Self::DataAccess {
            source: Box::new(err),
            context: context.as_ref().to_string(),
        }
    }

    /// Create an Arrow error with source and context
    ///
    /// # Arguments
    /// * `err` - The source error
    /// * `context` - The context describing what was happening when the error occurred
    ///
    /// # Returns
    /// A new `IdsError::ArrowWithContext` with the provided source and context
    #[must_use]
    pub fn arrow<E, S>(err: E, context: S) -> Self
    where
        E: std::error::Error + Send + Sync + 'static,
        S: AsRef<str>,
    {
        Self::ArrowWithContext {
            source: Box::new(err),
            context: context.as_ref().to_string(),
        }
    }

    /// Create an error for missing or invalid register data
    ///
    /// # Arguments
    /// * `register_type` - The type of register (e.g., "AKM", "BEF")
    /// * `details` - Additional details about what's missing
    ///
    /// # Returns
    /// A new `IdsError::DataLoading` with a formatted message
    #[must_use]
    pub fn register_data(register_type: impl ToString, details: impl ToString) -> Self {
        Self::DataLoading(format!(
            "Invalid {} register data: {}",
            register_type.to_string(),
            details.to_string()
        ))
    }

    /// Create an error for schema mismatches
    ///
    /// # Arguments
    /// * `expected` - The expected schema or field
    /// * `actual` - The actual schema or field found (or "not found")
    ///
    /// # Returns
    /// A new `IdsError::Schema` with a formatted message
    #[must_use]
    pub fn schema_mismatch(expected: impl ToString, actual: impl ToString) -> Self {
        Self::Schema(format!(
            "Schema mismatch: expected {}, found {}",
            expected.to_string(),
            actual.to_string()
        ))
    }

    /// Create an error for failed data lookup operations
    ///
    /// # Arguments
    /// * `entity_type` - The type of entity being looked up (PNR, column, etc.)
    /// * `identifier` - The identifier that wasn't found
    /// * `source` - The source being searched (register, dataset, etc.)
    ///
    /// # Returns
    /// A new `IdsError::MissingData` with a formatted message
    #[must_use]
    pub fn lookup_failed(
        entity_type: impl ToString,
        identifier: impl ToString,
        source: impl ToString,
    ) -> Self {
        Self::MissingData(format!(
            "Failed to find {} '{}' in {}",
            entity_type.to_string(),
            identifier.to_string(),
            source.to_string()
        ))
    }

    /// Create an error for invalid data types or conversions
    ///
    /// # Arguments
    /// * `source_type` - The source data type
    /// * `target_type` - The target data type
    /// * `details` - Optional additional details about the conversion failure
    ///
    /// # Returns
    /// A new `IdsError::TypeConversion` with a formatted message
    #[must_use]
    pub fn type_conversion_detailed(
        source_type: impl ToString,
        target_type: impl ToString,
        details: Option<impl ToString>,
    ) -> Self {
        let msg = if let Some(details) = details {
            format!(
                "Failed to convert {} to {}: {}",
                source_type.to_string(),
                target_type.to_string(),
                details.to_string()
            )
        } else {
            format!(
                "Failed to convert {} to {}",
                source_type.to_string(),
                target_type.to_string()
            )
        };

        Self::type_conversion(msg)
    }
}

/// Type alias for Result with `IdsError`
pub type Result<T> = std::result::Result<T, IdsError>;

/// Enhanced error handling with better context support
///
/// This module provides easy integration with anyhow and color-eyre for richer error contexts.
///
/// # Examples
///
/// ## Using anyhow context
/// ```
/// use types::error::{Result, AnyhowResultType};
/// use anyhow::Context;
///
/// fn read_config(path: &str) -> AnyhowResultType<String> {
///     std::fs::read_to_string(path)
///         .context(format!("Failed to read configuration file at {path}"))
/// }
/// ```
///
/// ## Using color-eyre
/// ```
/// use types::error::{Result, EyreResult};
/// use color_eyre::eyre::WrapErr;
///
/// fn process_data(path: &str) -> EyreResult<()> {
///     let data = std::fs::read_to_string(path)
///         .wrap_err(format!("Failed to read data file at {path}"))?;
///     // Process data...
///     Ok(())
/// }
/// ```
///
/// ## Converting to `IdsError`
/// ```
/// use types::error::{Result, IdsError};
/// use anyhow::Context;
///
/// fn load_config(path: &str) -> Result<String> {
///     std::fs::read_to_string(path)
///         .context(format!("Failed to read configuration file at {path}"))
///         .map_err(IdsError::from)
/// }
/// ```

// Type aliases for backwards compatibility
pub type SamplingError = IdsError;
pub type PlottingError = IdsError;
pub type DataGenError = IdsError;

/// Add a prelude for convenient imports
pub mod prelude {
    pub use super::{
        anyhow, AnyhowResultType, Context, ErrorContext, EyreResult, IdsError, LegacyErrorContext,
        Report, Result,
    };

    // Re-export macros defined at crate root
    pub use crate::{bail, ensure, try_with_context};

    /// Re-export `color_eyre`'s `WrapErr` trait for better error messages
    pub use color_eyre::eyre::WrapErr;

    /// Setup function to initialize color-eyre for pretty error reports
    ///
    /// Call this function at the beginning of your program to enable color-eyre's
    /// pretty error reporting with backtraces.
    ///
    /// # Example
    /// ```
    /// use types::error::prelude::*;
    ///
    /// fn main() -> EyreResult<()> {
    ///     install_color_eyre()?;
    ///
    ///     // Your program code...
    ///     Ok(())
    /// }
    /// ```
    pub fn install_color_eyre() -> color_eyre::Result<()> {
        color_eyre::install()
    }
}
</file>

<file path="src/family/mod.rs">
pub mod relations;
pub mod store;

pub use relations::FamilyRelations;
pub use store::FamilyStore;
</file>

<file path="src/family/relations.rs">
use chrono::NaiveDate;

/// Family relationships for a person
#[derive(Clone, Debug)]
pub struct FamilyRelations {
    pub pnr: String,
    pub birth_date: NaiveDate,
    pub father_id: Option<String>,
    pub father_birth_date: Option<NaiveDate>,
    pub mother_id: Option<String>,
    pub mother_birth_date: Option<NaiveDate>,
    pub family_id: Option<String>,
}

impl FamilyRelations {
    /// Create a new family relations object
    pub fn new(pnr: impl Into<String>, birth_date: NaiveDate) -> Self {
        Self {
            pnr: pnr.into(),
            birth_date,
            father_id: None,
            father_birth_date: None,
            mother_id: None,
            mother_birth_date: None,
            family_id: None,
        }
    }

    /// Add father information
    pub fn with_father(mut self, id: impl Into<String>, birth_date: Option<NaiveDate>) -> Self {
        self.father_id = Some(id.into());
        self.father_birth_date = birth_date;
        self
    }

    /// Add mother information
    pub fn with_mother(mut self, id: impl Into<String>, birth_date: Option<NaiveDate>) -> Self {
        self.mother_id = Some(id.into());
        self.mother_birth_date = birth_date;
        self
    }

    /// Add family ID
    pub fn with_family_id(mut self, id: impl Into<String>) -> Self {
        self.family_id = Some(id.into());
        self
    }
}
</file>

<file path="src/family/store.rs">
use crate::{error::IdsError, family::FamilyRelations};
use arrow::{
    array::{Array, Date32Array, StringArray},
    record_batch::RecordBatch,
};
use chrono::NaiveDate;
use hashbrown::HashMap;

/// A store for family relationships
#[derive(Clone, Debug)]
pub struct FamilyStore {
    pub relations: HashMap<String, FamilyRelations>,
}

impl Default for FamilyStore {
    fn default() -> Self {
        Self::new()
    }
}

impl FamilyStore {
    /// Create a new, empty family store
    #[must_use]
    pub fn new() -> Self {
        Self {
            relations: HashMap::new(),
        }
    }

    /// Get all relations in this store
    #[must_use]
    pub fn get_relations(&self) -> &HashMap<String, FamilyRelations> {
        &self.relations
    }

    /// Get a specific relation by PNR
    #[must_use]
    pub fn get_relation(&self, pnr: &str) -> Option<&FamilyRelations> {
        self.relations.get(pnr)
    }

    /// Add a relation to this store
    pub fn add_relation(&mut self, relation: FamilyRelations) {
        self.relations.insert(relation.pnr.clone(), relation);
    }

    /// Load family relations from a set of Arrow `RecordBatches`
    pub fn load_family_relations(&mut self, batches: Vec<RecordBatch>) -> Result<(), IdsError> {
        for batch in batches {
            self.process_batch(&batch)?;
        }
        Ok(())
    }

    fn process_batch(&mut self, batch: &RecordBatch) -> Result<(), IdsError> {
        // Get the string arrays from the batch
        let pnr_column = batch.column(batch.schema().index_of("PNR")?);
        let pnr_array = pnr_column
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| {
                IdsError::data_loading("PNR column is not a string array".to_string())
            })?;

        let birth_date_column = batch.column(batch.schema().index_of("BIRTH_DATE")?);
        let birth_date_array = birth_date_column
            .as_any()
            .downcast_ref::<Date32Array>()
            .ok_or_else(|| {
                IdsError::data_loading("BIRTH_DATE column is not a date array".to_string())
            })?;

        let father_id_column = batch.column(batch.schema().index_of("FATHER_ID")?);
        let father_id_array = father_id_column
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| {
                IdsError::data_loading("FATHER_ID column is not a string array".to_string())
            })?;

        let father_birth_date_column = batch.column(batch.schema().index_of("FATHER_BIRTH_DATE")?);
        let father_birth_date_array = father_birth_date_column
            .as_any()
            .downcast_ref::<Date32Array>()
            .ok_or_else(|| {
                IdsError::data_loading("FATHER_BIRTH_DATE column is not a date array".to_string())
            })?;

        let mother_id_column = batch.column(batch.schema().index_of("MOTHER_ID")?);
        let mother_id_array = mother_id_column
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| {
                IdsError::data_loading("MOTHER_ID column is not a string array".to_string())
            })?;

        let mother_birth_date_column = batch.column(batch.schema().index_of("MOTHER_BIRTH_DATE")?);
        let mother_birth_date_array = mother_birth_date_column
            .as_any()
            .downcast_ref::<Date32Array>()
            .ok_or_else(|| {
                IdsError::data_loading("MOTHER_BIRTH_DATE column is not a date array".to_string())
            })?;

        let family_id_column = batch.column(batch.schema().index_of("FAMILY_ID")?);
        let family_id_array = family_id_column
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| {
                IdsError::data_loading("FAMILY_ID column is not a string array".to_string())
            })?;

        // Helper function to convert date32 to NaiveDate
        fn convert_date32_to_naive_date(days_since_epoch: i32) -> Result<NaiveDate, IdsError> {
            // Use the new safe method
            NaiveDate::from_num_days_from_ce_opt(days_since_epoch).ok_or_else(|| {
                IdsError::data_loading(format!(
                    "Could not convert {days_since_epoch} days since epoch to date"
                ))
            })
        }

        for i in 0..batch.num_rows() {
            let pnr = pnr_array.value(i).to_string();
            let birth_date = convert_date32_to_naive_date(birth_date_array.value(i))?;

            let relation = FamilyRelations {
                pnr: pnr.clone(),
                birth_date,
                father_id: if father_id_array.is_null(i) {
                    None
                } else {
                    Some(father_id_array.value(i).to_string())
                },
                father_birth_date: if father_birth_date_array.is_null(i) {
                    None
                } else {
                    Some(convert_date32_to_naive_date(
                        father_birth_date_array.value(i),
                    )?)
                },
                mother_id: if mother_id_array.is_null(i) {
                    None
                } else {
                    Some(mother_id_array.value(i).to_string())
                },
                mother_birth_date: if mother_birth_date_array.is_null(i) {
                    None
                } else {
                    Some(convert_date32_to_naive_date(
                        mother_birth_date_array.value(i),
                    )?)
                },
                family_id: if family_id_array.is_null(i) {
                    None
                } else {
                    Some(family_id_array.value(i).to_string())
                },
            };

            self.relations.insert(pnr, relation);
        }
        Ok(())
    }
}
</file>

<file path="src/models/covariate/builders.rs">
use super::types::{Covariate, CovariateType, CovariateValue, DemographicExtras};
use hashbrown::HashMap;

// Builder for education covariates
#[derive(Clone)]
pub struct EducationBuilder {
    pub(crate) level: String,
    pub(crate) isced_code: Option<String>,
    pub(crate) years: Option<f32>,
    pub(crate) metadata: HashMap<String, String>,
}

impl EducationBuilder {
    /// Create a new builder instance
    #[must_use]
    pub fn new(level: impl Into<String>) -> Self {
        Self {
            level: level.into(),
            isced_code: None,
            years: None,
            metadata: HashMap::new(),
        }
    }

    /// Add an ISCED code to this education covariate
    pub fn with_isced_code(mut self, code: impl Into<String>) -> Self {
        self.isced_code = Some(code.into());
        self
    }

    /// Add years of education to this education covariate
    #[must_use] pub fn with_years(mut self, years: f32) -> Self {
        self.years = Some(years);
        self
    }

    /// Add metadata to this education covariate
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }

    /// Build the education covariate
    #[must_use] pub fn build(self) -> Covariate {
        Covariate {
            type_: CovariateType::Education,
            value: CovariateValue::Education {
                level: self.level,
                isced_code: self.isced_code,
                years: self.years,
            },
            metadata: self.metadata,
        }
    }
}

// Builder for income covariates
#[derive(Clone)]
pub struct IncomeBuilder {
    pub(crate) amount: f64,
    pub(crate) currency: String,
    pub(crate) type_code: String,
    pub(crate) wage_income: Option<f64>,
    pub(crate) employment_status: Option<i32>,
    pub(crate) metadata: HashMap<String, String>,
}

impl IncomeBuilder {
    /// Create a new builder instance
    #[must_use]
    pub fn new(amount: f64, currency: impl Into<String>, type_code: impl Into<String>) -> Self {
        Self {
            amount,
            currency: currency.into(),
            type_code: type_code.into(),
            wage_income: None,
            employment_status: None,
            metadata: HashMap::new(),
        }
    }

    /// Add wage income to this income covariate
    #[must_use] pub fn with_wage_income(mut self, wage_income: f64) -> Self {
        self.wage_income = Some(wage_income);
        self
    }

    /// Add employment status to this income covariate
    #[must_use] pub fn with_employment_status(mut self, status: i32) -> Self {
        self.employment_status = Some(status);
        self
    }

    /// Add metadata to this income covariate
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }

    /// Build the income covariate
    #[must_use] pub fn build(self) -> Covariate {
        Covariate {
            type_: CovariateType::Income,
            value: CovariateValue::Income {
                amount: self.amount,
                currency: self.currency,
                type_code: self.type_code,
                wage_income: self.wage_income,
                employment_status: self.employment_status,
            },
            metadata: self.metadata,
        }
    }
}

// Builder for occupation covariates
#[derive(Clone)]
pub struct OccupationBuilder {
    pub(crate) code: String,
    pub(crate) classification: String,
    pub(crate) socio: Option<i32>,
    pub(crate) socio02: Option<i32>,
    pub(crate) pre_socio: Option<i32>,
    pub(crate) metadata: HashMap<String, String>,
}

impl OccupationBuilder {
    /// Create a new builder instance
    #[must_use]
    pub fn new(code: impl Into<String>, classification: impl Into<String>) -> Self {
        Self {
            code: code.into(),
            classification: classification.into(),
            socio: None,
            socio02: None,
            pre_socio: None,
            metadata: HashMap::new(),
        }
    }

    /// Add socio code to this occupation covariate
    #[must_use] pub fn with_socio(mut self, socio: i32) -> Self {
        self.socio = Some(socio);
        self
    }

    /// Add socio02 code to this occupation covariate
    #[must_use] pub fn with_socio02(mut self, socio02: i32) -> Self {
        self.socio02 = Some(socio02);
        self
    }

    /// Add `pre_socio` code to this occupation covariate
    #[must_use] pub fn with_pre_socio(mut self, pre_socio: i32) -> Self {
        self.pre_socio = Some(pre_socio);
        self
    }

    /// Add metadata to this occupation covariate
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }

    /// Build the occupation covariate
    #[must_use] pub fn build(self) -> Covariate {
        Covariate {
            type_: CovariateType::Occupation,
            value: CovariateValue::Occupation {
                code: self.code,
                classification: self.classification,
                socio: self.socio,
                socio02: self.socio02,
                pre_socio: self.pre_socio,
            },
            metadata: self.metadata,
        }
    }
}

// Builder for demographics covariates
#[derive(Clone)]
pub struct DemographicsBuilder {
    pub(crate) family_size: i32,
    pub(crate) municipality: i32,
    pub(crate) family_type: String,
    pub(crate) civil_status: Option<String>,
    pub(crate) gender: Option<String>,
    pub(crate) citizenship: Option<String>,
    pub(crate) age: Option<i32>,
    pub(crate) children_count: Option<i32>,
    pub(crate) metadata: HashMap<String, String>,
}

impl DemographicsBuilder {
    /// Create a new builder instance
    #[must_use]
    pub fn new(family_size: i32, municipality: i32, family_type: impl Into<String>) -> Self {
        Self {
            family_size,
            municipality,
            family_type: family_type.into(),
            civil_status: None,
            gender: None,
            citizenship: None,
            age: None,
            children_count: None,
            metadata: HashMap::new(),
        }
    }

    /// Add civil status to this demographics covariate
    pub fn with_civil_status(mut self, status: impl Into<String>) -> Self {
        self.civil_status = Some(status.into());
        self
    }

    /// Add gender to this demographics covariate
    pub fn with_gender(mut self, gender: impl Into<String>) -> Self {
        self.gender = Some(gender.into());
        self
    }

    /// Add citizenship to this demographics covariate
    pub fn with_citizenship(mut self, citizenship: impl Into<String>) -> Self {
        self.citizenship = Some(citizenship.into());
        self
    }

    /// Add age to this demographics covariate
    #[must_use] pub fn with_age(mut self, age: i32) -> Self {
        self.age = Some(age);
        self
    }

    /// Add children count to this demographics covariate
    #[must_use] pub fn with_children_count(mut self, count: i32) -> Self {
        self.children_count = Some(count);
        self
    }

    /// Add all demographic extras at once
    #[must_use] pub fn with_extras(mut self, extras: DemographicExtras) -> Self {
        self.civil_status = extras.civil_status;
        self.gender = extras.gender;
        self.citizenship = extras.citizenship;
        self.age = extras.age;
        self.children_count = extras.children_count;
        self
    }

    /// Add metadata to this demographics covariate
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }

    /// Build the demographics covariate
    #[must_use] pub fn build(self) -> Covariate {
        Covariate {
            type_: CovariateType::Demographics,
            value: CovariateValue::Demographics {
                family_size: self.family_size,
                municipality: self.municipality,
                family_type: self.family_type,
                civil_status: self.civil_status,
                gender: self.gender,
                citizenship: self.citizenship,
                age: self.age,
                children_count: self.children_count,
            },
            metadata: self.metadata,
        }
    }
}
</file>

<file path="src/models/covariate/mod.rs">
// Modules
pub mod builders;
mod types;
mod values;

// Re-exports
pub use self::types::{Covariate, CovariateType, CovariateValue, DemographicExtras};

// Re-export builders for convenience
pub use self::builders::{DemographicsBuilder, EducationBuilder, IncomeBuilder, OccupationBuilder};
</file>

<file path="src/models/covariate/types.rs">
use hashbrown::HashMap;

#[cfg(feature = "serde-support")]
use serde::{Deserialize, Serialize};

/// A covariate represents a variable that can be used for matching or analysis
#[cfg_attr(feature = "serde-support", derive(Serialize, Deserialize))]
#[derive(Debug, Clone)]
pub struct Covariate {
    pub type_: CovariateType,
    pub value: CovariateValue,
    pub metadata: HashMap<String, String>,
}

/// Types of covariates available in the system
#[cfg_attr(feature = "serde-support", derive(Serialize, Deserialize))]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum CovariateType {
    /// Educational background information
    Education,
    /// Income and wealth information
    Income,
    /// Occupational data
    Occupation,
    /// Demographic information (age, gender, etc.)
    Demographics,
}

/// The actual value of a covariate, with type-specific fields
#[cfg_attr(feature = "serde-support", derive(Serialize, Deserialize))]
#[derive(Debug, Clone)]
pub enum CovariateValue {
    /// Education-related information
    Education {
        /// Education level description
        level: String,
        /// International Standard Classification of Education code
        isced_code: Option<String>,
        /// Years of education
        years: Option<f32>,
    },
    /// Income-related information
    Income {
        /// Income amount
        amount: f64,
        /// Currency code
        currency: String,
        /// Type of income
        type_code: String,
        /// Wage income (`LOENMV_13`)
        wage_income: Option<f64>,
        /// Employment status code (BESKST13)
        employment_status: Option<i32>,
    },
    /// Occupation-related information
    Occupation {
        /// Occupation code
        code: String,
        /// Classification system used
        classification: String,
        /// Socioeconomic status (SOCIO)
        socio: Option<i32>,
        /// Alternative socioeconomic status (SOCIO02)
        socio02: Option<i32>,
        /// Preliminary socioeconomic status (`PRE_SOCIO`)
        pre_socio: Option<i32>,
    },
    /// Demographic information
    Demographics {
        /// Number of people in the family
        family_size: i32,
        /// Municipality code
        municipality: i32,
        /// Family type description
        family_type: String,
        /// Civil status (CIVST)
        civil_status: Option<String>,
        /// Gender (KOEN)
        gender: Option<String>,
        /// Citizenship (STATSB)
        citizenship: Option<String>,
        /// Age in years (ALDER)
        age: Option<i32>,
        /// Number of children (ANTBOERNF/ANTBOERNH)
        children_count: Option<i32>,
    },
}

/// Container for additional demographic information to avoid clippy warnings
/// about too many arguments
#[cfg_attr(feature = "serde-support", derive(Serialize, Deserialize))]
#[derive(Debug, Clone, Default)]
pub struct DemographicExtras {
    /// Civil status (CIVST)
    pub civil_status: Option<String>,
    /// Gender (KOEN)
    pub gender: Option<String>,
    /// Citizenship (STATSB)
    pub citizenship: Option<String>,
    /// Age in years (ALDER)
    pub age: Option<i32>,
    /// Number of children (ANTBOERNF/ANTBOERNH)
    pub children_count: Option<i32>,
}
</file>

<file path="src/models/covariate/values.rs">
use super::builders::{DemographicsBuilder, EducationBuilder, IncomeBuilder, OccupationBuilder};
use super::types::{Covariate, CovariateType, CovariateValue};
use hashbrown::HashMap;

impl Covariate {
    /// Get the type of this covariate
    #[must_use]
    pub const fn type_(&self) -> CovariateType {
        self.type_
    }

    /// Create a new education covariate using the builder pattern
    #[must_use]
    pub fn education(level: impl Into<String>) -> EducationBuilder {
        EducationBuilder {
            level: level.into(),
            isced_code: None,
            years: None,
            metadata: HashMap::new(),
        }
    }

    /// Create a new income covariate using the builder pattern
    #[must_use]
    pub fn income(
        amount: f64,
        currency: impl Into<String>,
        type_code: impl Into<String>,
    ) -> IncomeBuilder {
        IncomeBuilder {
            amount,
            currency: currency.into(),
            type_code: type_code.into(),
            wage_income: None,
            employment_status: None,
            metadata: HashMap::new(),
        }
    }

    /// Create an extended income covariate with wage and employment details
    #[must_use]
    pub fn income_extended(
        amount: f64,
        currency: impl Into<String>,
        type_code: impl Into<String>,
        wage_income: Option<f64>,
        employment_status: Option<i32>,
    ) -> IncomeBuilder {
        IncomeBuilder {
            amount,
            currency: currency.into(),
            type_code: type_code.into(),
            wage_income,
            employment_status,
            metadata: HashMap::new(),
        }
    }

    /// Create a new occupation covariate using the builder pattern
    #[must_use]
    pub fn occupation(
        code: impl Into<String>,
        classification: impl Into<String>,
    ) -> OccupationBuilder {
        OccupationBuilder {
            code: code.into(),
            classification: classification.into(),
            socio: None,
            socio02: None,
            pre_socio: None,
            metadata: HashMap::new(),
        }
    }

    /// Create an extended occupation covariate with additional socio classifications
    #[must_use]
    pub fn occupation_extended(
        code: impl Into<String>,
        classification: impl Into<String>,
        socio: Option<i32>,
        socio02: Option<i32>,
        pre_socio: Option<i32>,
    ) -> OccupationBuilder {
        OccupationBuilder {
            code: code.into(),
            classification: classification.into(),
            socio,
            socio02,
            pre_socio,
            metadata: HashMap::new(),
        }
    }

    /// Create a new demographics covariate using the builder pattern
    #[must_use]
    pub fn demographics(
        family_size: i32,
        municipality: i32,
        family_type: impl Into<String>,
    ) -> DemographicsBuilder {
        DemographicsBuilder {
            family_size,
            municipality,
            family_type: family_type.into(),
            civil_status: None,
            gender: None,
            citizenship: None,
            age: None,
            children_count: None,
            metadata: HashMap::new(),
        }
    }

    /// Create a demographics covariate with all demographic extras
    #[must_use]
    pub fn demographics_with_extras(
        family_size: i32,
        municipality: i32,
        family_type: impl Into<String>,
        extras: super::types::DemographicExtras,
    ) -> DemographicsBuilder {
        DemographicsBuilder {
            family_size,
            municipality,
            family_type: family_type.into(),
            civil_status: extras.civil_status,
            gender: extras.gender,
            citizenship: extras.citizenship,
            age: extras.age,
            children_count: extras.children_count,
            metadata: HashMap::new(),
        }
    }

    // Education accessors
    #[must_use]
    pub fn education_level(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Education { level, .. } => Some(level.clone()),
            _ => None,
        }
    }

    #[must_use]
    pub fn isced_code(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Education { isced_code, .. } => isced_code.clone(),
            _ => None,
        }
    }

    #[must_use]

    pub const fn education_years(&self) -> Option<f32> {
        match &self.value {
            CovariateValue::Education { years, .. } => *years,
            _ => None,
        }
    }

    #[must_use]

    // Income accessors

    pub const fn income_amount(&self) -> Option<f64> {
        match &self.value {
            CovariateValue::Income { amount, .. } => Some(*amount),
            _ => None,
        }
    }

    #[must_use]

    pub fn currency(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Income { currency, .. } => Some(currency.clone()),
            _ => None,
        }
    }

    #[must_use]

    pub fn income_type_code(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Income { type_code, .. } => Some(type_code.clone()),
            _ => None,
        }
    }

    #[must_use]

    pub const fn wage_income(&self) -> Option<f64> {
        match &self.value {
            CovariateValue::Income { wage_income, .. } => *wage_income,
            _ => None,
        }
    }

    #[must_use]

    pub const fn employment_status(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Income {
                employment_status, ..
            } => *employment_status,
            _ => None,
        }
    }

    #[must_use]

    // Occupation accessors

    pub fn occupation_code(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Occupation { code, .. } => Some(code.clone()),
            _ => None,
        }
    }

    #[must_use]

    pub fn classification(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Occupation { classification, .. } => Some(classification.clone()),
            _ => None,
        }
    }

    #[must_use]

    pub const fn socio(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Occupation { socio, .. } => *socio,
            _ => None,
        }
    }

    #[must_use]

    pub const fn socio02(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Occupation { socio02, .. } => *socio02,
            _ => None,
        }
    }

    #[must_use]

    pub const fn pre_socio(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Occupation { pre_socio, .. } => *pre_socio,
            _ => None,
        }
    }

    #[must_use]

    // Demographics accessors

    pub const fn family_size(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Demographics { family_size, .. } => Some(*family_size),
            _ => None,
        }
    }

    #[must_use]

    pub const fn municipality(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Demographics { municipality, .. } => Some(*municipality),
            _ => None,
        }
    }

    #[must_use]

    pub fn family_type(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Demographics { family_type, .. } => Some(family_type.clone()),
            _ => None,
        }
    }

    #[must_use]

    pub fn civil_status(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Demographics { civil_status, .. } => civil_status.clone(),
            _ => None,
        }
    }

    #[must_use]

    pub fn gender(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Demographics { gender, .. } => gender.clone(),
            _ => None,
        }
    }

    #[must_use]

    pub fn citizenship(&self) -> Option<String> {
        match &self.value {
            CovariateValue::Demographics { citizenship, .. } => citizenship.clone(),
            _ => None,
        }
    }

    #[must_use]

    pub const fn age(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Demographics { age, .. } => *age,
            _ => None,
        }
    }

    #[must_use]

    pub const fn children_count(&self) -> Option<i32> {
        match &self.value {
            CovariateValue::Demographics { children_count, .. } => *children_count,
            _ => None,
        }
    }

    #[must_use]

    /// Add metadata to this covariate
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }
}
</file>

<file path="src/models/family/mod.rs">
// Modules
pub mod relations;
pub mod store;

// Re-exports
pub use self::relations::FamilyRelations;
pub use self::store::FamilyStore;
</file>

<file path="src/models/family/relations.rs">
use chrono::NaiveDate;

/// Family relationships for a person
#[derive(Clone, Debug)]
pub struct FamilyRelations {
    pub pnr: String,
    pub birth_date: NaiveDate,
    pub father_id: Option<String>,
    pub father_birth_date: Option<NaiveDate>,
    pub mother_id: Option<String>,
    pub mother_birth_date: Option<NaiveDate>,
    pub family_id: Option<String>,
}

impl FamilyRelations {
    /// Create a new family relations object
    pub fn new(pnr: impl Into<String>, birth_date: NaiveDate) -> Self {
        Self {
            pnr: pnr.into(),
            birth_date,
            father_id: None,
            father_birth_date: None,
            mother_id: None,
            mother_birth_date: None,
            family_id: None,
        }
    }

    /// Add father information
    pub fn with_father(mut self, id: impl Into<String>, birth_date: Option<NaiveDate>) -> Self {
        self.father_id = Some(id.into());
        self.father_birth_date = birth_date;
        self
    }

    /// Add mother information
    pub fn with_mother(mut self, id: impl Into<String>, birth_date: Option<NaiveDate>) -> Self {
        self.mother_id = Some(id.into());
        self.mother_birth_date = birth_date;
        self
    }

    /// Add family ID
    pub fn with_family_id(mut self, id: impl Into<String>) -> Self {
        self.family_id = Some(id.into());
        self
    }
}
</file>

<file path="src/models/family/store.rs">
use super::relations::FamilyRelations;
use crate::error::{IdsError, Result};
use arrow::{array::Array, record_batch::RecordBatch};
use chrono::NaiveDate;
use hashbrown::HashMap;

/// Convert an Arrow Date32 value (days since epoch) to a `NaiveDate`
fn convert_date32_to_naive_date(days_since_epoch: i32) -> Result<NaiveDate> {
    NaiveDate::from_num_days_from_ce_opt(days_since_epoch).ok_or_else(|| {
        IdsError::date_conversion(format!(
            "Could not convert {days_since_epoch} days since epoch to date"
        ))
    })
}

/// A store for family relationships
#[derive(Clone, Debug)]
pub struct FamilyStore {
    pub relations: HashMap<String, FamilyRelations>,
}

impl Default for FamilyStore {
    fn default() -> Self {
        Self::new()
    }
}

impl FamilyStore {
    /// Create a new, empty family store
    #[must_use]
    pub fn new() -> Self {
        Self {
            relations: HashMap::new(),
        }
    }

    /// Get all relations in this store
    #[must_use]
    pub fn get_relations(&self) -> &HashMap<String, FamilyRelations> {
        &self.relations
    }

    /// Get a specific relation by PNR
    #[must_use]
    pub fn get_relation(&self, pnr: &str) -> Option<&FamilyRelations> {
        self.relations.get(pnr)
    }

    /// Add a relation to this store
    pub fn add_relation(&mut self, relation: FamilyRelations) {
        self.relations.insert(relation.pnr.clone(), relation);
    }

    /// Load family relations from a set of Arrow `RecordBatches`
    pub fn load_family_relations(&mut self, batches: Vec<RecordBatch>) -> Result<()> {
        for batch in batches {
            self.process_batch(&batch)?;
        }
        Ok(())
    }

    fn process_batch(&mut self, batch: &RecordBatch) -> Result<()> {
        // Use the batch directly as it implements ArrowAccess

        // Get the arrays using the batch directly
        let pnr_array = batch.column(batch.schema().index_of("PNR")?);
        let birth_date_array = batch.column(batch.schema().index_of("BIRTH_DATE")?);
        let father_id_array = batch.column(batch.schema().index_of("FATHER_ID")?);
        let father_birth_date_array = batch.column(batch.schema().index_of("FATHER_BIRTH_DATE")?);
        let mother_id_array = batch.column(batch.schema().index_of("MOTHER_ID")?);
        let mother_birth_date_array = batch.column(batch.schema().index_of("MOTHER_BIRTH_DATE")?);
        let family_id_array = batch.column(batch.schema().index_of("FAMILY_ID")?);

        // Convert arrays to appropriate types
        let pnr_array = pnr_array
            .as_any()
            .downcast_ref::<arrow::array::StringArray>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert PNR array to StringArray".to_string(),
                )
            })?;
        let birth_date_array = birth_date_array
            .as_any()
            .downcast_ref::<arrow::array::Date32Array>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert BIRTH_DATE array to Date32Array".to_string(),
                )
            })?;
        let father_id_array = father_id_array
            .as_any()
            .downcast_ref::<arrow::array::StringArray>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert FATHER_ID array to StringArray".to_string(),
                )
            })?;
        let father_birth_date_array = father_birth_date_array
            .as_any()
            .downcast_ref::<arrow::array::Date32Array>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert FATHER_BIRTH_DATE array to Date32Array".to_string(),
                )
            })?;
        let mother_id_array = mother_id_array
            .as_any()
            .downcast_ref::<arrow::array::StringArray>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert MOTHER_ID array to StringArray".to_string(),
                )
            })?;
        let mother_birth_date_array = mother_birth_date_array
            .as_any()
            .downcast_ref::<arrow::array::Date32Array>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert MOTHER_BIRTH_DATE array to Date32Array".to_string(),
                )
            })?;
        let family_id_array = family_id_array
            .as_any()
            .downcast_ref::<arrow::array::StringArray>()
            .ok_or_else(|| {
                crate::error::IdsError::data_loading(
                    "Failed to convert FAMILY_ID array to StringArray".to_string(),
                )
            })?;

        for i in 0..batch.num_rows() {
            let pnr = pnr_array.value(i).to_string();
            let birth_date = convert_date32_to_naive_date(birth_date_array.value(i))?;

            let relation = FamilyRelations {
                pnr: pnr.clone(),
                birth_date,
                father_id: if father_id_array.is_null(i) {
                    None
                } else {
                    Some(father_id_array.value(i).to_string())
                },
                father_birth_date: if father_birth_date_array.is_null(i) {
                    None
                } else {
                    Some(convert_date32_to_naive_date(
                        father_birth_date_array.value(i),
                    )?)
                },
                mother_id: if mother_id_array.is_null(i) {
                    None
                } else {
                    Some(mother_id_array.value(i).to_string())
                },
                mother_birth_date: if mother_birth_date_array.is_null(i) {
                    None
                } else {
                    Some(convert_date32_to_naive_date(
                        mother_birth_date_array.value(i),
                    )?)
                },
                family_id: if family_id_array.is_null(i) {
                    None
                } else {
                    Some(family_id_array.value(i).to_string())
                },
            };

            self.relations.insert(pnr, relation);
        }
        Ok(())
    }
}
</file>

<file path="src/models/mod.rs">
//! Domain models for epidemiological research data.
//!
//! This module contains the core data structures used to represent
//! various types of data used in epidemiological research, including:
//!
//! - **Covariates**: Variables that may influence outcomes (education, income, etc.)
//! - **Family Relations**: Relationships between individuals
//! - **PNR Data**: Personal identification number handling
//! - **Time-Varying Values**: Values that change over time
//!
//! ## Examples
//!
//! Creating covariates using builders:
//!
//! ```
//! use types::models::{
//!     CovariateType,
//!     EducationBuilder,
//!     DemographicsBuilder,
//! };
//!
//! // Create an education covariate
//! let education = EducationBuilder::new("higher")
//!     .with_years(16.0)
//!     .build();
//!
//! // Create a demographics covariate
//! let demographics = DemographicsBuilder::new(2, 101, "nuclear")
//!     .with_age(42)
//!     .with_gender("M")
//!     .build();
//! ```
//!
//! Working with time-varying values:
//!
//! ```
//! use types::models::{TimeVaryingValue, Covariate};
//! use chrono::NaiveDate;
//!
//! fn process_time_varying(value: TimeVaryingValue<Covariate>) {
//!     println!("PNR: {}", value.pnr);
//!     println!("Start Date: {:?}", value.start_date);
//!     println!("End Date: {:?}", value.end_date);
//!     println!("Value: {:?}", value.value);
//! }
//! ```

// Submodules
pub mod covariate;
pub mod family;
pub mod pnr;
pub mod time_varying;

// Re-exports

/// Covariate models
pub use covariate::{Covariate, CovariateType, CovariateValue, DemographicExtras};

/// Builder types for creating covariates
pub use covariate::builders::{
    DemographicsBuilder, EducationBuilder, IncomeBuilder, OccupationBuilder,
};

/// Time-varying value models
pub use time_varying::TimeVaryingValue;

/// Family relation models
pub use family::FamilyRelations;

/// PNR (personal identification number) models - defined here since they're moved into the models directory
pub struct Pnr(pub String);
pub type PnrPool = hashbrown::HashMap<String, usize>;
pub struct PersonInfo;
pub struct ParentPair;
pub struct FamilyInfo;
</file>

<file path="src/models/pnr.rs">
use crate::error::{IdsError, Result};
use chrono::{Duration, NaiveDate};
use hashbrown::HashMap;
use rand::Rng;

pub type PersonInfo = (NaiveDate, String);
pub type ParentPair = (PersonInfo, PersonInfo);
pub type FamilyInfo = (PersonInfo, ParentPair);

#[derive(Debug)]
pub struct PnrPool {
    pool: HashMap<usize, PersonInfo>,
    children: HashMap<usize, PersonInfo>,
    parents: HashMap<usize, PersonInfo>,
}

impl PnrPool {
    pub fn new<R: Rng>(total_records: usize, rng: &mut R) -> Result<Self> {
        let mut pool = HashMap::new();
        let mut children = HashMap::new();
        let mut parents = HashMap::new();

        // Define study period constants
        let _study_start = NaiveDate::from_ymd_opt(2000, 1, 1)
            .ok_or_else(|| IdsError::invalid_date("Invalid study start date (2000-01-01)"))?;
        let study_end = NaiveDate::from_ymd_opt(2018, 12, 31)
            .ok_or_else(|| IdsError::invalid_date("Invalid study end date (2018-12-31)"))?;
        let earliest_birth = NaiveDate::from_ymd_opt(1995, 1, 1)
            .ok_or_else(|| IdsError::invalid_date("Invalid earliest birth date (1995-01-01)"))?;
        let latest_birth = study_end;

        let birth_range_days = (latest_birth - earliest_birth).num_days() as i32;

        // Generate children first
        for i in 0..total_records {
            // Generate child's birth date within study period
            let days_offset = rng.random_range(0..=birth_range_days);
            let birth_date = earliest_birth + Duration::days(i64::from(days_offset));

            let sequence = rng.random_range(0..10000);
            let pnr = format!("{}-{:04}", birth_date.format("%d%m%y"), sequence);

            children.insert(i, (birth_date, pnr.clone()));
            pool.insert(i, (birth_date, pnr));

            // Generate parents based on child's birth date
            let mother_age = rng.random_range(20..46); // mothers aged 20-45 at birth
            let father_age = rng.random_range(20..50); // fathers aged 20-49 at birth

            let mother_birth = birth_date - Duration::days(mother_age * 365);
            let father_birth = birth_date - Duration::days(father_age * 365);

            let mother_sequence = rng.random_range(0..10000);
            let father_sequence = rng.random_range(0..10000);

            let mother_pnr = format!("{}-{:04}", mother_birth.format("%d%m%y"), mother_sequence);
            let father_pnr = format!("{}-{:04}", father_birth.format("%d%m%y"), father_sequence);

            parents.insert(i + 1_000_000, (father_birth, father_pnr.clone())); // Father
            parents.insert(i + 2_000_000, (mother_birth, mother_pnr.clone())); // Mother

            pool.insert(i + 1_000_000, (father_birth, father_pnr));
            pool.insert(i + 2_000_000, (mother_birth, mother_pnr));
        }

        Ok(Self {
            pool,
            children,
            parents,
        })
    }

    #[must_use]
    pub fn get(&self, index: &usize) -> Option<PersonInfo> {
        self.pool.get(index).map(|(date, pnr)| (*date, pnr.clone()))
    }

    #[must_use]
    pub fn get_child(&self, index: &usize) -> Option<PersonInfo> {
        self.children
            .get(index)
            .map(|(date, pnr)| (*date, pnr.clone()))
    }

    #[must_use]
    pub fn get_parents(&self, index: &usize) -> Option<ParentPair> {
        let father = self.parents.get(&(index + 1_000_000))?;
        let mother = self.parents.get(&(index + 2_000_000))?;
        Some(((father.0, father.1.clone()), (mother.0, mother.1.clone())))
    }

    #[must_use]
    pub fn get_family(&self, index: &usize) -> Option<FamilyInfo> {
        let child = self.get_child(index)?;
        let parents = self.get_parents(index)?;
        Some((child, parents))
    }
}
</file>

<file path="src/models/time_varying.rs">
use chrono::NaiveDate;
use serde::{Deserialize, Serialize};

/// A value that varies over time, associated with a person
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeVaryingValue<T> {
    pub pnr: String,
    pub value: T,
    pub date: NaiveDate,
}

impl<T> TimeVaryingValue<T> {
    /// Create a new time-varying value
    pub fn new(pnr: impl Into<String>, value: T, date: NaiveDate) -> Self {
        Self {
            pnr: pnr.into(),
            value,
            date,
        }
    }
}
</file>

<file path="src/storage/arrow/access.rs">
use arrow::array::{Array, ArrayRef};
use arrow::datatypes::{DataType, SchemaRef};
use arrow::record_batch::RecordBatch;
use std::sync::Arc;

use crate::error::{IdsError, Result};
use crate::storage::arrow::convert::ArrowType;

/// Trait for accessing Arrow data with type safety
///
/// This trait provides a standardized interface for retrieving data from
/// Arrow-based storage with proper type conversion. It handles the details
/// of working with Arrow's data structures and provides a more ergonomic API.
pub trait ArrowAccess {
    /// Get a value from an Arrow column with proper type conversion
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve data from
    /// * `row` - The row index to retrieve
    ///
    /// # Returns
    /// * `Result<T>` - The converted value or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The column does not exist
    /// - The row index is out of bounds
    /// - The value cannot be converted to the requested type
    fn get_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<T>;

    /// Get a value from an Arrow column with optional type conversion
    ///
    /// Similar to `get_value` but returns None for null values instead of an error.
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve data from
    /// * `row` - The row index to retrieve
    ///
    /// # Returns
    /// * `Result<Option<T>>` - The converted value (or None if null) or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The column does not exist
    /// - The row index is out of bounds
    /// - The value cannot be converted to the requested type
    fn get_optional_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<Option<T>>;

    /// Check if a column exists
    ///
    /// # Arguments
    /// * `column` - The column name to check
    ///
    /// # Returns
    /// * `bool` - True if the column exists, false otherwise
    fn has_column(&self, column: &str) -> bool;

    /// Get the number of rows
    ///
    /// # Returns
    /// * `usize` - The number of rows in the record batch
    fn row_count(&self) -> usize;

    /// Get column names
    ///
    /// # Returns
    /// * `Vec<String>` - List of column names in the record batch
    fn column_names(&self) -> Vec<String>;

    /// Get the Arrow schema
    ///
    /// # Returns
    /// * `SchemaRef` - Reference to the Arrow schema
    fn schema(&self) -> SchemaRef;

    /// Get a column by name
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve
    ///
    /// # Returns
    /// * `Result<ArrayRef>` - The column as an Arrow array or an error
    ///
    /// # Errors
    /// Returns an error if the column does not exist
    fn get_column(&self, column: &str) -> Result<ArrayRef>;
}

/// Extension trait for Arrow access with convenience methods
///
/// This trait provides additional utility methods that build on top of
/// the core `ArrowAccess` trait.
pub trait ArrowAccessExt: ArrowAccess {
    /// Get a slice of values from a column
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve data from
    /// * `start` - The starting row index
    /// * `end` - The ending row index (exclusive)
    ///
    /// # Returns
    /// * `Result<Vec<T>>` - The converted values or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The column does not exist
    /// - The row indices are out of bounds
    /// - The values cannot be converted to the requested type
    fn get_values<T: ArrowType>(&self, column: &str, start: usize, end: usize) -> Result<Vec<T>>;

    /// Check if a column is of a specific data type
    ///
    /// # Arguments
    /// * `column` - The column name to check
    /// * `data_type` - The data type to check against
    ///
    /// # Returns
    /// * `bool` - True if the column exists and is of the specified type, false otherwise
    fn is_column_type(&self, column: &str, data_type: &DataType) -> bool;

    /// Get all values from a column
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve data from
    ///
    /// # Returns
    /// * `Result<Vec<T>>` - All values in the column or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The column does not exist
    /// - The values cannot be converted to the requested type
    fn get_all_values<T: ArrowType>(&self, column: &str) -> Result<Vec<T>>;

    /// Get all optional values from a column
    ///
    /// # Arguments
    /// * `column` - The column name to retrieve data from
    ///
    /// # Returns
    /// * `Result<Vec<Option<T>>>` - All values in the column (with nulls as None) or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The column does not exist
    /// - The values cannot be converted to the requested type
    fn get_all_optional_values<T: ArrowType>(&self, column: &str) -> Result<Vec<Option<T>>>;
}

// Implement the extension trait for any type that implements ArrowAccess
impl<T: ArrowAccess> ArrowAccessExt for T {
    fn get_values<U: ArrowType>(&self, column: &str, start: usize, end: usize) -> Result<Vec<U>> {
        let end = end.min(self.row_count());
        if start >= end {
            return Ok(Vec::new());
        }

        let mut values = Vec::with_capacity(end - start);
        for idx in start..end {
            values.push(self.get_value::<U>(column, idx)?);
        }
        Ok(values)
    }

    fn is_column_type(&self, column: &str, data_type: &DataType) -> bool {
        if let Ok(field) = self.schema().field_with_name(column) {
            return field.data_type() == data_type;
        }
        false
    }

    fn get_all_values<U: ArrowType>(&self, column: &str) -> Result<Vec<U>> {
        self.get_values::<U>(column, 0, self.row_count())
    }

    fn get_all_optional_values<U: ArrowType>(&self, column: &str) -> Result<Vec<Option<U>>> {
        let row_count = self.row_count();
        let mut values = Vec::with_capacity(row_count);

        for idx in 0..row_count {
            values.push(self.get_optional_value::<U>(column, idx)?);
        }

        Ok(values)
    }
}

/// Implementation of `ArrowAccess` for `RecordBatch`
impl ArrowAccess for RecordBatch {
    fn get_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<T> {
        let column = self.get_column(column)?;

        if row >= column.len() {
            return Err(IdsError::index_out_of_bounds(format!(
                "Row index {} out of bounds (len: {})",
                row,
                column.len()
            )));
        }

        T::from_array(&column, row).ok_or_else(|| {
            IdsError::type_conversion(format!(
                "Failed to convert value at row {row} to requested type"
            ))
        })
    }

    fn get_optional_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<Option<T>> {
        let column = self.get_column(column)?;

        if row >= column.len() {
            return Err(IdsError::index_out_of_bounds(format!(
                "Row index {} out of bounds (len: {})",
                row,
                column.len()
            )));
        }

        if column.is_null(row) {
            return Ok(None);
        }

        Ok(Some(T::from_array(&column, row).ok_or_else(|| {
            IdsError::type_conversion(format!(
                "Failed to convert value at row {row} in column to requested type"
            ))
        })?))
    }

    fn has_column(&self, column: &str) -> bool {
        self.schema().field_with_name(column).is_ok()
    }

    fn row_count(&self) -> usize {
        self.num_rows()
    }

    fn column_names(&self) -> Vec<String> {
        self.schema()
            .fields()
            .iter()
            .map(|f| f.name().clone())
            .collect()
    }

    fn schema(&self) -> SchemaRef {
        self.schema().clone()
    }

    fn get_column(&self, column: &str) -> Result<ArrayRef> {
        let idx = self
            .schema()
            .index_of(column)
            .map_err(|_| IdsError::column_not_found(format!("Column '{column}' not found")))?;

        Ok(Arc::clone(self.column(idx)))
    }
}

/// Implementation of `ArrowAccess` for `RecordBatch` reference
impl ArrowAccess for &RecordBatch {
    fn get_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<T> {
        (*self).get_value(column, row)
    }

    fn get_optional_value<T: ArrowType>(&self, column: &str, row: usize) -> Result<Option<T>> {
        (*self).get_optional_value(column, row)
    }

    fn has_column(&self, column: &str) -> bool {
        (*self).has_column(column)
    }

    fn row_count(&self) -> usize {
        (*self).row_count()
    }

    fn column_names(&self) -> Vec<String> {
        (*self).column_names()
    }

    fn schema(&self) -> SchemaRef {
        (*self).schema()
    }

    fn get_column(&self, column: &str) -> Result<ArrayRef> {
        (*self).get_column(column)
    }
}

// Re-exports for backward compatibility
pub type ArrowAccessor<'a> = dyn ArrowAccess + 'a;
</file>

<file path="src/storage/arrow/backend.rs">
use arrow::array::{Array, StringArray};
use arrow::record_batch::RecordBatch;
use chrono::NaiveDate;
use hashbrown::HashMap;
use lasso::ThreadedRodeo; // Add string interning support
use log;
use std::path::Path;
use std::sync::Arc;

// Updated imports for new module structure
use crate::{
    error::IdsError,
    family::{FamilyRelations, FamilyStore},
    models::{Covariate, CovariateType, TimeVaryingValue},
    storage::arrow::access::ArrowAccess,
    storage::arrow::convert::ArrowType,
    storage::arrow::utils::ArrowUtils,
    traits::Store,
    translation::TranslationMaps,
};

/// Arrow-based storage backend
#[derive(Debug, Clone)]
pub struct ArrowBackend {
    family_data: HashMap<String, FamilyRelations>,
    akm_data: HashMap<i32, Vec<RecordBatch>>,
    bef_data: HashMap<String, Vec<RecordBatch>>,
    ind_data: HashMap<i32, Vec<RecordBatch>>,
    uddf_data: HashMap<String, Vec<RecordBatch>>,
    translations: TranslationMaps,

    // Performance optimization: Cache for PNR to batch/index mapping
    pnr_index_cache: HashMap<(String, String), (usize, usize)>, // (register_type, pnr) -> (batch_idx, row_idx)

    // Performance optimization: Pre-computed date mapping for periods
    period_date_cache: HashMap<String, NaiveDate>, // period string -> date

    // Performance optimization: String interning for frequently used strings
    string_interner: Arc<ThreadedRodeo>, // Thread-safe string interner

    // Performance optimization: Cache common column indices for hot paths
    column_indices: HashMap<(String, String), usize>, // (register_type, column_name) -> index
}

impl ArrowBackend {
    /// Create a new `ArrowBackend` instance with empty data
    ///
    /// # Returns
    /// * `std::result::Result<Self, IdsError>` - A new `ArrowBackend` or an error
    ///
    /// # Errors
    /// Returns an error if the `TranslationMaps` cannot be initialized
    pub fn new() -> std::result::Result<Self, IdsError> {
        let translations =
            TranslationMaps::new().map_err(|e| IdsError::invalid_format(format!("{e}")))?;

        // Initialize thread-safe string interner with a reasonable capacity
        let string_interner = Arc::new(ThreadedRodeo::default());

        // Pre-intern common strings used in the codebase
        let common_strings = [
            "PNR",
            "HFAUDD",
            "PERINDKIALT_13",
            "DKK",
            "ANTPERSF",
            "KOM",
            "FAMILIE_TYPE",
            "STATSB",
            "akm",
            "bef",
            "ind",
            "uddf",
            "M",
            "F",
            "nuclear",
            "single",
            "married",
            "divorced",
        ];

        for s in common_strings {
            let _ = string_interner.get_or_intern(s);
        }

        Ok(Self {
            family_data: HashMap::new(),
            akm_data: HashMap::new(),
            bef_data: HashMap::new(),
            ind_data: HashMap::new(),
            uddf_data: HashMap::new(),
            translations,
            pnr_index_cache: HashMap::new(),
            period_date_cache: HashMap::new(),
            string_interner,
            column_indices: HashMap::new(),
        })
    }

    /// Create a new empty `ArrowBackend`, used for diagnostic mode when data loading fails
    ///
    /// # Panics
    ///
    /// This function will panic if it fails to create valid dates for the synthetic data.
    /// Since this is only used for diagnostic purposes and uses carefully constructed date values,
    /// the panics would indicate a serious programming error rather than a runtime condition.
    #[must_use]
    pub fn new_empty() -> Self {
        // Create a minimal store for diagnostic operations with some synthetic data for debugging
        let mut family_data = HashMap::new();
        let ind_data = HashMap::new();
        let bef_data = HashMap::new();
        let pnr_index_cache = HashMap::new();
        let mut period_date_cache = HashMap::new();
        let column_indices = HashMap::new();

        // Initialize thread-safe string interner with a reasonable capacity
        let string_interner = Arc::new(ThreadedRodeo::default());

        // Pre-intern common strings that will be used in diagnostic mode
        let common_strings = [
            "PNR",
            "HFAUDD",
            "PERINDKIALT_13",
            "DKK",
            "ANTPERSF",
            "KOM",
            "FAMILIE_TYPE",
            "STATSB",
            "akm",
            "bef",
            "ind",
            "uddf",
            "M",
            "F",
            "nuclear",
            "single",
            "married",
            "divorced",
        ];

        for s in common_strings {
            let _ = string_interner.get_or_intern(s);
        }

        // Add synthetic relationships and data for debugging in diagnostic mode
        for i in 0..100 {
            // Add some synthetic family data for diagnostic purposes
            let case_id = format!("C{i:06}");
            let control_id = format!("K{i:06}");

            // Calculate valid date components with safe ranges
            let year = 1990 + (i % 30);
            let month = 1 + (i % 12) as u32;
            let day = 1 + (i % 28) as u32; // Always  28 to avoid invalid dates

            let father_year = 1950 + (i % 30);
            let mother_year = 1955 + (i % 30);

            // Get a birth date based on the index - these are constructed to always be valid
            // We explicitly document the panics here since this is diagnostic code only
            let birth_date = chrono::NaiveDate::from_ymd_opt(year, month, day)
                .expect("Invalid synthetic birth date constructed in diagnostic mode");

            let father_birth_date = chrono::NaiveDate::from_ymd_opt(father_year, month, day)
                .expect("Invalid synthetic father birth date constructed in diagnostic mode");

            let mother_birth_date = chrono::NaiveDate::from_ymd_opt(mother_year, month, day)
                .expect("Invalid synthetic mother birth date constructed in diagnostic mode");

            // Create interned strings for IDs to reduce allocations
            let father_id = format!("F{i:06}");
            let mother_id = format!("M{i:06}");
            let family_id = format!("FAM{i:06}");
            let control_father_id = format!("F{:06}", i + 1000);
            let control_mother_id = format!("M{:06}", i + 1000);
            let control_family_id = format!("FAM{:06}", i + 1000);

            // Intern all the strings
            string_interner.get_or_intern(&father_id);
            string_interner.get_or_intern(&mother_id);
            string_interner.get_or_intern(&family_id);
            string_interner.get_or_intern(&control_father_id);
            string_interner.get_or_intern(&control_mother_id);
            string_interner.get_or_intern(&control_family_id);

            // Add family relations for cases and controls
            family_data.insert(
                case_id.clone(),
                FamilyRelations {
                    pnr: case_id.clone(),
                    birth_date,
                    father_id: Some(father_id.clone()),
                    father_birth_date: Some(father_birth_date),
                    mother_id: Some(mother_id.clone()),
                    mother_birth_date: Some(mother_birth_date),
                    family_id: Some(family_id.clone()),
                },
            );

            family_data.insert(
                control_id.clone(),
                FamilyRelations {
                    pnr: control_id.clone(),
                    birth_date,
                    father_id: Some(control_father_id.clone()),
                    father_birth_date: Some(father_birth_date),
                    mother_id: Some(control_mother_id.clone()),
                    mother_birth_date: Some(mother_birth_date),
                    family_id: Some(control_family_id.clone()),
                },
            );
        }

        // Pre-compute some period date mappings for common periods
        for year in 2000..2024 {
            // Add annual periods
            let period = format!("{year}");
            let date = NaiveDate::from_ymd_opt(year, 12, 31)
                .expect("Invalid date in new_empty period initialization");
            period_date_cache.insert(period, date);

            // Add quarterly periods
            for quarter in 1..=4 {
                let month = quarter * 3;
                let period = format!("{year}{month:02}");
                let date = NaiveDate::from_ymd_opt(year, month as u32, 1)
                    .expect("Invalid date in new_empty period initialization");
                period_date_cache.insert(period, date);
            }
        }

        Self {
            family_data,
            akm_data: HashMap::new(),
            bef_data,
            ind_data,
            uddf_data: HashMap::new(),
            translations: TranslationMaps::new_empty(),
            pnr_index_cache,
            period_date_cache,
            string_interner,
            column_indices,
        }
    }

    /// Cache column indices for a specific register and batch
    ///
    /// This method builds a cache of column indices for faster lookup
    /// of common columns in hot paths.
    ///
    /// # Arguments
    /// * `register_type` - The register type (e.g., "akm", "bef")
    /// * `batch` - A representative batch to extract schema from
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if column lookup fails
    fn cache_column_indices(
        &mut self,
        register_type: &str,
        batch: &RecordBatch,
    ) -> std::result::Result<(), IdsError> {
        // Common column names to cache for each register type
        let columns_to_cache = match register_type {
            "akm" => vec!["PNR", "JOBKODE", "LPR"],
            "bef" => vec!["PNR", "ANTPERSF", "KOM", "FAMILIE_TYPE", "STATSB"],
            "ind" => vec!["PNR", "PERINDKIALT_13"],
            "uddf" => vec!["PNR", "HFAUDD"],
            _ => vec!["PNR"],
        };

        // Cache each column index
        let schema = batch.schema();
        for col in columns_to_cache {
            // Use original string for index lookup
            if let Ok(idx) = schema.index_of(col) {
                // Store in cache
                self.column_indices
                    .insert((register_type.to_string(), col.to_string()), idx);

                // Also intern the string for future use
                self.string_interner.get_or_intern(col);
            }
        }

        Ok(())
    }

    /// Add AKM (labor market) data to the backend
    ///
    /// This method adds AKM data for a specific year and builds index caches
    /// for optimized access.
    ///
    /// # Arguments
    /// * `year` - The year for the data
    /// * `batches` - The record batches containing AKM data
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if batch validation fails
    pub fn add_akm_data(
        &mut self,
        year: i32,
        mut batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid AKM batch for year {year}: {e}");
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        // Cache column indices for faster access if batches aren't empty
        if !batches.is_empty() {
            self.cache_column_indices("akm", &batches[0])?;
        }

        // Build PNR index cache for faster lookups
        self.build_pnr_index_cache("akm", &batches)?;

        // Store the batches
        self.akm_data.insert(year, batches);
        Ok(())
    }

    /// Build PNR index cache for a specific register type and batch set
    ///
    /// This method builds an index cache that maps PNRs to batch and row indices
    /// for faster lookup operations.
    ///
    /// # Arguments
    /// * `register_type` - The type of register ("akm", "bef", etc.)
    /// * `batches` - The record batches to index
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if the PNR column cannot be found or accessed
    fn build_pnr_index_cache(
        &mut self,
        register_type: &str,
        batches: &[RecordBatch],
    ) -> std::result::Result<(), IdsError> {
        for (batch_idx, batch) in batches.iter().enumerate() {
            // Skip if the batch doesn't have a PNR column
            if !batch.schema().fields().iter().any(|f| f.name() == "PNR") {
                continue;
            }

            let pnr_idx = batch.schema().index_of("PNR")?;
            let pnr_array = batch.column(pnr_idx);

            if let Some(string_array) = pnr_array.as_any().downcast_ref::<StringArray>() {
                for row_idx in 0..string_array.len() {
                    if !string_array.is_null(row_idx) {
                        let pnr = string_array.value(row_idx).to_string();
                        // Store the mapping: (register_type, pnr) -> (batch_idx, row_idx)
                        self.pnr_index_cache
                            .insert((register_type.to_string(), pnr), (batch_idx, row_idx));
                    }
                }
            }
        }

        Ok(())
    }

    /// Add BEF (population) data to the backend
    ///
    /// This method adds BEF data for a specific period and builds index caches
    /// for optimized access.
    ///
    /// # Arguments
    /// * `period` - The period for the data (e.g., "201903")
    /// * `batches` - The record batches containing BEF data
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if batch validation fails
    pub fn add_bef_data(
        &mut self,
        period: String,
        mut batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid BEF batch for period {period}: {e}");
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        // Cache column indices for faster access if batches aren't empty
        if !batches.is_empty() {
            self.cache_column_indices("bef", &batches[0])?;
        }

        // Build PNR index cache for faster lookups
        self.build_pnr_index_cache("bef", &batches)?;

        // Pre-compute period date for faster period lookups
        self.add_period_to_cache(&period)?;

        // Intern the period for future use
        self.string_interner.get_or_intern(&period);
        self.bef_data.insert(period, batches);
        Ok(())
    }

    /// Add IND (income) data to the backend
    ///
    /// This method adds IND data for a specific year and builds index caches
    /// for optimized access.
    ///
    /// # Arguments
    /// * `year` - The year for the data
    /// * `batches` - The record batches containing IND data
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if batch validation fails
    pub fn add_ind_data(
        &mut self,
        year: i32,
        mut batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid IND batch for year {year}: {e}");
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        // Cache column indices for faster access if batches aren't empty
        if !batches.is_empty() {
            self.cache_column_indices("ind", &batches[0])?;
        }

        // Build PNR index cache for faster lookups
        self.build_pnr_index_cache("ind", &batches)?;

        self.ind_data.insert(year, batches);
        Ok(())
    }

    /// Add UDDF (education) data to the backend
    ///
    /// This method adds UDDF data for a specific period and builds index caches
    /// for optimized access.
    ///
    /// # Arguments
    /// * `period` - The period for the data (e.g., "201903")
    /// * `batches` - The record batches containing UDDF data
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if batch validation fails
    pub fn add_uddf_data(
        &mut self,
        period: String,
        mut batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid UDDF batch for period {period}: {e}");
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        // Cache column indices for faster access if batches aren't empty
        if !batches.is_empty() {
            self.cache_column_indices("uddf", &batches[0])?;
        }

        // Build PNR index cache for faster lookups
        self.build_pnr_index_cache("uddf", &batches)?;

        // Pre-compute period date for faster period lookups
        self.add_period_to_cache(&period)?;

        // Intern the period for future use
        self.string_interner.get_or_intern(&period);
        self.uddf_data.insert(period, batches);
        Ok(())
    }

    /// Add a period to the date cache for faster lookups
    ///
    /// This method parses a period string like "201903" and adds a mapping
    /// to the corresponding `NaiveDate`.
    ///
    /// # Arguments
    /// * `period` - The period string (e.g., "201903")
    ///
    /// # Returns
    /// * `std::result::Result<(), IdsError>` - Success or an error
    ///
    /// # Errors
    /// Returns an error if the period cannot be parsed into a valid date
    fn add_period_to_cache(&mut self, period: &str) -> std::result::Result<(), IdsError> {
        // Skip if period is already in cache
        if self.period_date_cache.contains_key(period) {
            return Ok(());
        }

        // Handle special cases like 'current' or directory names that might contain non-numeric characters
        if period == "current" {
            // Use current date for 'current' period
            use chrono::Utc;
            let today = Utc::now().naive_utc().date();
            self.period_date_cache.insert(period.to_string(), today);
            return Ok(());
        }

        // Extract numeric part from the period (to handle paths like 'bef/202012' or file extensions)
        let period_clean = period
            .chars()
            .filter(|c| c.is_numeric())
            .collect::<String>();

        // Try to parse as a full period string (YYYYMM)
        if period_clean.len() >= 6 {
            let year_str = &period_clean[0..4];
            let month_str = &period_clean[4..6];

            if let (Ok(year), Ok(month)) = (year_str.parse::<i32>(), month_str.parse::<u32>()) {
                if month > 0 && month <= 12 {
                    if let Some(date) = NaiveDate::from_ymd_opt(year, month, 1) {
                        self.period_date_cache.insert(period.to_string(), date);
                        return Ok(());
                    }
                }
            }
        }

        // Try to parse as just a year (YYYY)
        if period_clean.len() >= 4 {
            let year_str = &period_clean[0..4];

            if let Ok(year) = year_str.parse::<i32>() {
                if let Some(date) = NaiveDate::from_ymd_opt(year, 12, 31) {
                    self.period_date_cache.insert(period.to_string(), date);
                    return Ok(());
                }
            }
        }

        // Handle directory paths by extracting last component
        let path = Path::new(period);
        if let Some(file_name) = path.file_name() {
            if let Some(file_str) = file_name.to_str() {
                // Try again with just the file name
                if file_str != period {
                    return self.add_period_to_cache(file_str);
                }
            }
        }

        // If we get here, resort to a default date to avoid errors
        log::warn!(
            "Could not parse period '{period}', using a default date (2020-01-01)"
        );
        let default_date = NaiveDate::from_ymd_opt(2020, 1, 1).unwrap();
        self.period_date_cache
            .insert(period.to_string(), default_date);
        Ok(())
    }

    /// Add family data to the backend
    pub fn add_family_data(
        &mut self,
        batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Load family relations using existing implementation
        self.load_family_relations(batches)
    }

    /// Get education covariate for a PNR at a given date
    ///
    /// # Arguments
    /// * `pnr` - The person identification number
    /// * `date` - The reference date
    ///
    /// # Returns
    /// * `std::result::Result<Option<Covariate>, IdsError>` - Education covariate or None
    ///
    /// # Errors
    /// Returns an error if data access fails
    fn get_education(
        &mut self,
        pnr: &str,
        date: NaiveDate,
    ) -> std::result::Result<Option<Covariate>, IdsError> {
        // Get a temporary copy of the uddf_data keys to avoid borrowing self twice
        let period_keys: Vec<String> = self.uddf_data.keys().cloned().collect();
        let period_map: HashMap<String, Vec<RecordBatch>> = period_keys
            .iter()
            .filter_map(|k| self.uddf_data.get(k).map(|v| (k.clone(), v.clone())))
            .collect();

        // Find the closest period
        let period = self.find_closest_period(date, &period_map)?;

        if let Some(period_str) = period {
            if let Some(batches) = self.uddf_data.get(period_str) {
                // Search through batches with the cached index if available
                for (batch_idx, batch) in batches.iter().enumerate() {
                    // Use optimized PNR index lookup with cache
                    if let Some(idx) =
                        self.find_pnr_index_with_cache(batch, pnr, "uddf", batch_idx)?
                    {
                        // Get string array for education level
                        let hfaudd_array = self.get_string_array(batch, "HFAUDD")?;

                        if !hfaudd_array.is_null(idx) {
                            let level = hfaudd_array.value(idx).to_string();
                            return Ok(Some(Covariate::education(level).build()));
                        }
                    }
                }
            }
        }
        Ok(None)
    }

    /// Get income covariate for a PNR at a given date
    ///
    /// # Arguments
    /// * `pnr` - The person identification number
    /// * `date` - The reference date
    ///
    /// # Returns
    /// * `std::result::Result<Option<Covariate>, IdsError>` - Income covariate or None
    ///
    /// # Errors
    /// Returns an error if data access fails
    fn get_income(
        &self,
        pnr: &str,
        date: NaiveDate,
    ) -> std::result::Result<Option<Covariate>, IdsError> {
        use chrono::Datelike;
        let year = date.year();
        if let Some(batches) = self.ind_data.get(&year) {
            // Search through batches with the cached index if available
            for (batch_idx, batch) in batches.iter().enumerate() {
                // Use optimized PNR index lookup with cache
                if let Some(idx) = self.find_pnr_index_with_cache(batch, pnr, "ind", batch_idx)? {
                    // Get income column directly
                    let col_idx = batch.schema().index_of("PERINDKIALT_13")?;
                    let column = batch.column(col_idx);

                    let array = column
                        .as_any()
                        .downcast_ref::<arrow::array::Float64Array>()
                        .ok_or_else(|| {
                            IdsError::data_loading("Income column not a float array".to_string())
                        })?;
                    let amount = if array.is_null(idx) {
                        None
                    } else {
                        Some(array.value(idx))
                    };
                    if let Some(amount) = amount {
                        return Ok(Some(
                            Covariate::income(amount, "DKK", "PERINDKIALT_13").build(),
                        ));
                    }
                }
            }
        }
        Ok(None)
    }

    /// Get occupation covariate for a PNR at a given date
    ///
    /// # Arguments
    /// * `pnr` - The person identification number
    /// * `date` - The reference date
    ///
    /// # Returns
    /// * `std::result::Result<Option<Covariate>, IdsError>` - Occupation covariate or None
    ///
    /// # Errors
    /// Returns an error if data access fails
    fn get_occupation(
        &mut self,
        pnr: &str,
        date: NaiveDate,
    ) -> std::result::Result<Option<Covariate>, IdsError> {
        use chrono::Datelike;
        let year = date.year();

        if let Some(batches) = self.akm_data.get(&year) {
            // Search through batches with the cached index if available
            for (batch_idx, batch) in batches.iter().enumerate() {
                // Use optimized PNR index lookup with cache
                if let Some(idx) = self.find_pnr_index_with_cache(batch, pnr, "akm", batch_idx)? {
                    // Access occupation-related fields
                    let schema = batch.schema();

                    // Default values in case columns are missing
                    let mut socio: Option<i32> = None;
                    let mut socio02: Option<i32> = None;
                    let mut socio13: Option<i32> = None;
                    let mut pre_socio: Option<i32> = None;

                    // Get SOCIO column if it exists
                    if let Ok(col_idx) = schema.index_of("SOCIO") {
                        let column = batch.column(col_idx);
                        if let Some(array) =
                            column.as_any().downcast_ref::<arrow::array::Int32Array>()
                        {
                            if !array.is_null(idx) {
                                socio = Some(array.value(idx));
                            }
                        }
                    }

                    // Get SOCIO02 column if it exists
                    if let Ok(col_idx) = schema.index_of("SOCIO02") {
                        let column = batch.column(col_idx);
                        if let Some(array) =
                            column.as_any().downcast_ref::<arrow::array::Int32Array>()
                        {
                            if !array.is_null(idx) {
                                socio02 = Some(array.value(idx));
                            }
                        }
                    }

                    // Get SOCIO13 column if it exists
                    if let Ok(col_idx) = schema.index_of("SOCIO13") {
                        let column = batch.column(col_idx);
                        if let Some(array) =
                            column.as_any().downcast_ref::<arrow::array::Int32Array>()
                        {
                            if !array.is_null(idx) {
                                socio13 = Some(array.value(idx));
                            }
                        }
                    }

                    // Get PRE_SOCIO column if it exists
                    if let Ok(col_idx) = schema.index_of("PRE_SOCIO") {
                        let column = batch.column(col_idx);
                        if let Some(array) =
                            column.as_any().downcast_ref::<arrow::array::Int32Array>()
                        {
                            if !array.is_null(idx) {
                                pre_socio = Some(array.value(idx));
                            }
                        }
                    }

                    // If any SOCIO categorization is available, build the occupation covariate
                    if socio.is_some()
                        || socio02.is_some()
                        || socio13.is_some()
                        || pre_socio.is_some()
                    {
                        // We need both code and classification for occupation
                        let classification = "SOCIO"; // Default classification
                        let code = socio13
                            .map(|s| s.to_string())
                            .or_else(|| socio.map(|s| s.to_string()))
                            .or_else(|| socio02.map(|s| s.to_string()))
                            .unwrap_or_else(|| "0".to_string());

                        let mut builder = Covariate::occupation(code, classification);

                        // Add socio values to builder
                        if let Some(val) = socio {
                            builder = builder.with_socio(val);

                            // Add metadata directly since we don't have a Socio translation type
                            builder = builder.with_metadata("socio_value", val.to_string());
                        }

                        if let Some(val) = socio02 {
                            builder = builder.with_socio02(val);

                            // Add metadata directly
                            builder = builder.with_metadata("socio02_value", val.to_string());
                        }

                        if let Some(val) = socio13 {
                            // Add translated value to metadata if available
                            if let Some(translated) = self.translations.translate(
                                crate::translation::TranslationType::Socio13,
                                &val.to_string(),
                            ) {
                                builder = builder.with_metadata("socio13_category", translated);
                            }

                            // Also store the raw value
                            builder = builder.with_metadata("socio13_value", val.to_string());
                        }

                        if let Some(val) = pre_socio {
                            builder = builder.with_pre_socio(val);

                            // Add metadata directly
                            builder = builder.with_metadata("pre_socio_value", val.to_string());
                        }

                        return Ok(Some(builder.build()));
                    }
                }
            }
        }

        Ok(None)
    }

    /// Get demographics covariate for a PNR at a given date
    ///
    /// # Arguments
    /// * `pnr` - The person identification number
    /// * `date` - The reference date
    ///
    /// # Returns
    /// * `std::result::Result<Option<Covariate>, IdsError>` - Demographics covariate or None
    ///
    /// # Errors
    /// Returns an error if data access fails
    fn get_demographics(
        &mut self,
        pnr: &str,
        date: NaiveDate,
    ) -> std::result::Result<Option<Covariate>, IdsError> {
        // Get a temporary copy of the bef_data keys to avoid borrowing self twice
        let period_keys: Vec<String> = self.bef_data.keys().cloned().collect();
        let period_map: HashMap<String, Vec<RecordBatch>> = period_keys
            .iter()
            .filter_map(|k| self.bef_data.get(k).map(|v| (k.clone(), v.clone())))
            .collect();

        // Find the closest period
        let period = self.find_closest_period(date, &period_map)?;

        if let Some(period_str) = period {
            if let Some(batches) = self.bef_data.get(period_str) {
                // Fetch cached column indices
                let family_size_key = ("bef".to_string(), "ANTPERSF".to_string());
                let kom_key = ("bef".to_string(), "KOM".to_string());
                let family_type_key = ("bef".to_string(), "FAMILIE_TYPE".to_string());
                let statsb_key = ("bef".to_string(), "STATSB".to_string());

                // Search through batches with the cached index if available
                for (batch_idx, batch) in batches.iter().enumerate() {
                    // Use optimized PNR index lookup with cache
                    if let Some(idx) =
                        self.find_pnr_index_with_cache(batch, pnr, "bef", batch_idx)?
                    {
                        // Get column indices from cache when available for hot paths
                        let family_size_idx =
                            if let Some(&idx) = self.column_indices.get(&family_size_key) {
                                idx
                            } else {
                                batch.schema().index_of("ANTPERSF")?
                            };

                        let kom_idx = if let Some(&idx) = self.column_indices.get(&kom_key) {
                            idx
                        } else {
                            batch.schema().index_of("KOM")?
                        };

                        let family_type_idx =
                            if let Some(&idx) = self.column_indices.get(&family_type_key) {
                                idx
                            } else {
                                batch.schema().index_of("FAMILIE_TYPE")?
                            };

                        let statsb_idx = if let Some(&idx) = self.column_indices.get(&statsb_key) {
                            idx
                        } else {
                            batch.schema().index_of("STATSB")?
                        };

                        // Get columns directly with efficient index access
                        let family_size_col = batch.column(family_size_idx);
                        let kom_col = batch.column(kom_idx);
                        let family_col = batch.column(family_type_idx);
                        let statsb_col = batch.column(statsb_idx);

                        // Extract values with optimized null checking
                        let family_size: Option<i32> = if family_size_col.is_null(idx) {
                            None
                        } else {
                            let array = family_size_col
                                .as_any()
                                .downcast_ref::<arrow::array::Int32Array>()
                                .ok_or_else(|| {
                                    IdsError::data_loading(
                                        "ANTPERSF not an int32 array".to_string(),
                                    )
                                })?;
                            Some(array.value(idx))
                        };

                        let municipality: Option<i32> = if kom_col.is_null(idx) {
                            None
                        } else {
                            let array = kom_col
                                .as_any()
                                .downcast_ref::<arrow::array::Int32Array>()
                                .ok_or_else(|| {
                                    IdsError::data_loading("KOM not an int32 array".to_string())
                                })?;
                            Some(array.value(idx))
                        };

                        let family_type: Option<i32> = if family_col.is_null(idx) {
                            None
                        } else {
                            let array = family_col
                                .as_any()
                                .downcast_ref::<arrow::array::Int32Array>()
                                .ok_or_else(|| {
                                    IdsError::data_loading(
                                        "FAMILIE_TYPE not an int32 array".to_string(),
                                    )
                                })?;
                            Some(array.value(idx))
                        };

                        let statsb: Option<String> = if statsb_col.is_null(idx) {
                            None
                        } else {
                            let array = statsb_col
                                .as_any()
                                .downcast_ref::<arrow::array::StringArray>()
                                .ok_or_else(|| {
                                    IdsError::data_loading("STATSB not a string array".to_string())
                                })?;

                            // Use string interning for frequently repeated values
                            let value = array.value(idx);
                            // Intern the string but return the original value
                            self.string_interner.get_or_intern(value);
                            Some(value.to_string())
                        };

                        // If at least family_size is available, we can build a demographics covariate
                        if let Some(family_size) = family_size {
                            // Pre-allocate builder to reduce allocations
                            let mut builder = Covariate::demographics(
                                family_size,
                                municipality.unwrap_or(0),
                                family_type.map_or_else(|| "0".to_string(), |ft| ft.to_string()),
                            );

                            // Add citizenship if available
                            if let Some(statsb) = statsb {
                                // Pass string directly from string interner
                                builder = builder.with_citizenship(statsb.clone());

                                // Add translated value to metadata if available
                                if let Some(translated) = self
                                    .translations
                                    .translate(crate::translation::TranslationType::Statsb, &statsb)
                                {
                                    builder =
                                        builder.with_metadata("statsb_translated", translated);
                                }
                            }

                            return Ok(Some(builder.build()));
                        }
                    }
                }
            }
        }
        Ok(None)
    }

    /// Optimize batch operations by slicing when needed
    pub fn optimize_batch(&mut self, batch: &mut RecordBatch) -> std::result::Result<(), IdsError> {
        // Align buffers for better memory performance
        let _ = ArrowUtils::align_batch_buffers(batch);
        Ok(())
    }

    /// Slice a batch for zero-copy operations
    pub fn slice_batch(
        &self,
        batch: &RecordBatch,
        offset: usize,
        length: usize,
    ) -> std::result::Result<RecordBatch, IdsError> {
        let mut columns = Vec::with_capacity(batch.num_columns());

        for i in 0..batch.num_columns() {
            columns.push(ArrowUtils::slice_array(
                batch.column(i).as_ref(),
                offset,
                length,
            ));
        }

        RecordBatch::try_new(batch.schema(), columns)
            .map_err(|e| IdsError::invalid_operation(format!("Failed to create sliced batch: {e}")))
    }

    /// Create an optimized string array
    pub fn create_optimized_string_array(
        &self,
        strings: &[String],
    ) -> std::result::Result<StringArray, IdsError> {
        ArrowUtils::create_optimized_string_array(strings, strings.len())
    }

    /// Find the closest period for a date
    ///
    /// This method finds the most specific period (e.g., "202303" over "2023")
    /// that is before or equal to the target date.
    ///
    /// # Arguments
    /// * `date` - The target date
    /// * `data` - The data map to search in
    ///
    /// # Returns
    /// * `std::result::Result<Option<&'a String>, IdsError>` - The closest period or None
    ///
    /// # Errors
    /// Returns an error if period date conversion fails
    fn find_closest_period<'a>(
        &mut self,
        date: NaiveDate,
        data: &'a HashMap<String, Vec<RecordBatch>>,
    ) -> std::result::Result<Option<&'a String>, IdsError> {
        // Check if data is empty
        if data.is_empty() {
            return Ok(None);
        }

        // Special fast path - if there's only one period, just use it
        if data.len() == 1 {
            let key = data.keys().next().unwrap();
            // Still add it to the cache if needed
            let _ = self.add_period_to_cache(key);
            return Ok(Some(key));
        }

        // Track the closest period we've found
        let mut closest_period: Option<&String> = None;
        let mut closest_date: Option<NaiveDate> = None;

        // Fast path - use our cache for date comparisons
        for period in data.keys() {
            // Get the period date from cache or compute it
            let period_date = if let Some(cached_date) = self.period_date_cache.get(period) {
                *cached_date
            } else {
                // Add to cache and get it back
                if let Err(e) = self.add_period_to_cache(period) {
                    log::warn!("Failed to parse period '{period}': {e}");
                    continue; // Skip this period
                }

                // Now it should be in the cache
                if let Some(date) = self.period_date_cache.get(period) { *date } else {
                    log::warn!("Period '{period}' not found in cache after adding");
                    continue; // Skip this period
                }
            };

            // Only consider periods before or equal to the target date
            // If we can't find any periods before the target date, we'll
            // end up using the most recent period available
            if period_date <= date || closest_date.is_none() {
                // First period or a more recent period than what we've found so far
                if closest_date.is_none() || period_date > closest_date.unwrap() {
                    closest_date = Some(period_date);
                    closest_period = Some(period);
                } else if period_date == closest_date.unwrap() {
                    // For equal dates, prefer the more specific period (longer string)
                    if period.len() > closest_period.unwrap().len() {
                        closest_period = Some(period);
                    }
                }
            }
        }

        // If we couldn't find a suitable period (all periods are after the target date),
        // use the earliest available period
        if closest_period.is_none() && !data.is_empty() {
            let mut earliest_period: Option<&String> = None;
            let mut earliest_date: Option<NaiveDate> = None;

            for period in data.keys() {
                let period_date = if let Some(cached_date) = self.period_date_cache.get(period) {
                    *cached_date
                } else {
                    continue; // Skip if not in cache
                };

                if earliest_date.is_none() || period_date < earliest_date.unwrap() {
                    earliest_date = Some(period_date);
                    earliest_period = Some(period);
                }
            }

            closest_period = earliest_period;
        }

        Ok(closest_period)
    }

    pub fn load_family_relations(
        &mut self,
        mut family_batches: Vec<RecordBatch>,
    ) -> std::result::Result<(), IdsError> {
        // Optimize batches before loading
        for batch in &mut family_batches {
            // Validate batch
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid family relations batch: {e}");
            }

            // Optimize memory layout
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        let mut family_store = FamilyStore::new();
        family_store.load_family_relations(family_batches)?;
        self.family_data = family_store.get_relations().clone();
        Ok(())
    }
}

impl Store for ArrowBackend {
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> std::result::Result<Option<Covariate>, IdsError> {
        match covariate_type {
            CovariateType::Education => self.get_education(pnr, date),
            CovariateType::Income => self.get_income(pnr, date),
            CovariateType::Demographics => self.get_demographics(pnr, date),
            CovariateType::Occupation => self.get_occupation(pnr, date),
        }
    }

    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations> {
        self.family_data.get(pnr)
    }

    fn load_data(
        &mut self,
        _data: Vec<TimeVaryingValue<Covariate>>,
    ) -> std::result::Result<(), IdsError> {
        Err(IdsError::invalid_operation(
            "Cannot load time-varying data into Arrow store",
        ))
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn as_any_mut(&mut self) -> &mut dyn std::any::Any {
        self
    }
}

// Helper methods for data access and optimization
impl ArrowBackend {
    /// Find the index of a PNR in a batch using cached indices when available
    ///
    /// This method first checks the PNR index cache before falling back to a linear scan
    /// of the batch. The cache provides O(1) lookups for previously indexed PNRs.
    ///
    /// # Arguments
    /// * `batch` - The record batch to search in
    /// * `pnr` - The PNR to find
    /// * `register_type` - Optional register type for cache lookup
    ///
    /// # Returns
    /// * `std::result::Result<Option<usize>, IdsError>` - The found index or None
    ///
    /// # Errors
    /// Returns an error if the PNR column cannot be accessed
    fn find_pnr_index_with_cache(
        &self,
        batch: &RecordBatch,
        pnr: &str,
        register_type: &str,
        batch_idx: usize,
    ) -> std::result::Result<Option<usize>, IdsError> {
        // First check if we have this PNR in our index cache
        if let Some(&(cached_batch_idx, row_idx)) = self
            .pnr_index_cache
            .get(&(register_type.to_string(), pnr.to_string()))
        {
            // Only use cache if the batch index matches
            if cached_batch_idx == batch_idx {
                return Ok(Some(row_idx));
            }
        }

        // Fall back to standard search if not found in cache
        self.find_pnr_index(batch, pnr)
    }

    /// Find the index of a PNR in a batch
    ///
    /// This is the basic implementation without using the cache.
    ///
    /// # Arguments
    /// * `batch` - The record batch to search in
    /// * `pnr` - The PNR to find
    ///
    /// # Returns
    /// * `std::result::Result<Option<usize>, IdsError>` - The found index or None
    ///
    /// # Errors
    /// Returns an error if the PNR column cannot be accessed
    fn find_pnr_index(
        &self,
        batch: &RecordBatch,
        pnr: &str,
    ) -> std::result::Result<Option<usize>, IdsError> {
        // Use cached column index for PNR if available
        let pnr_idx = if let Some(&idx) = self
            .column_indices
            .get(&(String::new(), "PNR".to_string()))
        {
            idx
        } else if batch.schema().fields().iter().any(|f| f.name() == "PNR") {
            batch.schema().index_of("PNR")?
        } else {
            return Ok(None);
        };

        let pnr_array = batch.column(pnr_idx);

        // Intern commonly looked up PNRs
        self.string_interner.get_or_intern(pnr);

        if let Some(string_array) = pnr_array.as_any().downcast_ref::<StringArray>() {
            // Use binary search if the array is large (>1000 elements)
            let len = string_array.len();
            if len > 1000 {
                // Create a partial index for faster search by dividing into chunks
                let chunk_size = (len as f64).sqrt() as usize; // Square root of length for optimal chunk size
                let mut i = 0;
                while i < len {
                    let end = (i + chunk_size).min(len);
                    // Check first and last elements of chunk to see if we should search it
                    if !string_array.is_null(i) && !string_array.is_null(end - 1) {
                        let first = string_array.value(i);
                        let last = string_array.value(end - 1);

                        // Only search this chunk if the PNR might be in it (lexicographically between first and last)
                        if (pnr >= first && pnr <= last) ||
                           // Special case for chunks that wrap around lexicographically
                           (first > last && (pnr >= first || pnr <= last))
                        {
                            // Linear search within this smaller chunk
                            for j in i..end {
                                if !string_array.is_null(j) {
                                    // Use direct string comparison as it's more efficient for small chunks
                                    if string_array.value(j) == pnr {
                                        // Intern the found PNR for future lookups
                                        self.string_interner.get_or_intern(pnr);
                                        return Ok(Some(j));
                                    }
                                }
                            }
                        }
                    }
                    i += chunk_size;
                }

                // Not found in any chunk
                return Ok(None);
            }
            // Linear scan for small arrays
            for i in 0..string_array.len() {
                if !string_array.is_null(i) {
                    // Use direct string comparison for small arrays
                    if string_array.value(i) == pnr {
                        // Intern the found PNR for future lookups
                        self.string_interner.get_or_intern(pnr);
                        return Ok(Some(i));
                    }
                }
            }
        }

        Ok(None)
    }

    // Helper method to get a string array from a column using the cache when available
    fn get_string_array<'a>(
        &self,
        batch: &'a RecordBatch,
        column_name: &str,
    ) -> std::result::Result<&'a StringArray, IdsError> {
        // First check if we have the column index in our cache
        let register_type = if column_name == "HFAUDD" {
            "uddf"
        } else if column_name == "PERINDKIALT_13" {
            "ind"
        } else if ["ANTPERSF", "KOM", "FAMILIE_TYPE", "STATSB"].contains(&column_name) {
            "bef"
        } else if ["JOBKODE", "LPR"].contains(&column_name) {
            "akm"
        } else {
            "" // Unknown register type
        };

        let col_idx = if register_type.is_empty() {
            // Direct schema lookup for non-cached columns
            batch.schema().index_of(column_name)?
        } else {
            // Try to get from cache first
            if let Some(&idx) = self
                .column_indices
                .get(&(register_type.to_string(), column_name.to_string()))
            {
                idx
            } else {
                // Fall back to schema lookup
                batch.schema().index_of(column_name)?
            }
        };

        let array = batch.column(col_idx);

        array
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(move || {
                IdsError::data_loading(format!("Column {column_name} is not a string array"))
            })
    }

    fn validate_batch(&self, batch: &RecordBatch) -> std::result::Result<(), IdsError> {
        // Implementation to validate batch structure
        if batch.num_rows() == 0 {
            return Err(IdsError::data_loading("Empty batch".to_string()));
        }

        Ok(())
    }

    /// Run benchmarks and collect performance metrics
    ///
    /// This function executes a set of microbenchmarks to measure the performance
    /// of critical operations and returns the results as a map of operation names
    /// to durations in nanoseconds.
    ///
    /// # Returns
    /// * `HashMap<String, u128>` - Map of operation names to durations in nanoseconds
    #[cfg(test)]
    #[must_use] pub fn run_performance_benchmarks(&self) -> HashMap<String, u128> {
        use std::time::{Duration, Instant};

        let mut results = HashMap::new();

        // Benchmark string interning
        let mut total_duration = Duration::new(0, 0);
        let iterations = 1000;

        for i in 0..iterations {
            let test_str = format!("test_string_{i}");
            let start = Instant::now();
            let _ = self.string_interner.get_or_intern(&test_str);
            total_duration += start.elapsed();
        }

        results.insert(
            "string_interning_ns".to_string(),
            total_duration.as_nanos() / iterations as u128,
        );

        // Benchmark column index cache
        if !self.column_indices.is_empty() {
            let mut total_duration = Duration::new(0, 0);
            let iterations = 1000;

            // Get a sample key
            let sample_key = self.column_indices.keys().next().unwrap().clone();

            for _ in 0..iterations {
                let start = Instant::now();
                let _ = self.column_indices.get(&sample_key);
                total_duration += start.elapsed();
            }

            results.insert(
                "column_cache_lookup_ns".to_string(),
                total_duration.as_nanos() / iterations as u128,
            );
        }

        // Benchmark period date cache
        if !self.period_date_cache.is_empty() {
            let mut total_duration = Duration::new(0, 0);
            let iterations = 1000;

            // Get a sample key
            let sample_key = self.period_date_cache.keys().next().unwrap().clone();

            for _ in 0..iterations {
                let start = Instant::now();
                let _ = self.period_date_cache.get(&sample_key);
                total_duration += start.elapsed();
            }

            results.insert(
                "period_cache_lookup_ns".to_string(),
                total_duration.as_nanos() / iterations as u128,
            );
        }

        // Return all performance metrics
        results
    }
}

// Implement ArrowAccess for ArrowBackend
impl ArrowAccess for ArrowBackend {
    fn get_value<T: ArrowType>(
        &self,
        _column: &str,
        _row: usize,
    ) -> std::result::Result<T, IdsError> {
        Err(IdsError::invalid_operation(
            "ArrowBackend does not implement direct get_value. Use get_covariate instead."
                .to_string(),
        ))
    }

    fn get_optional_value<T: ArrowType>(
        &self,
        _column: &str,
        _row: usize,
    ) -> std::result::Result<Option<T>, IdsError> {
        Err(IdsError::invalid_operation(
            "ArrowBackend does not implement direct get_optional_value. Use get_covariate instead."
                .to_string(),
        ))
    }
    fn get_column(&self, _column: &str) -> std::result::Result<arrow::array::ArrayRef, IdsError> {
        Err(IdsError::invalid_operation(
            "ArrowBackend does not implement direct get_column. Use get_covariate instead."
                .to_string(),
        ))
    }

    fn has_column(&self, _column: &str) -> bool {
        false // This implementation doesn't provide direct column access
    }

    fn row_count(&self) -> usize {
        0 // This implementation doesn't provide direct row access
    }

    fn column_names(&self) -> Vec<String> {
        Vec::new() // This implementation doesn't provide direct column access
    }

    fn schema(&self) -> arrow::datatypes::SchemaRef {
        // Create an empty schema for compatibility
        use arrow::datatypes::{Field, Schema};
        use std::sync::Arc;

        // Create an empty schema with explicitly typed empty vector
        let empty_fields: Vec<Field> = vec![];
        Arc::new(Schema::new(empty_fields))
    }
}
</file>

<file path="src/storage/arrow/convert.rs">
use crate::error::Result;
use arrow::array::{Array, ArrayRef};
use arrow::datatypes::{DataType, Field, Schema as ArrowSchema};
use arrow::record_batch::RecordBatch;

/// Create a schema from field definitions
///
/// This function simplifies the creation of Arrow schemas by taking
/// a simple vector of name/type pairs.
///
/// # Arguments
/// * `fields` - Vector of (name, datatype) tuples
///
/// # Returns
/// An Arrow Schema with the specified fields
#[must_use]
pub fn create_schema(fields: Vec<(&str, DataType)>) -> ArrowSchema {
    let fields = fields
        .into_iter()
        .map(|(name, data_type)| Field::new(name, data_type, true))
        .collect::<Vec<_>>();

    ArrowSchema::new(fields)
}

/// Trait for converting between `RecordBatch` and other formats
///
/// This trait provides methods for converting between Arrow `RecordBatch`
/// and other data formats like CSV.
pub trait RecordBatchConversion {
    /// Convert `RecordBatch` to CSV string
    ///
    /// # Returns
    /// A CSV string representation of the batch
    ///
    /// # Errors
    /// Returns an error if the conversion fails
    fn to_csv(&self) -> Result<String>;

    /// Create `RecordBatch` from CSV string
    ///
    /// # Arguments
    /// * `csv` - CSV data as string
    /// * `schema` - Arrow schema for parsing
    ///
    /// # Returns
    /// A `RecordBatch` containing the parsed data
    ///
    /// # Errors
    /// Returns an error if parsing fails
    fn from_csv(csv: &str, schema: &ArrowSchema) -> Result<RecordBatch>;
}

/// Trait for types that can be converted from Arrow arrays
///
/// This trait enables consistent type-safe access to Arrow data by providing
/// a standardized way to extract values from Arrow arrays with proper type
/// checking and conversion.
pub trait ArrowType: Sized {
    /// Convert a value from an Arrow array at the specified index
    ///
    /// # Arguments
    /// * `array` - The Arrow array to extract from
    /// * `index` - The row index to extract
    ///
    /// # Returns
    /// * `Option<Self>` - The converted value or None if conversion failed
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self>;
}

// Implement for basic types used in the codebase

impl ArrowType for String {
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self> {
        if index >= array.len() || array.is_null(index) {
            return None;
        }

        match array.data_type() {
            DataType::Utf8 => {
                let array = array.as_any().downcast_ref::<arrow::array::StringArray>()?;
                Some(array.value(index).to_string())
            }
            DataType::LargeUtf8 => {
                let array = array
                    .as_any()
                    .downcast_ref::<arrow::array::LargeStringArray>()?;
                Some(array.value(index).to_string())
            }
            _ => None,
        }
    }
}

impl ArrowType for i32 {
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self> {
        if index >= array.len() || array.is_null(index) {
            return None;
        }

        match array.data_type() {
            DataType::Int32 => {
                let array = array.as_any().downcast_ref::<arrow::array::Int32Array>()?;
                Some(array.value(index))
            }
            DataType::Date32 => {
                let array = array.as_any().downcast_ref::<arrow::array::Date32Array>()?;
                Some(array.value(index))
            }
            _ => None,
        }
    }
}

impl ArrowType for i64 {
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self> {
        if index >= array.len() || array.is_null(index) {
            return None;
        }

        match array.data_type() {
            DataType::Int64 => {
                let array = array.as_any().downcast_ref::<arrow::array::Int64Array>()?;
                Some(array.value(index))
            }
            _ => None,
        }
    }
}

impl ArrowType for f64 {
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self> {
        if index >= array.len() || array.is_null(index) {
            return None;
        }

        match array.data_type() {
            DataType::Float64 => {
                let array = array
                    .as_any()
                    .downcast_ref::<arrow::array::Float64Array>()?;
                Some(array.value(index))
            }
            _ => None,
        }
    }
}

impl ArrowType for bool {
    fn from_array(array: &ArrayRef, index: usize) -> Option<Self> {
        if index >= array.len() || array.is_null(index) {
            return None;
        }

        match array.data_type() {
            DataType::Boolean => {
                let array = array
                    .as_any()
                    .downcast_ref::<arrow::array::BooleanArray>()?;
                Some(array.value(index))
            }
            _ => None,
        }
    }
}
</file>

<file path="src/storage/arrow/mod.rs">
//! Arrow integration utilities and types.
//!
//! This module provides integration with the Apache Arrow format,
//! enabling efficient columnar data storage and retrieval.
//!
//! Note: This module is only available when the `arrow-integration` feature is enabled.

#[cfg(feature = "arrow-integration")]
pub mod access;
#[cfg(feature = "arrow-integration")]
pub mod backend;
#[cfg(feature = "arrow-integration")]
pub mod convert;
#[cfg(feature = "arrow-integration")]
pub mod utils;
#[cfg(feature = "arrow-integration")]
pub mod values;

// Re-export key types
#[cfg(feature = "arrow-integration")]
pub use access::ArrowAccess;
#[cfg(feature = "arrow-integration")]
pub use backend::ArrowBackend;
#[cfg(feature = "arrow-integration")]
pub use convert::{create_schema, RecordBatchConversion};
#[cfg(feature = "arrow-integration")]
pub use utils::ArrowUtils;
#[cfg(feature = "arrow-integration")]
pub use values::ArrowValue;

#[cfg(not(feature = "arrow-integration"))]
compile_error!("The Arrow functionality requires the 'arrow-integration' feature to be enabled");
</file>

<file path="src/storage/arrow/utils.rs">
use crate::error::{IdsError, Result};
use arrow::array::{
    make_array, Array, ArrayData, BooleanArray, Date32Array, Float64Array, Int32Array, StringArray,
};
use arrow::buffer::Buffer;
use arrow::compute::filter_record_batch;
use arrow::datatypes::{DataType, Schema as ArrowSchema};
use arrow::record_batch::RecordBatch;
use chrono::NaiveDate;
use std::sync::Arc;

/// Utility functions for working with Arrow batches
///
/// This struct provides static methods for common Arrow operations,
/// including batch creation, manipulation, and optimization.
pub struct ArrowUtils;

impl ArrowUtils {
    /// Find PNR column index in a batch
    ///
    /// Searches for common PNR column names in different casing variations.
    ///
    /// # Arguments
    /// * `batch` - The record batch to search
    ///
    /// # Returns
    /// The index of the PNR column if found
    ///
    /// # Errors
    /// Returns an error if there's an issue accessing columns
    pub fn find_pnr_index(batch: &RecordBatch) -> Result<Option<usize>> {
        // Check common PNR column names
        for name in &["PNR", "pnr", "Pnr", "CPR", "cpr", "Cpr", "id", "ID", "Id"] {
            // The index_of function returns a Result, not an Option
            match batch.schema().index_of(name) {
                Ok(idx) => {
                    // Verify it's a string column
                    if matches!(batch.schema().field(idx).data_type(), DataType::Utf8) {
                        return Ok(Some(idx));
                    }
                }
                Err(_) => continue, // Column name not found, try the next one
            }
        }

        // No PNR column found
        Ok(None)
    }

    /// Filter a batch by a boolean mask
    ///
    /// # Arguments
    /// * `batch` - The record batch to filter
    /// * `mask` - Boolean array where true values keep the corresponding rows
    ///
    /// # Returns
    /// The filtered batch, or None if all rows were filtered out
    ///
    /// # Errors
    /// Returns an error if filtering fails
    pub fn filter_batch_by_mask(batch: &RecordBatch, mask: &[bool]) -> Result<Option<RecordBatch>> {
        // Create a BooleanArray from the mask
        let mask_array = BooleanArray::from(mask.to_vec());

        // Apply the filter
        match filter_record_batch(batch, &mask_array) {
            Ok(filtered) if filtered.num_rows() > 0 => Ok(Some(filtered)),
            Ok(_) => Ok(None), // Empty result
            Err(e) => Err(IdsError::invalid_operation(format!(
                "Failed to filter batch: {e}"
            ))),
        }
    }

    /// Create a new empty batch with the given schema
    ///
    /// # Arguments
    /// * `schema` - The schema for the empty batch
    ///
    /// # Returns
    /// A new empty `RecordBatch` with the provided schema
    ///
    /// # Errors
    /// Returns an error if the empty batch cannot be created
    pub fn create_empty_batch(schema: ArrowSchema) -> Result<RecordBatch> {
        let schema_arc = Arc::new(schema);
        let fields = schema_arc.fields();
        let columns = fields
            .iter()
            .map(|field| match field.data_type() {
                DataType::Int32 => Arc::new(Int32Array::from(Vec::<i32>::new())) as Arc<dyn Array>,
                DataType::Float64 => {
                    Arc::new(Float64Array::from(Vec::<f64>::new())) as Arc<dyn Array>
                }
                DataType::Utf8 => {
                    Arc::new(StringArray::from(Vec::<String>::new())) as Arc<dyn Array>
                }
                DataType::Date32 => {
                    Arc::new(Date32Array::from(Vec::<i32>::new())) as Arc<dyn Array>
                }
                _ => Arc::new(StringArray::from(Vec::<String>::new())) as Arc<dyn Array>,
            })
            .collect();

        let fields_len = fields.len();
        RecordBatch::try_new(schema_arc, columns).map_err(|err| {
            IdsError::invalid_operation(format!(
                "Failed to create empty batch with {fields_len} fields: {err}"
            ))
        })
    }

    /// Get Unix epoch (1970-01-01) date safely
    ///
    /// # Returns
    /// A Result containing the Unix epoch date
    ///
    /// # Errors
    /// Returns an error if the date 1970-01-01 cannot be created
    pub fn get_unix_epoch() -> Result<NaiveDate> {
        NaiveDate::from_ymd_opt(1970, 1, 1)
            .ok_or_else(|| IdsError::invalid_date("Failed to create Unix epoch date (1970-01-01)"))
    }

    /// Convert `NaiveDate` to days since epoch (for Date32 arrays) safely
    ///
    /// # Arguments
    /// * `date` - The date to convert
    ///
    /// # Returns
    /// Number of days since Unix epoch as i32
    ///
    /// # Errors
    /// Returns an error if the Unix epoch date can't be created or if the result would
    /// overflow an i32
    pub fn date_to_days_since_epoch(date: NaiveDate) -> Result<i32> {
        let epoch = Self::get_unix_epoch()?;
        let days = date.signed_duration_since(epoch).num_days();

        // Safely convert to i32, checking for overflow
        i32::try_from(days).map_err(|_| {
            IdsError::invalid_date(format!(
                "Date conversion overflow: days since epoch ({days}) exceeds i32 range"
            ))
        })
    }

    /// Concatenate multiple batches with the same schema
    ///
    /// # Arguments
    /// * `batches` - Array of record batches to concatenate
    ///
    /// # Returns
    /// A single concatenated batch
    ///
    /// # Errors
    /// Returns an error if batches have different schemas or concatenation fails
    pub fn concat_batches(batches: &[RecordBatch]) -> Result<RecordBatch> {
        if batches.is_empty() {
            return Err(IdsError::missing_data("No batches to concatenate"));
        }

        if batches.len() == 1 {
            return Ok(batches[0].clone());
        }

        let schema = Arc::new((*batches[0].schema()).clone());

        // Check that all batches have the same schema using ptr_eq for faster comparison
        // when the schemas are the same instance
        for batch in batches.iter().skip(1) {
            if !Arc::ptr_eq(&batch.schema(), &schema) {
                // Create references that live long enough
                let batch_schema = batch.schema();
                let batch_fields = batch_schema.fields();
                let schema_fields = schema.fields();

                if batch_fields.len() != schema_fields.len() {
                    return Err(IdsError::invalid_operation(
                        "Cannot concatenate batches with different schemas (field count mismatch)",
                    ));
                }

                for (i, field) in schema_fields.iter().enumerate() {
                    let batch_field = &batch_fields[i];
                    if field.name() != batch_field.name()
                        || field.data_type() != batch_field.data_type()
                    {
                        return Err(IdsError::invalid_operation(
                            "Cannot concatenate batches with different schemas (field mismatch)",
                        ));
                    }
                }
            }
        }

        // Concatenate each column
        let mut columns = Vec::with_capacity(schema.fields().len());

        for i in 0..schema.fields().len() {
            let arrays: Vec<&dyn Array> = batches
                .iter()
                .map(|batch| batch.column(i).as_ref())
                .collect();

            let concat = arrow::compute::concat(&arrays).map_err(|e| {
                IdsError::invalid_operation(format!("Failed to concatenate column: {e}"))
            })?;

            columns.push(concat);
        }

        RecordBatch::try_new(schema, columns).map_err(|e| {
            IdsError::invalid_operation(format!("Failed to create concatenated batch: {e}"))
        })
    }

    /// Create an array from builder for efficient memory usage
    ///
    /// # Arguments
    /// * `strings` - The string values to include in the array
    /// * `capacity` - Capacity hint for buffer allocation
    ///
    /// # Returns
    /// An optimized `StringArray`
    ///
    /// # Errors
    /// Returns an error if array creation fails
    pub fn create_optimized_string_array(
        strings: &[String],
        _capacity: usize,
    ) -> Result<StringArray> {
        // Estimate total size of all strings
        let total_string_size: usize = strings.iter().map(std::string::String::len).sum();

        // Create buffers
        let mut values = String::with_capacity(total_string_size);
        let mut offsets = Vec::with_capacity(strings.len() + 1);
        let mut nulls = Vec::with_capacity(strings.len());

        // Start with offset 0
        offsets.push(0);

        // Fill the values and offsets
        for s in strings {
            values.push_str(s);
            offsets.push(values.len());
            nulls.push(true); // All values are valid
        }

        // Convert to Arrow buffers
        let values_buffer = Buffer::from(values.into_bytes());
        let offsets_buffer = Buffer::from(offsets.iter().map(|&o| o as i32).collect::<Vec<i32>>());

        // Create array data
        let builder = ArrayData::builder(DataType::Utf8)
            .len(strings.len())
            .add_buffer(offsets_buffer)
            .add_buffer(values_buffer);

        // Build array
        let array_data = unsafe { builder.build_unchecked() };
        Ok(StringArray::from(array_data))
    }

    /// Align a batch's buffers for better memory performance
    ///
    /// # Arguments
    /// * `batch` - The record batch to align
    ///
    /// # Returns
    /// A new record batch with aligned buffers
    ///
    /// # Errors
    /// Returns an error if the aligned batch cannot be created
    pub fn align_batch_buffers(batch: &RecordBatch) -> Result<RecordBatch> {
        let columns: Vec<Arc<dyn Array>> = batch
            .columns()
            .iter()
            .map(|col| {
                let mut array_data = col.to_data();
                array_data.align_buffers();
                make_array(array_data)
            })
            .collect();

        RecordBatch::try_new(batch.schema(), columns).map_err(|err| {
            IdsError::invalid_operation(format!("Failed to create aligned batch: {err}"))
        })
    }

    /// Create a sliced array for zero-copy operations
    ///
    /// # Arguments
    /// * `array` - The source array to slice
    /// * `offset` - The starting index
    /// * `length` - The number of elements to include
    ///
    /// # Returns
    /// A new array view representing the slice
    pub fn slice_array(array: &dyn Array, offset: usize, length: usize) -> Arc<dyn Array> {
        array.slice(offset, length)
    }

    /// Check if two arrays have the same data by pointer comparison
    ///
    /// # Arguments
    /// * `array1` - First array to compare
    /// * `array2` - Second array to compare
    ///
    /// # Returns
    /// True if arrays share the same memory
    pub fn arrays_equal_by_ptr(array1: &dyn Array, array2: &dyn Array) -> bool {
        // Since we can't use ptr_eq directly on ArrayData, we compare memory addresses
        std::ptr::eq(
            array1.to_data().buffers()[0].as_ptr(),
            array2.to_data().buffers()[0].as_ptr(),
        )
    }
}
</file>

<file path="src/storage/arrow/values.rs">
use arrow::record_batch::RecordBatch;
use std::sync::Arc;

use crate::error::Result;

/// A wrapper around Arrow data structures that provides standardized access
///
/// This type ensures that data can be accessed consistently regardless of its
/// source or storage format. It provides a unified interface for working with
/// Arrow data throughout the codebase.
#[derive(Clone)]
pub struct ArrowValue {
    /// The underlying Arrow `RecordBatch` containing the data
    pub batch: Arc<RecordBatch>,
}

impl ArrowValue {
    /// Create a new `ArrowValue` from a `RecordBatch`
    ///
    /// # Arguments
    /// * `batch` - The `RecordBatch` to wrap
    ///
    /// # Returns
    /// * `ArrowValue` - The wrapped value
    #[must_use] pub fn new(batch: RecordBatch) -> Self {
        Self {
            batch: Arc::new(batch),
        }
    }

    /// Create a new `ArrowValue` from an Arc-wrapped `RecordBatch`
    ///
    /// # Arguments
    /// * `batch` - The `RecordBatch` to wrap, already in an Arc
    ///
    /// # Returns
    /// * `ArrowValue` - The wrapped value
    #[must_use] pub fn from_arc(batch: Arc<RecordBatch>) -> Self {
        Self { batch }
    }

    /// Get the underlying `RecordBatch`
    ///
    /// # Returns
    /// * `&RecordBatch` - Reference to the wrapped `RecordBatch`
    #[must_use] pub fn batch(&self) -> &RecordBatch {
        &self.batch
    }

    /// Get the number of rows in the batch
    ///
    /// # Returns
    /// * `usize` - The number of rows
    #[must_use] pub fn row_count(&self) -> usize {
        self.batch.num_rows()
    }

    /// Check if the batch is empty
    ///
    /// # Returns
    /// * `bool` - True if the batch has no rows, false otherwise
    #[must_use] pub fn is_empty(&self) -> bool {
        self.batch.num_rows() == 0
    }

    /// Create an empty `ArrowValue` with the same schema
    ///
    /// # Returns
    /// * `Result<ArrowValue>` - Empty batch with the same schema
    ///
    /// # Errors
    /// Returns an error if creating the empty batch fails
    pub fn empty_like(&self) -> Result<Self> {
        let schema = self.batch.schema();
        let empty_arrays = schema
            .fields()
            .iter()
            .map(|field| arrow::array::new_empty_array(field.data_type()))
            .collect::<Vec<_>>();

        let empty_batch = RecordBatch::try_new(schema.clone(), empty_arrays)?;
        Ok(Self::new(empty_batch))
    }
}

// Implementation of From<RecordBatch> for easier conversion
impl From<RecordBatch> for ArrowValue {
    fn from(batch: RecordBatch) -> Self {
        Self::new(batch)
    }
}

// Implementation of From<Arc<RecordBatch>> for easier conversion
impl From<Arc<RecordBatch>> for ArrowValue {
    fn from(batch: Arc<RecordBatch>) -> Self {
        Self::from_arc(batch)
    }
}
</file>

<file path="src/storage/backends/memory.rs">
// Memory backend implementation placeholder
// This file will be populated during the next phase of refactoring
// It will contain a simple in-memory storage backend implementation
</file>

<file path="src/storage/backends/mod.rs">
// This module will contain various storage backends
// Currently these are still in the old location, to be moved in phases

pub mod memory;
pub mod time_varying;

// Re-exports (will be uncommented once implemented)
// pub use time_varying::TimeVaryingBackend;
// pub use memory::MemoryBackend;
</file>

<file path="src/storage/backends/time_varying.rs">
// Time-varying backend implementation placeholder
// This file will be populated during the next phase of refactoring
// It will contain the TimeVaryingBackend that is currently in store/time_varying_backend.rs
</file>

<file path="src/storage/concurrency/mod.rs">
//! Concurrency utilities for thread-safe data access.
//!
//! This module provides standardized concurrency primitives and patterns
//! for ensuring thread-safe access to data stores and caches. It consolidates
//! the various concurrency approaches used throughout the codebase into a
//! consistent, optimized set of utilities.

use crate::error::{IdsError, Result};
use crate::models::{Covariate, CovariateType, TimeVaryingValue};
use crate::traits::Store;
use chrono::NaiveDate;
use dashmap::DashMap;
use parking_lot::{Mutex, RwLock, RwLockReadGuard, RwLockWriteGuard};
use std::hash::{BuildHasher, Hash, RandomState};
use std::sync::Arc;

/// Standard thread-safe wrapper for store implementations.
///
/// This wrapper provides consistent thread-safe access to any store implementation
/// using high-performance `RwLock` for concurrent read access and exclusive write access.
#[derive(Debug, Clone)]
pub struct ThreadSafeStore<S: Store + 'static> {
    inner: Arc<RwLock<S>>,
}

impl<S: Store + 'static> ThreadSafeStore<S> {
    /// Creates a new thread-safe store wrapper around the provided store.
    ///
    /// # Arguments
    ///
    /// * `store` - The store to wrap
    ///
    /// # Returns
    ///
    /// A new thread-safe store wrapper
    #[must_use]
    pub fn new(store: S) -> Self {
        Self {
            inner: Arc::new(RwLock::new(store)),
        }
    }

    /// Access the inner store with shared read access.
    ///
    /// This method acquires a read lock on the store, enabling multiple concurrent
    /// readers but blocking writes until all read locks are released.
    ///
    /// # Returns
    ///
    /// A guard that provides shared access to the store
    #[must_use]
    pub fn read(&self) -> RwLockReadGuard<'_, S> {
        self.inner.read()
    }

    /// Access the inner store with exclusive write access.
    ///
    /// This method acquires a write lock on the store, blocking all other access
    /// until the write lock is released.
    ///
    /// # Returns
    ///
    /// A guard that provides exclusive access to the store
    #[must_use]
    pub fn write(&self) -> RwLockWriteGuard<'_, S> {
        self.inner.write()
    }

    /// Get a covariate with minimal locking time.
    ///
    /// This method acquires the lock only for the duration of the covariate retrieval.
    ///
    /// # Arguments
    ///
    /// * `pnr` - The person identification number
    /// * `covariate_type` - The type of covariate to retrieve
    /// * `date` - The date for which to retrieve the covariate
    ///
    /// # Returns
    ///
    /// A Result containing the covariate (if found) or an error
    pub fn covariate(
        &self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>> {
        let mut store = self.inner.write();
        store.covariate(pnr, covariate_type, date)
    }

    /// Gets the inner store implementation directly.
    ///
    /// # Returns
    ///
    /// A reference to the Arc-wrapped `RwLock` containing the store
    #[must_use]
    pub fn inner(&self) -> &Arc<RwLock<S>> {
        &self.inner
    }
}

/// Implementation of the Store trait for `ThreadSafeStore`.
///
/// This allows `ThreadSafeStore` to be used anywhere a Store is expected.
impl<S: Store + 'static> Store for ThreadSafeStore<S> {
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>> {
        let mut store = self.inner.write();
        store.covariate(pnr, covariate_type, date)
    }

    fn family_relations(&self, _pnr: &str) -> Option<&crate::family::FamilyRelations> {
        // This operation requires holding the read lock for the entire method call
        // which means we can't return a reference to something inside the lock.
        // Instead, we need to clone the data or restructure the API.
        // For now, this returns None to avoid deadlocks, but the API needs to be changed.
        None
    }

    fn load_data(&mut self, data: Vec<TimeVaryingValue<Covariate>>) -> Result<()> {
        let mut store = self.inner.write();
        store.load_data(data)
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn as_any_mut(&mut self) -> &mut dyn std::any::Any {
        self
    }
}

/// High-performance sharded cache for improved concurrency.
///
/// This optimized cache implementation uses efficient data sharding based on key hashing
/// to minimize contention and maximize throughput in highly concurrent scenarios.
/// It eliminates redundant locks by leveraging `DashMap`'s built-in concurrency.
pub struct ShardedCache<K, V> {
    /// Array of `DashMap` instances, each responsible for a shard of the keyspace
    shards: Vec<dashmap::DashMap<K, V>>,
    /// Number of shards for distributing keys
    num_shards: usize,
    /// Hash function state for key distribution
    hasher: RandomState,
}

impl<K, V> ShardedCache<K, V>
where
    K: Hash + Eq + Clone,
    V: Clone,
{
    /// Create a new sharded cache with the specified capacity.
    ///
    /// # Arguments
    ///
    /// * `capacity` - The total approximate capacity of the cache
    /// * `num_shards` - The number of shards to use (defaults to the number of logical CPU cores)
    ///
    /// # Returns
    ///
    /// A new sharded cache instance
    #[must_use]
    pub fn new(capacity: usize, num_shards: Option<usize>) -> Self {
        // Determine optimal shard count based on CPU cores or provided value
        let num_shards = num_shards.unwrap_or_else(|| {
            std::thread::available_parallelism()
                .map(std::num::NonZero::get)
                .unwrap_or(16)
                .max(4)
        });

        // Calculate per-shard capacity, ensuring even distribution
        let per_shard_capacity = (capacity / num_shards) + 1;

        // Create shards with pre-allocated capacity
        let shards: Vec<DashMap<K, V>> = (0..num_shards)
            .map(|_| DashMap::with_capacity_and_hasher(per_shard_capacity, RandomState::new()))
            .collect();

        Self {
            shards,
            num_shards,
            hasher: RandomState::new(),
        }
    }

    /// Get the shard index for a key using consistent hashing.
    ///
    /// Uses a high-quality hash function to distribute keys evenly across shards.
    #[inline]
    fn shard_idx<Q: Hash>(&self, key: &Q) -> usize {
        (self.hasher.hash_one(key) % self.num_shards as u64) as usize
    }

    /// Get a value from the cache.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to look up
    ///
    /// # Returns
    ///
    /// The value if present, otherwise None
    pub fn get(&self, key: &K) -> Option<V> {
        let shard_idx = self.shard_idx(key);
        self.shards[shard_idx].get(key).map(|v| v.clone())
    }

    /// Insert a value into the cache.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to insert
    /// * `value` - The value to insert
    pub fn insert(&self, key: K, value: V) {
        let shard_idx = self.shard_idx(&key);
        self.shards[shard_idx].insert(key, value);
    }

    /// Check if the cache contains a key.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to check
    ///
    /// # Returns
    ///
    /// True if the key is present, otherwise false
    pub fn contains_key(&self, key: &K) -> bool {
        let shard_idx = self.shard_idx(key);
        self.shards[shard_idx].contains_key(key)
    }

    /// Clear all entries from the cache.
    pub fn clear(&self) {
        self.shards.iter().for_each(dashmap::DashMap::clear);
    }

    /// Get the approximate number of entries in the cache.
    ///
    /// # Returns
    ///
    /// The approximate number of entries
    #[must_use] pub fn len(&self) -> usize {
        self.shards.iter().map(dashmap::DashMap::len).sum()
    }

    /// Check if the cache is empty.
    ///
    /// # Returns
    ///
    /// True if the cache is empty, otherwise false
    #[must_use] pub fn is_empty(&self) -> bool {
        self.shards.iter().all(dashmap::DashMap::is_empty)
    }

    /// Perform a bulk insertion with minimal contention.
    ///
    /// This method pre-sorts entries by shard to minimize cross-shard operations and
    /// maximize insertion throughput in concurrent scenarios.
    ///
    /// # Arguments
    ///
    /// * `entries` - The entries to insert
    pub fn insert_batch(&self, entries: Vec<(K, V)>) {
        // Group entries by shard for efficient insertion
        let mut sharded_entries: Vec<Vec<(K, V)>> = vec![Vec::new(); self.num_shards];

        // Distribute entries to their target shards
        for (key, value) in entries {
            let idx = self.shard_idx(&key);
            sharded_entries[idx].push((key, value));
        }

        // Process each shard in parallel using rayon if available
        #[cfg(feature = "parallel")]
        {
            use rayon::prelude::*;
            sharded_entries
                .into_par_iter()
                .enumerate()
                .for_each(|(idx, entries)| {
                    if !entries.is_empty() {
                        let shard = &self.shards[idx];
                        entries.into_iter().for_each(|(key, value)| {
                            shard.insert(key, value);
                        });
                    }
                });
        }

        // Sequential fallback when parallel feature is not enabled
        #[cfg(not(feature = "parallel"))]
        {
            for (idx, entries) in sharded_entries.into_iter().enumerate() {
                if !entries.is_empty() {
                    let shard = &self.shards[idx];
                    for (key, value) in entries {
                        shard.insert(key, value);
                    }
                }
            }
        }
    }

    /// Remove an entry from the cache.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to remove
    ///
    /// # Returns
    ///
    /// The removed value if it was present
    pub fn remove(&self, key: &K) -> Option<V> {
        let shard_idx = self.shard_idx(key);
        self.shards[shard_idx].remove(key).map(|(_, v)| v)
    }

    /// Get or compute a value in the cache.
    ///
    /// If the key exists in the cache, returns the existing value.
    /// Otherwise, computes a new value using the provided function and inserts it.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to look up
    /// * `f` - Function to compute a new value if key is not present
    ///
    /// # Returns
    ///
    /// The existing or newly computed value
    pub fn get_or_insert_with<F>(&self, key: K, f: F) -> V
    where
        F: FnOnce() -> V,
    {
        let shard_idx = self.shard_idx(&key);
        self.shards[shard_idx].entry(key).or_insert_with(f).clone()
    }
}

/// A high-performance cache for covariates.
///
/// This cache implementation provides low-contention access to covariate data
/// using a sharded approach with fine-grained locking.
pub struct CovariateCache {
    cache: ShardedCache<crate::storage::CacheKey, Option<Covariate>>,
    bulk_lock: Mutex<()>,
}

impl CovariateCache {
    /// Create a new covariate cache with the specified capacity.
    ///
    /// # Arguments
    ///
    /// * `capacity` - The approximate capacity of the cache
    ///
    /// # Returns
    ///
    /// A new `CovariateCache` instance
    #[must_use]
    pub fn new(capacity: usize) -> Self {
        Self {
            cache: ShardedCache::<crate::storage::CacheKey, Option<Covariate>>::new(capacity, None),
            bulk_lock: Mutex::new(()),
        }
    }

    /// Get a value from the cache.
    ///
    /// # Arguments
    ///
    /// * `key` - The cache key to look up
    ///
    /// # Returns
    ///
    /// The value if present, otherwise None
    pub fn get(&self, key: &crate::storage::CacheKey) -> Option<Option<Covariate>> {
        self.cache.get(key)
    }

    /// Insert a value into the cache.
    ///
    /// # Arguments
    ///
    /// * `key` - The cache key to insert
    /// * `value` - The value to insert
    pub fn insert(&self, key: crate::storage::CacheKey, value: Option<Covariate>) {
        self.cache.insert(key, value);
    }

    /// Clear the cache.
    pub fn clear(&self) {
        let _guard = self.bulk_lock.lock();
        self.cache.clear();
    }

    /// Get the number of entries in the cache.
    ///
    /// # Returns
    ///
    /// The number of entries
    pub fn len(&self) -> usize {
        self.cache.len()
    }

    /// Check if the cache is empty.
    ///
    /// # Returns
    ///
    /// True if the cache is empty, otherwise false
    pub fn is_empty(&self) -> bool {
        self.cache.len() == 0
    }

    /// Get or load a value from the cache.
    ///
    /// # Arguments
    ///
    /// * `store` - The store to load from if the value is not in the cache
    /// * `key` - The key to look up
    ///
    /// # Returns
    ///
    /// A Result containing the value or an error
    pub fn get_or_load(
        &self,
        store: &mut impl Store,
        key: crate::storage::CacheKey,
    ) -> Result<Option<Covariate>> {
        // First check if the value is in the cache
        if let Some(value) = self.cache.get(&key) {
            return Ok(value);
        }

        // Not in cache, load from store
        let pnr = &key.pnr;
        let cov_type = key.covariate_type;
        let date = key.date;

        let value = store.covariate(pnr, cov_type, date)?;

        // Cache the result
        self.cache.insert(key, value.clone());

        Ok(value)
    }

    /// Bulk load values into the cache.
    ///
    /// # Arguments
    ///
    /// * `store` - The store to load from
    /// * `pnrs` - The PNRs to load for
    /// * `covariate_types` - The covariate types to load
    /// * `dates` - The dates to load for
    ///
    /// # Returns
    ///
    /// A Result containing the number of entries loaded or an error
    pub fn bulk_load(
        &self,
        store: &mut impl Store,
        pnrs: &[String],
        covariate_types: &[CovariateType],
        dates: &[NaiveDate],
    ) -> Result<usize> {
        // For large bulk operations, acquire the bulk lock
        let _bulk_guard = self.bulk_lock.lock();

        // Create all cache keys
        let total_keys = pnrs.len() * covariate_types.len() * dates.len();
        let mut keys = Vec::with_capacity(total_keys);

        for pnr in pnrs {
            for &cov_type in covariate_types {
                for &date in dates {
                    let key = crate::storage::CacheKey::new(pnr, cov_type, date);
                    if !self.cache.contains_key(&key) {
                        keys.push((key, pnr.clone(), cov_type, date));
                    }
                }
            }
        }

        // Load missing values
        let mut loaded_entries = Vec::with_capacity(keys.len());

        for (key, pnr, cov_type, date) in keys {
            match store.covariate(&pnr, cov_type, date) {
                Ok(value) => {
                    loaded_entries.push((key, value.clone()));
                }
                Err(e) => {
                    return Err(IdsError::invalid_operation(format!(
                        "Failed to load covariate: {e}"
                    )));
                }
            }
        }

        // Bulk insert into cache
        let entry_count = loaded_entries.len();
        if !loaded_entries.is_empty() {
            self.cache.insert_batch(loaded_entries);
        }

        Ok(entry_count)
    }
}
</file>

<file path="src/storage/mod.rs">
//! Storage abstractions for different data backends.
//!
//! This module provides storage abstractions for working with different data backends,
//! including Arrow, in-memory storage, and time-varying data.
//!
//! The main types in this module are:
//!
//! - `DataStore`: The central data store that manages multiple backends
//! - `Backend`: Trait for implementing different storage backends
//! - `ArrowBackend`: Arrow-based storage backend implementation
//! - `MemoryBackend`: Simple in-memory storage backend
//! - `TimeVaryingBackend`: Backend for time-varying data
//!
//! Additionally, this module provides concurrency utilities for thread-safe
//! access to storage backends:
//!
//! - `ThreadSafeStore`: Thread-safe wrapper for any Store implementation
//! - `ShardedCache`: High-performance sharded cache for concurrent access
//! - `CovariateCache`: Optimized cache for covariates with low contention

use crate::models::CovariateType;
use chrono::NaiveDate;

/// Common cache key for covariate lookups
/// Used across various caching implementations
///
/// Optimized implementation that uses a string interner pool to minimize
/// memory usage when many PNRs are used in cache keys.
#[derive(Debug, Hash, Eq, PartialEq, Clone)]
pub struct CacheKey {
    /// PNR identifier string, using an Arc-string for memory-efficient cloning
    pub pnr: std::sync::Arc<str>,
    /// Type of covariate for this cache entry
    pub covariate_type: CovariateType,
    /// Reference date for this covariate
    pub date: NaiveDate,
}

impl CacheKey {
    /// Create a new cache key with efficient memory usage
    ///
    /// Uses a thread-local cache of PNR strings to minimize memory allocations
    /// when creating many cache keys with the same PNRs.
    ///
    /// # Arguments
    /// * `pnr` - The PNR identifier
    /// * `covariate_type` - The type of covariate
    /// * `date` - The reference date
    ///
    /// # Returns
    /// A new cache key with optimized memory usage
    #[must_use]
    pub fn new(pnr: &str, covariate_type: CovariateType, date: NaiveDate) -> Self {
        use std::sync::Arc;

        // Simply create a new Arc directly without caching
        // This avoids the borrowing issues with the complex RefCell/DashMap combination
        let pnr_arc: Arc<str> = Arc::from(pnr);

        Self {
            pnr: pnr_arc,
            covariate_type,
            date,
        }
    }

    /// Create a new cache key with a pre-allocated Arc<str>
    ///
    /// This is useful when you already have an Arc<str> from another source,
    /// avoiding the need to go through the cache lookup.
    ///
    /// # Arguments
    /// * `pnr` - The PNR identifier as an Arc<str>
    /// * `covariate_type` - The type of covariate
    /// * `date` - The reference date
    ///
    /// # Returns
    /// A new cache key using the provided Arc<str>
    #[must_use]
    pub fn from_arc(
        pnr: std::sync::Arc<str>,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Self {
        Self {
            pnr,
            covariate_type,
            date,
        }
    }
}

pub mod arrow;
pub mod backends;
pub mod concurrency;

// Re-export public types
pub use crate::store::DataStore;
pub use crate::traits::Store as Backend;

// Export the consolidated backends
pub use crate::store::time_varying_backend::TimeVaryingBackend;
pub use arrow::backend::ArrowBackend;

// Export concurrency utilities
pub use concurrency::{CovariateCache, ShardedCache, ThreadSafeStore};
</file>

<file path="src/store/arrow_backend.rs">
use arrow::array::{Array, StringArray};
use arrow::record_batch::RecordBatch;
use chrono::NaiveDate;
use hashbrown::HashMap;
use log;

use crate::{
    arrow::utils::ArrowUtils,
    error::{IdsError, Result},
    family::{FamilyRelations, FamilyStore},
    models::{Covariate, CovariateType, TimeVaryingValue},
    traits::Store,
    translation::TranslationMaps,
};

/// Arrow-based storage backend
#[derive(Debug, Clone)]
pub struct ArrowBackend {
    family_data: HashMap<String, FamilyRelations>,
    akm_data: HashMap<i32, Vec<RecordBatch>>,
    bef_data: HashMap<String, Vec<RecordBatch>>,
    ind_data: HashMap<i32, Vec<RecordBatch>>,
    uddf_data: HashMap<String, Vec<RecordBatch>>,
    translations: TranslationMaps,
}

impl ArrowBackend {
    pub fn new() -> Result<Self> {
        let translations =
            TranslationMaps::new().map_err(|e| IdsError::invalid_format(format!("{e}")))?;

        Ok(Self {
            family_data: HashMap::new(),
            akm_data: HashMap::new(),
            bef_data: HashMap::new(),
            ind_data: HashMap::new(),
            uddf_data: HashMap::new(),
            translations,
        })
    }

    /// Create a new empty ArrowBackend, used for diagnostic mode when data loading fails
    ///
    /// # Panics
    ///
    /// This function will panic if it fails to create valid dates for the synthetic data.
    /// Since this is only used for diagnostic purposes and uses carefully constructed date values,
    /// the panics would indicate a serious programming error rather than a runtime condition.
    #[must_use]
    pub fn new_empty() -> Self {
        // Create a minimal store for diagnostic operations with some synthetic data for debugging
        let mut family_data = HashMap::new();
        let ind_data = HashMap::new();
        let bef_data = HashMap::new();

        // Add synthetic relationships and data for debugging in diagnostic mode
        for i in 0..100 {
            // Add some synthetic family data for diagnostic purposes
            let case_id = format!("C{i:06}");
            let control_id = format!("K{i:06}");

            // Calculate valid date components with safe ranges
            let year = 1990 + (i % 30);
            let month = 1 + (i % 12) as u32;
            let day = 1 + (i % 28) as u32; // Always  28 to avoid invalid dates

            let father_year = 1950 + (i % 30);
            let mother_year = 1955 + (i % 30);

            // Get a birth date based on the index - these are constructed to always be valid
            // We explicitly document the panics here since this is diagnostic code only
            let birth_date = chrono::NaiveDate::from_ymd_opt(year, month, day)
                .expect("Invalid synthetic birth date constructed in diagnostic mode");

            let father_birth_date = chrono::NaiveDate::from_ymd_opt(father_year, month, day)
                .expect("Invalid synthetic father birth date constructed in diagnostic mode");

            let mother_birth_date = chrono::NaiveDate::from_ymd_opt(mother_year, month, day)
                .expect("Invalid synthetic mother birth date constructed in diagnostic mode");

            // Add family relations for cases and controls
            family_data.insert(
                case_id.clone(),
                FamilyRelations {
                    pnr: case_id.clone(),
                    birth_date,
                    father_id: Some(format!("F{i:06}")),
                    father_birth_date: Some(father_birth_date),
                    mother_id: Some(format!("M{i:06}")),
                    mother_birth_date: Some(mother_birth_date),
                    family_id: Some(format!("FAM{i:06}")),
                },
            );

            family_data.insert(
                control_id.clone(),
                FamilyRelations {
                    pnr: control_id.clone(),
                    birth_date,
                    father_id: Some(format!("F{:06}", i + 1000)),
                    father_birth_date: Some(father_birth_date),
                    mother_id: Some(format!("M{:06}", i + 1000)),
                    mother_birth_date: Some(mother_birth_date),
                    family_id: Some(format!("FAM{:06}", i + 1000)),
                },
            );
        }

        Self {
            family_data,
            akm_data: HashMap::new(),
            bef_data,
            ind_data,
            uddf_data: HashMap::new(),
            translations: TranslationMaps::new_empty(),
        }
    }

    pub fn add_akm_data(&mut self, year: i32, mut batches: Vec<RecordBatch>) -> Result<()> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid AKM batch for year {}: {}", year, e);
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        self.akm_data.insert(year, batches);
        Ok(())
    }

    pub fn add_bef_data(&mut self, period: String, mut batches: Vec<RecordBatch>) -> Result<()> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid BEF batch for period {}: {}", period, e);
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        self.bef_data.insert(period, batches);
        Ok(())
    }

    pub fn add_ind_data(&mut self, year: i32, mut batches: Vec<RecordBatch>) -> Result<()> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid IND batch for year {}: {}", year, e);
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        self.ind_data.insert(year, batches);
        Ok(())
    }

    pub fn add_uddf_data(&mut self, period: String, mut batches: Vec<RecordBatch>) -> Result<()> {
        // Validate batches first
        for batch in &batches {
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid UDDF batch for period {}: {}", period, e);
            }
        }

        // Optimize batch memory layout
        for batch in &mut batches {
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        self.uddf_data.insert(period, batches);
        Ok(())
    }

    /// Add family data to the backend
    pub fn add_family_data(&mut self, batches: Vec<RecordBatch>) -> Result<()> {
        // Load family relations using existing implementation
        self.load_family_relations(batches)
    }

    fn get_education(&self, pnr: &str, date: NaiveDate) -> Result<Option<Covariate>> {
        // Find the closest UDDF data period before the given date
        let period = self.find_closest_period(date, &self.uddf_data)?;

        if let Some(batches) = period.and_then(|p| self.uddf_data.get(p)) {
            for batch in batches {
                if let Some(idx) = self.find_pnr_index(batch, pnr)? {
                    // Use optimized array data access
                    let hfaudd_array = self.get_string_array(batch, "HFAUDD")?;

                    if !hfaudd_array.is_null(idx) {
                        let level = hfaudd_array.value(idx).to_string();
                        return Ok(Some(Covariate::education(level).build()));
                    }
                }
            }
        }
        Ok(None)
    }

    fn get_income(&self, pnr: &str, date: NaiveDate) -> Result<Option<Covariate>> {
        use chrono::Datelike;
        let year = date.year();
        if let Some(batches) = self.ind_data.get(&year) {
            for batch in batches {
                if let Some(idx) = self.find_pnr_index(batch, pnr)? {
                    // Get value directly using optimized method
                    // Use batch directly to get the value
                    let column = match batch.schema().index_of("PERINDKIALT_13") {
                        Ok(idx) => batch.column(idx),
                        Err(_) => continue, // Column not found, try next batch
                    };

                    let array = column
                        .as_any()
                        .downcast_ref::<arrow::array::Float64Array>()
                        .ok_or_else(|| {
                            IdsError::data_loading("Income column not a float array".to_string())
                        })?;
                    let amount = if array.is_null(idx) {
                        None
                    } else {
                        Some(array.value(idx))
                    };
                    if let Some(amount) = amount {
                        return Ok(Some(
                            Covariate::income(amount, "DKK", "PERINDKIALT_13").build(),
                        ));
                    }
                }
            }
        }
        Ok(None)
    }

    fn get_demographics(&self, pnr: &str, date: NaiveDate) -> Result<Option<Covariate>> {
        let period = self.find_closest_period(date, &self.bef_data)?;

        if let Some(batches) = period.and_then(|p| self.bef_data.get(p)) {
            for batch in batches {
                if let Some(idx) = self.find_pnr_index(batch, pnr)? {
                    // Use direct access for better performance - get all values at once
                    // Get values directly from the batch
                    let schema = batch.schema();

                    // Get family size
                    let family_size: Option<i32> = match schema.index_of("ANTPERSF") {
                        Ok(col_idx) => {
                            let array = batch.column(col_idx);
                            if array.is_null(idx) {
                                None
                            } else if let Some(typed_array) =
                                array.as_any().downcast_ref::<arrow::array::Int32Array>()
                            {
                                Some(typed_array.value(idx))
                            } else {
                                return Err(IdsError::data_loading(
                                    "ANTPERSF not an int32 array".to_string(),
                                ));
                            }
                        }
                        Err(_) => None,
                    };

                    // Get municipality
                    let municipality: Option<i32> = match schema.index_of("KOM") {
                        Ok(col_idx) => {
                            let array = batch.column(col_idx);
                            if array.is_null(idx) {
                                None
                            } else if let Some(typed_array) =
                                array.as_any().downcast_ref::<arrow::array::Int32Array>()
                            {
                                Some(typed_array.value(idx))
                            } else {
                                return Err(IdsError::data_loading(
                                    "KOM not an int32 array".to_string(),
                                ));
                            }
                        }
                        Err(_) => None,
                    };

                    // Get family type
                    let family_type: Option<i32> = match schema.index_of("FAMILIE_TYPE") {
                        Ok(col_idx) => {
                            let array = batch.column(col_idx);
                            if array.is_null(idx) {
                                None
                            } else if let Some(typed_array) =
                                array.as_any().downcast_ref::<arrow::array::Int32Array>()
                            {
                                Some(typed_array.value(idx))
                            } else {
                                return Err(IdsError::data_loading(
                                    "FAMILIE_TYPE not an int32 array".to_string(),
                                ));
                            }
                        }
                        Err(_) => None,
                    };

                    // Get citizenship
                    let statsb: Option<String> = match schema.index_of("STATSB") {
                        Ok(col_idx) => {
                            let array = batch.column(col_idx);
                            if array.is_null(idx) {
                                None
                            } else if let Some(typed_array) =
                                array.as_any().downcast_ref::<arrow::array::StringArray>()
                            {
                                Some(typed_array.value(idx).to_string())
                            } else {
                                return Err(IdsError::data_loading(
                                    "STATSB not a string array".to_string(),
                                ));
                            }
                        }
                        Err(_) => None,
                    };

                    if let (Some(family_size), Some(municipality), Some(family_type)) =
                        (family_size, municipality, family_type)
                    {
                        let mut builder = Covariate::demographics(
                            family_size,
                            municipality,
                            family_type.to_string(),
                        );

                        // Add citizenship if available
                        if let Some(statsb) = statsb {
                            builder = builder.with_citizenship(statsb.clone());

                            // Add translated value to metadata
                            if let Some(translated) = self
                                .translations
                                .translate(crate::translation::TranslationType::Statsb, &statsb)
                            {
                                builder = builder.with_metadata("statsb_translated", translated);
                            }
                        }

                        return Ok(Some(builder.build()));
                    }
                }
            }
        }
        Ok(None)
    }

    /// Optimize batch operations by slicing when needed
    pub fn optimize_batch(&mut self, batch: &mut RecordBatch) -> Result<()> {
        // Align buffers for better memory performance
        let _ = ArrowUtils::align_batch_buffers(batch);
        Ok(())
    }

    /// Slice a batch for zero-copy operations
    pub fn slice_batch(
        &self,
        batch: &RecordBatch,
        offset: usize,
        length: usize,
    ) -> Result<RecordBatch> {
        let mut columns = Vec::with_capacity(batch.num_columns());

        for i in 0..batch.num_columns() {
            columns.push(ArrowUtils::slice_array(
                batch.column(i).as_ref(),
                offset,
                length,
            ));
        }

        RecordBatch::try_new(batch.schema(), columns)
            .map_err(|e| IdsError::invalid_operation(format!("Failed to create sliced batch: {e}")))
    }

    /// Create an optimized string array
    pub fn create_optimized_string_array(&self, strings: &[String]) -> Result<StringArray> {
        ArrowUtils::create_optimized_string_array(strings, strings.len())
    }

    /// Find closest period date
    ///
    /// # Arguments
    /// * `date` - The target date
    /// * `data` - The data map to search in
    ///
    /// # Returns
    /// * `Result<Option<&'a String>>` - The closest period or None
    fn find_closest_period<'a>(
        &self,
        date: NaiveDate,
        data: &'a HashMap<String, Vec<RecordBatch>>,
    ) -> Result<Option<&'a String>> {
        Ok(data
            .keys()
            .filter(|p| {
                // Safely handle potential parsing errors with defaults
                if p.len() < 4 {
                    return false; // Period string too short for YYYY format
                }

                let year: i32 = match p[0..4].parse() {
                    Ok(y) => y,
                    Err(_) => return false, // Skip invalid year format
                };

                let month: u32 = if p.len() > 5 {
                    // Parse month safely, defaulting to December (12) for invalid input
                    match p[4..6].parse::<u32>() {
                        Ok(m) if m >= 1 && m <= 12 => m, // Valid month range
                        _ => 12,                         // Default to December for invalid month
                    }
                } else {
                    12 // Default to December when no month specified
                };

                // Only include periods that can be converted to valid dates and are before or equal to target date
                NaiveDate::from_ymd_opt(year, month, 1)
                    .is_some_and(|period_date| period_date <= date)
            })
            .max_by_key(|p| p.len()))
    }

    /// Load family relations from batches
    ///
    /// # Arguments
    /// * `family_batches` - The batches containing family relation data
    ///
    /// # Returns
    /// * `Result<()>` - Success or an error
    pub fn load_family_relations(&mut self, mut family_batches: Vec<RecordBatch>) -> Result<()> {
        // Optimize batches before loading
        for batch in &mut family_batches {
            // Validate batch
            if let Err(e) = self.validate_batch(batch) {
                log::warn!("Invalid family relations batch: {}", e);
            }

            // Optimize memory layout
            let _ = ArrowUtils::align_batch_buffers(batch);
        }

        let mut family_store = FamilyStore::new();
        family_store.load_family_relations(family_batches)?;
        self.family_data = family_store.get_relations().clone();
        Ok(())
    }

    // Helper methods to support the Arrow implementation

    /// Find the index of a PNR in a batch
    ///
    /// # Arguments
    /// * `batch` - The batch to search
    /// * `pnr` - The PNR to find
    ///
    /// # Returns
    /// * `Result<Option<usize>>` - The index or None
    fn find_pnr_index(&self, batch: &RecordBatch, pnr: &str) -> Result<Option<usize>> {
        if !batch.schema().fields().iter().any(|f| f.name() == "PNR") {
            return Ok(None);
        }

        let pnr_idx = batch.schema().index_of("PNR")?;
        let pnr_array = batch.column(pnr_idx);

        if let Some(string_array) = pnr_array.as_any().downcast_ref::<StringArray>() {
            for i in 0..string_array.len() {
                if !string_array.is_null(i) && string_array.value(i) == pnr {
                    return Ok(Some(i));
                }
            }
        }

        Ok(None)
    }

    /// Get a string array from a batch
    ///
    /// # Arguments
    /// * `batch` - The batch to get the array from
    /// * `column_name` - The column name
    ///
    /// # Returns
    /// * `Result<&'a StringArray>` - The string array or an error
    fn get_string_array<'a>(
        &self,
        batch: &'a RecordBatch,
        column_name: &str,
    ) -> Result<&'a StringArray> {
        let col_idx = batch.schema().index_of(column_name)?;
        let array = batch.column(col_idx);

        array.as_any().downcast_ref::<StringArray>().ok_or_else(|| {
            IdsError::data_loading(format!("Column {} is not a string array", column_name))
        })
    }

    /// Validate a batch
    ///
    /// # Arguments
    /// * `batch` - The batch to validate
    ///
    /// # Returns
    /// * `Result<()>` - Success or an error
    fn validate_batch(&self, batch: &RecordBatch) -> Result<()> {
        // Implementation to validate batch structure
        if batch.num_rows() == 0 {
            return Err(IdsError::data_loading("Empty batch".to_string()));
        }

        Ok(())
    }
}

impl Store for ArrowBackend {
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>> {
        match covariate_type {
            CovariateType::Education => self.get_education(pnr, date),
            CovariateType::Income => self.get_income(pnr, date),
            CovariateType::Demographics => self.get_demographics(pnr, date),
            CovariateType::Occupation => Ok(None), // Implement if needed
        }
    }

    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations> {
        self.family_data.get(pnr)
    }

    fn load_data(&mut self, _data: Vec<TimeVaryingValue<Covariate>>) -> Result<()> {
        Err(IdsError::invalid_operation(
            "Cannot load time-varying data into Arrow store",
        ))
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn as_any_mut(&mut self) -> &mut dyn std::any::Any {
        self
    }
}
</file>

<file path="src/store/data_store.rs">
use arrow::record_batch::RecordBatch;
use chrono::NaiveDate;
use std::path::Path;

use crate::{
    error::{IdsError, Result},
    family::FamilyRelations,
    models::{Covariate, CovariateType, TimeVaryingValue},
    storage::{self, arrow::backend::ArrowBackend, ThreadSafeStore},
    store::TimeVaryingBackend,
    traits::Store,
};

// Use the shared CacheKey from storage module
pub use storage::CacheKey;

/// Combined store implementation with different backend options and thread-safety
pub enum DataStore {
    Arrow(ThreadSafeStore<ArrowBackend>),
    TimeVarying(ThreadSafeStore<TimeVaryingBackend>),
}

impl DataStore {
    /// Create a new `DataStore` with an `ArrowBackend`
    pub fn new_arrow() -> Result<Self> {
        Ok(Self::Arrow(ThreadSafeStore::new(ArrowBackend::new()?)))
    }

    /// Create a new `DataStore` with a `TimeVaryingBackend`
    #[must_use]
    pub fn new_time_varying() -> Self {
        Self::TimeVarying(ThreadSafeStore::new(TimeVaryingBackend::new()))
    }

    /// Access the underlying arrow store (thread-safe)
    #[must_use]
    pub fn as_arrow_store(&self) -> Option<&ThreadSafeStore<ArrowBackend>> {
        match self {
            Self::Arrow(store) => Some(store),
            _ => None,
        }
    }

    /// Access the underlying time-varying store (thread-safe)
    #[must_use]
    pub fn as_time_varying_store(&self) -> Option<&ThreadSafeStore<TimeVaryingBackend>> {
        match self {
            Self::TimeVarying(store) => Some(store),
            _ => None,
        }
    }

    /// Check if this data store contains a specific backend type
    #[must_use]
    pub fn has_backend_type<T: Store + 'static>(&self) -> bool {
        match self {
            Self::Arrow(_) => std::any::TypeId::of::<ArrowBackend>() == std::any::TypeId::of::<T>(),
            Self::TimeVarying(_) => {
                std::any::TypeId::of::<TimeVaryingBackend>() == std::any::TypeId::of::<T>()
            }
        }
    }

    /// Load family relations data (only for arrow backend)
    pub fn load_family_relations(&mut self, batches: Vec<RecordBatch>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.load_family_relations(batches)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot load family relations into this backend type",
            )),
        }
    }

    /// Add AKM (labor market) data
    pub fn add_akm_data(&mut self, year: i32, batches: Vec<RecordBatch>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.add_akm_data(year, batches)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot add AKM data to this backend type",
            )),
        }
    }

    /// Add BEF (population) data
    pub fn add_bef_data(&mut self, period: String, batches: Vec<RecordBatch>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.add_bef_data(period, batches)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot add BEF data to this backend type",
            )),
        }
    }

    /// Add IND (income) data
    pub fn add_ind_data(&mut self, year: i32, batches: Vec<RecordBatch>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.add_ind_data(year, batches)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot add IND data to this backend type",
            )),
        }
    }

    /// Add UDDF (education) data
    pub fn add_uddf_data(&mut self, period: String, batches: Vec<RecordBatch>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.add_uddf_data(period, batches)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot add UDDF data to this backend type",
            )),
        }
    }

    /// Save current covariates to CSV (only for time-varying backend)
    pub fn save_to_csv(&self, path: &Path) -> Result<()> {
        match self {
            Self::TimeVarying(store) => {
                let backend = store.read();
                backend.save_to_csv(path)
            }
            _ => Err(IdsError::invalid_operation(
                "Cannot save this backend type to CSV",
            )),
        }
    }
}

impl Store for DataStore {
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>> {
        // Delegate to the appropriate backend with proper locking
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.covariate(pnr, covariate_type, date)
            }
            Self::TimeVarying(store) => {
                let mut backend = store.write();
                backend.covariate(pnr, covariate_type, date)
            }
        }
    }

    fn family_relations(&self, _pnr: &str) -> Option<&FamilyRelations> {
        // This implementation is inherently problematic with our RwLock approach.
        // We can't return a reference to data inside the lock, as the lock would be released.
        // For now, we'll return None, but this API needs to be restructured.
        None
    }

    fn load_data(&mut self, data: Vec<TimeVaryingValue<Covariate>>) -> Result<()> {
        match self {
            Self::Arrow(store) => {
                let mut backend = store.write();
                backend.load_data(data)
            }
            Self::TimeVarying(store) => {
                let mut backend = store.write();
                backend.load_data(data)
            }
        }
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn as_any_mut(&mut self) -> &mut dyn std::any::Any {
        self
    }
}
</file>

<file path="src/store/mod.rs">
mod data_store;
pub use data_store::{CacheKey, DataStore};

// We're consolidating on the storage::arrow::backend implementation
pub mod time_varying_backend;

pub use crate::storage::arrow::backend::ArrowBackend;
pub use time_varying_backend::TimeVaryingBackend;

/// Backend trait marker for storage implementations
pub trait Backend: crate::traits::Store {
    // All methods are already in Store trait
}
</file>

<file path="src/store/time_varying_backend.rs">
use chrono::NaiveDate;
use dashmap::DashMap;
use hashbrown::HashMap;
use std::path::Path;

use crate::{
    error::IdsError,
    family::FamilyRelations,
    models::{Covariate, CovariateType, TimeVaryingValue},
    traits::Store,
};

/// Time-varying storage backend
#[derive(Debug)]
pub struct TimeVaryingBackend {
    data: DashMap<String, Vec<TimeVaryingValue<Covariate>>>,
    family_data: HashMap<String, FamilyRelations>,
}

impl Default for TimeVaryingBackend {
    fn default() -> Self {
        Self::new()
    }
}

impl TimeVaryingBackend {
    /// Create a new time-varying backend
    #[must_use]
    pub fn new() -> Self {
        Self {
            data: DashMap::new(),
            family_data: HashMap::new(),
        }
    }

    /// Get the latest value at a specific date
    fn get_latest_value(
        &self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Option<Covariate> {
        self.data.get(pnr).and_then(|values| {
            values
                .iter()
                .filter(|v| v.date <= date && v.value.type_() == covariate_type)
                .max_by_key(|v| v.date)
                .map(|v| v.value.clone())
        })
    }

    /// Save data to CSV
    pub fn save_to_csv(&self, path: &Path) -> Result<(), IdsError> {
        let mut writer = csv::Writer::from_path(path).map_err(IdsError::Csv)?;

        writer
            .write_record(["PNR", "Date", "Covariate Type", "Value"])
            .map_err(IdsError::Csv)?;

        for entry in &self.data {
            for value in entry.value() {
                writer
                    .write_record([
                        &value.pnr,
                        &value.date.to_string(),
                        &format!("{:?}", value.value.type_()),
                        &format!("{:?}", value.value),
                    ])
                    .map_err(IdsError::Csv)?;
            }
        }

        writer.flush().map_err(IdsError::Io)?;
        Ok(())
    }

    /// Add family relation
    pub fn add_family_relation(&mut self, relation: FamilyRelations) {
        self.family_data.insert(relation.pnr.clone(), relation);
    }
}

impl Store for TimeVaryingBackend {
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>, IdsError> {
        Ok(self.get_latest_value(pnr, covariate_type, date))
    }

    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations> {
        self.family_data.get(pnr)
    }

    fn load_data(&mut self, data: Vec<TimeVaryingValue<Covariate>>) -> Result<(), IdsError> {
        for value in data {
            self.data.entry(value.pnr.clone()).or_default().push(value);
        }
        Ok(())
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn as_any_mut(&mut self) -> &mut dyn std::any::Any {
        self
    }
}
</file>

<file path="src/traits/access.rs">
use crate::error::Result;
use crate::models::family::relations::FamilyRelations;

// Conditionally import ArrowValue based on feature
#[cfg(not(feature = "arrow-integration"))]
use crate::models::TimeVaryingValue as ArrowValue;
#[cfg(feature = "arrow-integration")]
use crate::storage::arrow::values::ArrowValue;

/// Core trait for accessing data from a backend store
///
/// This trait defines the fundamental operations for retrieving data from
/// any storage backend. Implementations are responsible for providing efficient
/// access to stored data with proper error handling.
pub trait Store {
    /// Retrieves data for a specific year and field
    ///
    /// # Arguments
    /// * `year` - The year for which to retrieve data
    /// * `field` - The field name to retrieve
    ///
    /// # Returns
    /// * `Result<ArrowValue>` - The data wrapped in an `ArrowValue` or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The data does not exist for the given year/field
    /// - There was a problem accessing the data
    /// - The data could not be converted to an `ArrowValue`
    ///
    /// # Examples
    ///
    /// ```
    /// # use types::prelude::*;
    /// # fn example() -> Result<()> {
    /// # let store = DataStore::new();
    /// // Access data for 2020 employment status
    /// let employment_data = store.data(2020, "employment_status")?;
    /// # Ok(())
    /// # }
    /// ```
    fn data(&self, year: i32, field: &str) -> Result<ArrowValue>;

    /// Checks if data exists for a specific year and field
    ///
    /// # Arguments
    /// * `year` - The year to check
    /// * `field` - The field name to check
    ///
    /// # Returns
    /// * `bool` - True if the data exists, false otherwise
    ///
    /// # Examples
    ///
    /// ```
    /// # use types::prelude::*;
    /// # let store = DataStore::new();
    /// // Check if 2020 employment data exists
    /// if store.has_data(2020, "employment_status") {
    ///     println!("Data exists for 2020 employment status");
    /// }
    /// ```
    fn has_data(&self, year: i32, field: &str) -> bool;

    /// Returns all years available in the store
    ///
    /// # Returns
    /// * `Vec<i32>` - List of years for which data is available
    ///
    /// # Examples
    ///
    /// ```
    /// # use types::prelude::*;
    /// # let store = DataStore::new();
    /// // Get all available years
    /// let available_years = store.years();
    /// println!("Data available for years: {:?}", available_years);
    /// ```
    fn years(&self) -> Vec<i32>;

    /// Returns all fields available in the store
    ///
    /// # Returns
    /// * `Vec<String>` - List of field names available in the store
    ///
    /// # Examples
    ///
    /// ```
    /// # use types::prelude::*;
    /// # let store = DataStore::new();
    /// // Get all available fields
    /// let available_fields = store.fields();
    /// println!("Available fields: {:?}", available_fields);
    /// ```
    fn fields(&self) -> Vec<String>;

    /// Returns family relations if available
    ///
    /// # Returns
    /// * `Option<&FamilyRelations>` - Family relations data if available, None otherwise
    ///
    /// # Examples
    ///
    /// ```
    /// # use types::prelude::*;
    /// # let store = DataStore::new();
    /// // Access family relations data
    /// if let Some(family_data) = store.family_relations() {
    ///     println!("Family data available with {} families", family_data.count());
    /// }
    /// ```
    fn family_relations(&self) -> Option<&FamilyRelations>;
}

/// Backend implementation marker trait
///
/// This trait serves as a marker for types that implement the `Store` trait
/// and can be used as a backend in the data store. This allows for type-safe
/// extensions of backend functionality.
pub trait Backend: Store {}

// Automatically implement Backend for any type that implements Store
impl<T: Store> Backend for T {}
</file>

<file path="src/traits/cacheable.rs">
//! Cacheable trait for objects that support caching operations
//!
//! This trait provides a standardized interface for caching operations,
//! supporting both in-memory caching and potentially other storage backends.

use crate::error::IdsError;

/// Trait for cacheable operations
///
/// This trait defines a standard interface for objects that perform
/// cacheable operations, with methods for retrieving, computing, and
/// invalidating cached values.
///
/// # Type Parameters
///
/// * `K` - The key type for cache lookups
/// * `V` - The value type stored in the cache
pub trait Cacheable<K, V> {
    /// Get a value from the cache or compute it if not present
    ///
    /// This method tries to retrieve a value from the cache using the provided key.
    /// If the value is not found, it calls the compute function to generate the value,
    /// stores it in the cache, and returns it.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to look up in the cache
    /// * `compute_fn` - Function to generate the value if not found in cache
    ///
    /// # Returns
    ///
    /// * `Result<V, IdsError>` - The cached or computed value, or an error
    fn get_or_compute<F>(&self, key: K, compute_fn: F) -> Result<V, IdsError>
    where
        F: FnOnce() -> Result<V, IdsError>;

    /// Prefetch multiple values into the cache
    ///
    /// This method can be used to load multiple values into the cache
    /// in a single operation, which may be more efficient than individual lookups.
    ///
    /// # Arguments
    ///
    /// * `keys` - Slice of keys to prefetch
    ///
    /// # Returns
    ///
    /// * `Result<usize, IdsError>` - Number of items successfully prefetched, or an error
    fn prefetch(&self, keys: &[K]) -> Result<usize, IdsError>;

    /// Invalidate a cached value
    ///
    /// This method removes a value from the cache, forcing it to be
    /// recomputed on the next access.
    ///
    /// # Arguments
    ///
    /// * `key` - The key to invalidate
    ///
    /// # Returns
    ///
    /// * `bool` - True if the key was found and removed, false if not found
    fn invalidate(&self, key: &K) -> bool;

    /// Clear all cached values
    ///
    /// This method removes all values from the cache.
    fn clear(&self);
}
</file>

<file path="src/traits/mod.rs">
//! Traits for the ids-rs codebase.
//!
//! This module contains trait definitions that provide standardized interfaces
//! for various components of the system, including:
//!
//! - **Store**: Core trait for data storage and retrieval
//! - **`FamilyAccess`**: Trait for accessing family relations
//! - **`CovariateProcessor`**: Trait for processing covariates
//! - **`DateHelpers`**: Trait for date handling utilities
//! - **Cacheable**: Trait for cacheable objects
//! - **`TimeVaryingAccess`**: Trait for accessing time-varying data
//!
//! These traits allow for loose coupling between components and enable
//! alternative implementations of key functionality.

// Submodules
pub mod access;
pub mod cacheable;
pub mod processing;
pub mod utils;

// Imports
use crate::{
    error::Result,
    family::relations::FamilyRelations,
    models::{Covariate, CovariateType, TimeVaryingValue},
};
use chrono::NaiveDate;

// Re-exports
pub use self::cacheable::Cacheable;
pub use self::processing::{CovariateProcessor, VariableType};
pub use self::utils::DateHelpers;
pub use crate::storage::arrow::access::ArrowAccess;

/// Store trait for data storage and retrieval.
///
/// This trait defines the core interface for all data storage backends.
/// It provides methods for accessing covariates, family relations, and
/// loading data into the store.
///
/// # Examples
///
/// ```
/// use types::prelude::*;
/// use chrono::NaiveDate;
///
/// fn process_person_data<S: Store>(
///     store: &mut S,
///     pnr: &str,
///     date: NaiveDate
/// ) -> Result<()> {
///     // Get education covariate
///     if let Some(education) = store.covariate(pnr, CovariateType::Education, date)? {
///         println!("Education: {:?}", education);
///     }
///
///     // Get all covariates (example only, this method would also need &mut self)
///     let all_covariates = vec![]; // Placeholder for store.covariates(pnr, date)?
///     println!("Found {} covariates", all_covariates.len());
///
///     Ok(())
/// }
/// ```
pub trait Store: Send + Sync {
    /// Returns a specific covariate for a person at a given date.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    /// * `covariate_type` - The type of covariate to retrieve
    /// * `date` - The date at which to retrieve the covariate
    ///
    /// # Returns
    ///
    /// A Result containing an Option of the covariate, or an error if retrieval failed.
    /// The Option will be None if no covariate of the specified type exists for the
    /// person at the given date.
    fn covariate(
        &mut self,
        pnr: &str,
        covariate_type: CovariateType,
        date: NaiveDate,
    ) -> Result<Option<Covariate>>;

    /// Returns family relations for a person.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    ///
    /// # Returns
    ///
    /// An Option containing a reference to the family relations if they exist,
    /// or None if no family relations exist for the person.
    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations>;

    /// Loads data into the store.
    ///
    /// # Parameters
    ///
    /// * `data` - A vector of time-varying covariates to load
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure of the operation.
    fn load_data(&mut self, data: Vec<TimeVaryingValue<Covariate>>) -> Result<()>;

    /// Returns all covariates for a person at a given date.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    /// * `date` - The date at which to retrieve the covariates
    ///
    /// # Returns
    ///
    /// A Result containing a `HashMap` of covariates indexed by type,
    /// or an error if retrieval failed.
    fn covariates(
        &mut self,
        pnr: &str,
        date: NaiveDate,
    ) -> Result<hashbrown::HashMap<CovariateType, Covariate>> {
        let mut covariates = hashbrown::HashMap::new();

        for covariate_type in &[
            CovariateType::Demographics,
            CovariateType::Education,
            CovariateType::Income,
            CovariateType::Occupation,
        ] {
            if let Some(covariate) = self.covariate(pnr, *covariate_type, date)? {
                covariates.insert(*covariate_type, covariate);
            }
        }

        Ok(covariates)
    }

    /// Returns covariates for a person's family at a given date.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    /// * `date` - The date at which to retrieve the covariates
    ///
    /// # Returns
    ///
    /// A Result containing an Option of a `HashMap` of covariates indexed by type,
    /// or an error if retrieval failed. The Option will be None if the person has
    /// no family relations or if no covariates exist for the family.
    fn family_covariates(
        &mut self,
        pnr: &str,
        date: NaiveDate,
    ) -> Result<Option<hashbrown::HashMap<CovariateType, Covariate>>> {
        let family = self.family_relations(pnr);

        if let Some(_family) = family {
            let covariates = self.covariates(pnr, date)?;
            if !covariates.is_empty() {
                return Ok(Some(covariates));
            }
        }

        Ok(None)
    }

    /// Converts to Any for dynamic casting.
    ///
    /// This method is primarily used for internal type conversions
    /// and should not be used directly in most cases.
    fn as_any(&self) -> &dyn std::any::Any;

    /// Converts to Any for dynamic casting (mutable).
    ///
    /// This method is primarily used for internal type conversions
    /// and should not be used directly in most cases.
    fn as_any_mut(&mut self) -> &mut dyn std::any::Any;
}

/// Trait for accessing family relations.
///
/// This trait provides methods for accessing family relations,
/// including parents and birth dates.
///
/// # Examples
///
/// ```
/// use types::prelude::*;
/// use chrono::NaiveDate;
///
/// fn print_family_info<F: FamilyAccess>(family_access: &F, pnr: &str) {
///     // Get parents
///     if let Some((father, mother)) = family_access.parents(pnr) {
///         println!("Father: {:?}, Mother: {:?}", father, mother);
///     }
///
///     // Get birth date
///     if let Some(birth_date) = family_access.birth_date(pnr) {
///         println!("Birth date: {}", birth_date);
///     }
/// }
/// ```
pub trait FamilyAccess {
    /// Returns family relations for a person.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    ///
    /// # Returns
    ///
    /// An Option containing a reference to the family relations if they exist,
    /// or None if no family relations exist for the person.
    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations>;

    /// Returns the parents' PNRs for a person.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    ///
    /// # Returns
    ///
    /// An Option containing a tuple of Options for father and mother PNRs,
    /// or None if no family relations exist for the person.
    fn parents(&self, pnr: &str) -> Option<(Option<String>, Option<String>)>;

    /// Returns the birth date for a person.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    ///
    /// # Returns
    ///
    /// An Option containing the birth date if it exists,
    /// or None if no birth date exists for the person.
    fn birth_date(&self, pnr: &str) -> Option<NaiveDate>;
}

/// Trait for accessing time-varying data.
///
/// This trait provides methods for accessing data that varies over time,
/// such as covariates that change at different dates.
///
/// # Type Parameters
///
/// * `T` - The type of data being accessed
///
/// # Examples
///
/// ```
/// use types::prelude::*;
/// use chrono::NaiveDate;
///
/// fn print_data_at_date<A: TimeVaryingAccess<Covariate>>(
///     access: &A,
///     pnr: &str,
///     date: NaiveDate
/// ) {
///     if let Some(covariates) = access.at_date(pnr, date) {
///         println!("Found {} covariates at {}", covariates.len(), date);
///     }
/// }
/// ```
pub trait TimeVaryingAccess<T> {
    /// Returns data for a person at a given date.
    ///
    /// # Parameters
    ///
    /// * `pnr` - The personal identification number (PNR)
    /// * `date` - The date at which to retrieve the data
    ///
    /// # Returns
    ///
    /// An Option containing a vector of data if it exists,
    /// or None if no data exists for the person at the given date.
    fn at_date(&self, pnr: &str, date: NaiveDate) -> Option<Vec<T>>;

    /// Loads data into the store.
    ///
    /// # Parameters
    ///
    /// * `data` - A vector of time-varying data to load
    ///
    /// # Returns
    ///
    /// A Result indicating success or failure of the operation.
    fn load_data(&self, data: Vec<TimeVaryingValue<T>>) -> Result<()>;
}

// Implement FamilyAccess for any type that implements Store
impl<T: Store> FamilyAccess for T {
    fn family_relations(&self, pnr: &str) -> Option<&FamilyRelations> {
        Store::family_relations(self, pnr)
    }

    fn parents(&self, pnr: &str) -> Option<(Option<String>, Option<String>)> {
        self.family_relations(pnr)
            .map(|rel| (rel.father_id.clone(), rel.mother_id.clone()))
    }

    fn birth_date(&self, pnr: &str) -> Option<NaiveDate> {
        self.family_relations(pnr).map(|rel| rel.birth_date)
    }
}
</file>

<file path="src/traits/processing.rs">
use crate::error::Result;
use crate::models::covariate::{Covariate, CovariateType};
use crate::traits::access::Store;

/// Variable type for covariate processing
#[derive(Debug, Clone, Copy, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub enum VariableType {
    /// Numeric variable (f64)
    Numeric,
    /// Categorical variable (String)
    Categorical,
    /// Binary variable (0 or 1)
    Binary,
}

/// Trait for processing covariate data from a data store
///
/// This trait defines the core functionality for processors that transform
/// raw data from a store into structured covariate values. Implementations
/// are responsible for handling specific covariate types and applying the
/// appropriate transformations.
pub trait CovariateProcessor: Send + Sync {
    /// Process covariate data for a specific year
    ///
    /// # Arguments
    /// * `store` - The data store containing source data
    /// * `year` - The year for which to process data
    ///
    /// # Returns
    /// * `Result<Covariate>` - The processed covariate data or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - Required data is missing from the store
    /// - Processing fails due to invalid or inconsistent data
    /// - Type conversion errors occur
    fn process(&self, store: &dyn Store, year: i32) -> Result<Covariate>;

    /// Get the type of covariate this processor handles
    ///
    /// # Returns
    /// * `CovariateType` - The type of covariate this processor generates
    fn covariate_type(&self) -> CovariateType;

    /// Get the field names required by this processor
    ///
    /// # Returns
    /// * `Vec<String>` - List of field names needed from the store
    fn required_fields(&self) -> Vec<String>;

    /// Check if the processor can run with the available data
    ///
    /// # Arguments
    /// * `store` - The data store to check
    /// * `year` - The year to check
    ///
    /// # Returns
    /// * `bool` - True if all required fields are available, false otherwise
    fn can_process(&self, store: &dyn Store, year: i32) -> bool {
        self.required_fields()
            .iter()
            .all(|field| store.has_data(year, field))
    }

    /// Get the name of this processor
    fn name(&self) -> &str;

    /// Determine if this variable should be treated as categorical
    fn is_categorical(&self) -> bool;

    /// Get the variable type for this processor
    fn variable_type(&self) -> VariableType {
        if self.is_categorical() {
            VariableType::Categorical
        } else {
            VariableType::Numeric
        }
    }

    /// Extract a numeric value from a covariate, returning None if not applicable
    fn process_numeric(&self, covariate: &Covariate) -> Option<f64>;

    /// Extract a categorical value from a covariate, returning None if not applicable
    fn process_categorical(&self, covariate: &Covariate) -> Option<String>;

    /// Convert a categorical value to a numeric representation if needed for calculations
    fn categorical_to_numeric(&self, value: &str) -> f64 {
        if let Ok(num) = value.parse::<f64>() {
            num
        } else {
            // Hash the string to create a stable numeric value
            let mut hash = 0.0;
            for (i, b) in value.bytes().enumerate() {
                hash += f64::from(b) * (i + 1) as f64;
            }
            hash
        }
    }
}

/// Extension trait for covariate processors with additional utility methods
pub trait CovariateProcessorExt: CovariateProcessor {
    /// Process covariate data for multiple years
    ///
    /// # Arguments
    /// * `store` - The data store containing source data
    /// * `years` - The years for which to process data
    ///
    /// # Returns
    /// * `Result<Vec<Covariate>>` - The processed covariate data for each year or an error
    ///
    /// # Errors
    /// Returns an error if processing fails for any year
    fn process_years(&self, store: &dyn Store, years: &[i32]) -> Result<Vec<Covariate>>;

    /// Process all available years in the store
    ///
    /// # Arguments
    /// * `store` - The data store containing source data
    ///
    /// # Returns
    /// * `Result<Vec<Covariate>>` - The processed covariate data for all years or an error
    ///
    /// # Errors
    /// Returns an error if processing fails for any year
    fn process_all_years(&self, store: &dyn Store) -> Result<Vec<Covariate>>;

    /// Find the latest year that can be processed
    ///
    /// # Arguments
    /// * `store` - The data store to check
    ///
    /// # Returns
    /// * `Option<i32>` - The latest year that can be processed, or None if no year can be processed
    fn latest_processable_year(&self, store: &dyn Store) -> Option<i32>;
}

// Implement the extension trait for any type that implements CovariateProcessor
impl<T: CovariateProcessor> CovariateProcessorExt for T {
    fn process_years(&self, store: &dyn Store, years: &[i32]) -> Result<Vec<Covariate>> {
        let mut results = Vec::with_capacity(years.len());

        for &year in years {
            if self.can_process(store, year) {
                results.push(self.process(store, year)?);
            }
        }

        Ok(results)
    }

    fn process_all_years(&self, store: &dyn Store) -> Result<Vec<Covariate>> {
        let years = store.years();
        self.process_years(store, &years)
    }

    fn latest_processable_year(&self, store: &dyn Store) -> Option<i32> {
        store
            .years()
            .into_iter()
            .filter(|&year| self.can_process(store, year))
            .max()
    }
}

// For backward compatibility
pub trait LegacyCovariateProcessor: CovariateProcessor {
    fn get_name(&self) -> &str {
        self.name()
    }

    fn get_covariate_type(&self) -> CovariateType {
        self.covariate_type()
    }

    fn get_variable_type(&self) -> VariableType {
        self.variable_type()
    }
}

// Implement LegacyCovariateProcessor for all CovariateProcessor implementors
impl<T: CovariateProcessor + ?Sized> LegacyCovariateProcessor for T {}
</file>

<file path="src/traits/utils.rs">
use chrono::{Datelike, NaiveDate};

use crate::error::{IdsError, Result};

/// Trait for date-related helper functions
///
/// This trait provides common operations for working with dates,
/// with consistent error handling.
pub trait DateHelpers {
    /// Convert to `NaiveDate`
    ///
    /// # Returns
    /// * `Result<NaiveDate>` - The date as a `NaiveDate` or an error
    ///
    /// # Errors
    /// Returns an error if the conversion fails
    fn to_naive_date(&self) -> Result<NaiveDate>;

    /// Get year from date
    ///
    /// # Returns
    /// * `Result<i32>` - The year as an i32 or an error
    ///
    /// # Errors
    /// Returns an error if the conversion to `NaiveDate` fails
    fn year(&self) -> Result<i32>;

    /// Calculate age at a reference date
    ///
    /// # Arguments
    /// * `reference_date` - The date at which to calculate the age
    ///
    /// # Returns
    /// * `Result<u32>` - The age in years or an error
    ///
    /// # Errors
    /// Returns an error if:
    /// - The conversion to `NaiveDate` fails
    /// - The calculation yields an invalid age (e.g., negative)
    fn age_at(&self, reference_date: &NaiveDate) -> Result<u32>;

    /// Check if date is in a specific year
    ///
    /// # Arguments
    /// * `year` - The year to check against
    ///
    /// # Returns
    /// * `Result<bool>` - True if the date is in the specified year, false otherwise
    ///
    /// # Errors
    /// Returns an error if the conversion to `NaiveDate` fails
    fn is_in_year(&self, year: i32) -> Result<bool>;

    /// Get month from date
    ///
    /// # Returns
    /// * `Result<u32>` - The month as a u32 (1-12) or an error
    ///
    /// # Errors
    /// Returns an error if the conversion to `NaiveDate` fails
    fn month(&self) -> Result<u32>;

    /// Get day from date
    ///
    /// # Returns
    /// * `Result<u32>` - The day as a u32 (1-31) or an error
    ///
    /// # Errors
    /// Returns an error if the conversion to `NaiveDate` fails
    fn day(&self) -> Result<u32>;

    /// Get the quarter (1-4) for this date
    ///
    /// # Returns
    /// * `Result<u32>` - The quarter (1-4) or an error
    ///
    /// # Errors
    /// Returns an error if the conversion to `NaiveDate` fails
    fn quarter(&self) -> Result<u32> {
        Ok(((self.month()? - 1) / 3) + 1)
    }
}

/// Implementation of `DateHelpers` for i32 (days since epoch)
///
/// This implementation safely converts an integer representing days since the Common Era
/// into a `NaiveDate`, using the safer `from_num_days_from_ce_opt` method
/// that returns an Option rather than panicking.
impl DateHelpers for i32 {
    /// Convert days since epoch to `NaiveDate`
    ///
    /// # Returns
    /// * `Result<NaiveDate>` - The date as a `NaiveDate` or an error
    ///
    /// # Errors
    /// Returns a `date_conversion` error if the integer value doesn't represent a valid date
    ///
    /// # Safety
    /// Uses the non-panicking `from_num_days_from_ce_opt` method rather than the deprecated
    /// `from_num_days_from_ce` method for improved safety.
    fn to_naive_date(&self) -> Result<NaiveDate> {
        NaiveDate::from_num_days_from_ce_opt(*self)
            .ok_or_else(|| IdsError::date_conversion(format!("Invalid days since epoch: {self}")))
    }

    fn year(&self) -> Result<i32> {
        let date = self.to_naive_date()?;
        Ok(Datelike::year(&date))
    }

    fn age_at(&self, reference_date: &NaiveDate) -> Result<u32> {
        let birth_date = self.to_naive_date()?;

        if birth_date > *reference_date {
            return Err(IdsError::invalid_value(format!(
                "Birth date ({birth_date}) is after reference date ({reference_date})"
            )));
        }

        let mut age = Datelike::year(reference_date) - Datelike::year(&birth_date);

        // Adjust if birthday hasn't occurred yet in the reference year
        if Datelike::month(reference_date) < Datelike::month(&birth_date)
            || (Datelike::month(reference_date) == Datelike::month(&birth_date)
                && Datelike::day(reference_date) < Datelike::day(&birth_date))
        {
            age -= 1;
        }

        Ok(age as u32)
    }

    fn is_in_year(&self, year: i32) -> Result<bool> {
        Ok(self.year()? == year)
    }

    fn month(&self) -> Result<u32> {
        let date = self.to_naive_date()?;
        Ok(Datelike::month(&date))
    }

    fn day(&self) -> Result<u32> {
        let date = self.to_naive_date()?;
        Ok(Datelike::day(&date))
    }
}

/// Implementation of `DateHelpers` for `NaiveDate` directly
impl DateHelpers for NaiveDate {
    fn to_naive_date(&self) -> Result<NaiveDate> {
        Ok(*self)
    }

    fn year(&self) -> Result<i32> {
        Ok(Datelike::year(self))
    }

    fn age_at(&self, reference_date: &NaiveDate) -> Result<u32> {
        if self > reference_date {
            return Err(IdsError::invalid_value(format!(
                "Birth date ({self}) is after reference date ({reference_date})"
            )));
        }

        let mut age = Datelike::year(reference_date) - Datelike::year(self);

        // Adjust if birthday hasn't occurred yet in the reference year
        if Datelike::month(reference_date) < Datelike::month(self)
            || (Datelike::month(reference_date) == Datelike::month(self)
                && Datelike::day(reference_date) < Datelike::day(self))
        {
            age -= 1;
        }

        Ok(age as u32)
    }

    fn is_in_year(&self, year: i32) -> Result<bool> {
        Ok(Datelike::year(self) == year)
    }

    fn month(&self) -> Result<u32> {
        Ok(Datelike::month(self))
    }

    fn day(&self) -> Result<u32> {
        Ok(Datelike::day(self))
    }
}

/// Implementation of `DateHelpers` for Option<i32>
impl DateHelpers for Option<i32> {
    fn to_naive_date(&self) -> Result<NaiveDate> {
        match self {
            Some(days) => days.to_naive_date(),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn year(&self) -> Result<i32> {
        match self {
            Some(days) => days.year(),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn age_at(&self, reference_date: &NaiveDate) -> Result<u32> {
        match self {
            Some(days) => days.age_at(reference_date),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn is_in_year(&self, year: i32) -> Result<bool> {
        match self {
            Some(days) => days.is_in_year(year),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn month(&self) -> Result<u32> {
        match self {
            Some(days) => days.month(),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn day(&self) -> Result<u32> {
        match self {
            Some(days) => days.day(),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }
}

/// Implementation of `DateHelpers` for Option<NaiveDate>
impl DateHelpers for Option<NaiveDate> {
    fn to_naive_date(&self) -> Result<NaiveDate> {
        match self {
            Some(date) => Ok(*date),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn year(&self) -> Result<i32> {
        match self {
            Some(date) => Ok(Datelike::year(date)),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn age_at(&self, reference_date: &NaiveDate) -> Result<u32> {
        match self {
            Some(date) => DateHelpers::age_at(date, reference_date),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn is_in_year(&self, year: i32) -> Result<bool> {
        match self {
            Some(date) => Ok(Datelike::year(date) == year),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn month(&self) -> Result<u32> {
        match self {
            Some(date) => Ok(Datelike::month(date)),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }

    fn day(&self) -> Result<u32> {
        match self {
            Some(date) => Ok(Datelike::day(date)),
            None => Err(IdsError::missing_value("Date is null".to_string())),
        }
    }
}
</file>

<file path="src/translation/mod.rs">
use hashbrown::HashMap;
use std::fs::File;
use std::path::Path;

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum TranslationType {
    Statsb,
    Civst,
    FamilyType,
    FmMark,
    Hustype,
    Reg,
    Socio13,
    Hfaudd,
}

#[derive(Debug, Clone)]
pub struct TranslationMaps {
    maps: HashMap<TranslationType, HashMap<String, String>>,
}

impl TranslationMaps {
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        // First try loading from files
        match Self::load_from_files() {
            Ok(maps) => {
                log::info!("Successfully loaded translation maps from files");
                Ok(maps)
            }
            Err(e) => {
                log::warn!(
                    "Failed to load translation maps from files: {e}. Using embedded maps instead."
                );
                Ok(Self::load_embedded())
            }
        }
    }

    fn load_from_files() -> Result<Self, Box<dyn std::error::Error>> {
        let mut maps = HashMap::new();

        maps.insert(
            TranslationType::Statsb,
            load_translation_map("mappings/statsb.json")?,
        );
        maps.insert(
            TranslationType::Civst,
            load_translation_map("mappings/civst.json")?,
        );
        maps.insert(
            TranslationType::FamilyType,
            load_translation_map("mappings/family_type.json")?,
        );
        maps.insert(
            TranslationType::FmMark,
            load_translation_map("mappings/fm_mark.json")?,
        );
        maps.insert(
            TranslationType::Hustype,
            load_translation_map("mappings/hustype.json")?,
        );
        maps.insert(
            TranslationType::Reg,
            load_translation_map("mappings/reg.json")?,
        );
        maps.insert(
            TranslationType::Socio13,
            load_translation_map("mappings/socio13.json")?,
        );
        maps.insert(
            TranslationType::Hfaudd,
            load_translation_map("mappings/hfaudd.json")?,
        );

        Ok(Self { maps })
    }

    fn load_embedded() -> Self {
        let mut maps = HashMap::new();

        maps.insert(
            TranslationType::Statsb,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/statsb.json"
            )),
        );
        maps.insert(
            TranslationType::Civst,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/civst.json"
            )),
        );
        maps.insert(
            TranslationType::FamilyType,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/family_type.json"
            )),
        );
        maps.insert(
            TranslationType::FmMark,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/fm_mark.json"
            )),
        );
        maps.insert(
            TranslationType::Hustype,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/hustype.json"
            )),
        );
        maps.insert(
            TranslationType::Reg,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/reg.json"
            )),
        );
        maps.insert(
            TranslationType::Socio13,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/socio13.json"
            )),
        );
        maps.insert(
            TranslationType::Hfaudd,
            parse_embedded_json(include_str!(
                "../../../ids/python/ids_toolkit/mappings/hfaudd.json"
            )),
        );

        Self { maps }
    }

    /// Create an empty translation map for diagnostic purposes
    #[must_use]
    pub fn new_empty() -> Self {
        Self {
            maps: HashMap::new(),
        }
    }

    pub fn translate(&self, translation_type: TranslationType, code: &str) -> Option<&str> {
        self.maps
            .get(&translation_type)?
            .get(code)
            .map(String::as_str)
    }

    /// Get all codes that translate to a specific value for a given translation type
    /// Useful for finding all HFAUDD codes that map to a specific ISCED level
    #[must_use]
    pub fn get_codes_for_value(
        &self,
        translation_type: TranslationType,
        value: &str,
    ) -> Vec<String> {
        if let Some(map) = self.maps.get(&translation_type) {
            map.iter()
                .filter(|(_, v)| v == &value)
                .map(|(k, _)| k.clone())
                .collect()
        } else {
            Vec::new()
        }
    }
}

// Parse JSON string to HashMap
fn parse_embedded_json(json_str: &str) -> HashMap<String, String> {
    match serde_json::from_str(json_str) {
        Ok(map) => map,
        Err(e) => {
            log::error!("Failed to parse embedded JSON: {e}");
            HashMap::new()
        }
    }
}

fn load_translation_map(path: &str) -> Result<HashMap<String, String>, Box<dyn std::error::Error>> {
    // Log the attempted path
    log::info!("Loading translation map from path: {path}");

    // Try locations in order of priority:
    // 1. Check if there's an environment variable specifying mappings directory
    // 2. Try the provided path directly
    // 3. Try with current directory

    // First, check for environment variable IDS_MAPPINGS_DIR
    if let Ok(mappings_dir) = std::env::var("IDS_MAPPINGS_DIR") {
        let file_name = Path::new(path).file_name().ok_or("Invalid path")?;
        let env_path = Path::new(&mappings_dir).join(file_name);
        log::info!("Trying path from IDS_MAPPINGS_DIR: {}", env_path.display());

        if let Ok(file) = File::open(&env_path) {
            let map: HashMap<String, String> = serde_json::from_reader(file)?;
            return Ok(map);
        }

        log::warn!(
            "Failed to open translation map at environment path: {}",
            env_path.display()
        );
    }

    // Try the provided path directly
    let file_result = File::open(Path::new(path));

    if let Err(ref e) = file_result {
        log::warn!("Failed to open translation map at {path}: {e}");

        // Try with current directory
        let current_dir = std::env::current_dir()?;
        let absolute_path = current_dir.join(path);
        log::info!("Trying absolute path: {}", absolute_path.display());

        let file = File::open(absolute_path)?;
        let map: HashMap<String, String> = serde_json::from_reader(file)?;
        return Ok(map);
    }

    let file = file_result?;
    let map: HashMap<String, String> = serde_json::from_reader(file)?;
    Ok(map)
}
</file>

<file path="src/utils/logging.rs">
//! Logging utilities and helpers.
//!
//! This module provides utilities for initializing and using the logging system.
//! It is only available when the `logging` feature is enabled.

use crate::error::{IdsError, Result};

/// Initializes the logging system with sensible defaults.
///
/// This function sets up the logging system with reasonable defaults for console output.
/// It automatically detects if the program is running in a terminal and adjusts the output accordingly.
///
/// # Returns
///
/// A Result indicating whether the logging system was successfully initialized.
///
/// # Errors
///
/// Returns an error if the logging system could not be initialized.
pub fn init_logger() -> Result<()> {
    log::set_max_level(log::LevelFilter::Info);
    log::info!("Logging initialized at info level");
    Ok(())
}

/// Initializes the logging system with the specified log level.
///
/// This function sets up the logging system with the specified log level for console output.
///
/// # Parameters
///
/// * `level` - The log level to use (trace, debug, info, warn, error)
///
/// # Returns
///
/// A Result indicating whether the logging system was successfully initialized.
///
/// # Errors
///
/// Returns an error if the logging system could not be initialized or if the log level is invalid.
pub fn init_logger_with_level(level: &str) -> Result<()> {
    let log_level = match level.to_lowercase().as_str() {
        "trace" => log::LevelFilter::Trace,
        "debug" => log::LevelFilter::Debug,
        "info" => log::LevelFilter::Info,
        "warn" => log::LevelFilter::Warn,
        "error" => log::LevelFilter::Error,
        _ => {
            return Err(IdsError::validation(format!(
                "Invalid log level: {level}"
            )))
        }
    };

    log::set_max_level(log_level);
    log::info!("Logging initialized at {level} level");
    Ok(())
}

/// Logs a message at the debug level.
///
/// This macro is a convenience wrapper around `log::debug`! that is conditionally compiled
/// based on the logging feature.
#[macro_export]
macro_rules! log_debug {
    ($($arg:tt)*) => {
        log::debug!($($arg)*);
    };
}

/// Logs a message at the info level.
///
/// This macro is a convenience wrapper around `log::info`! that is conditionally compiled
/// based on the logging feature.
#[macro_export]
macro_rules! log_info {
    ($($arg:tt)*) => {
        log::info!($($arg)*);
    };
}

/// Logs a message at the warn level.
///
/// This macro is a convenience wrapper around `log::warn`! that is conditionally compiled
/// based on the logging feature.
#[macro_export]
macro_rules! log_warn {
    ($($arg:tt)*) => {
        log::warn!($($arg)*);
    };
}

/// Logs a message at the error level.
///
/// This macro is a convenience wrapper around `log::error`! that is conditionally compiled
/// based on the logging feature.
#[macro_export]
macro_rules! log_error {
    ($($arg:tt)*) => {
        log::error!($($arg)*);
    };
}
</file>

<file path="src/utils/mod.rs">
//! Utility functions and helpers for common operations.
//!
//! This module provides various utility functions and helpers that are used
//! throughout the codebase, including:
//!
//! - Date handling utilities
//! - String manipulation functions
//! - Translation maps and utilities
//! - Logging utilities
//! - Common constants and default values
//!
//! Many of these utilities were previously scattered across different modules
//! and have been consolidated here for better organization.

// Re-export utilities from other modules
pub use crate::traits::utils::DateHelpers;
pub use crate::translation::{TranslationMaps, TranslationType};

#[cfg(feature = "logging")]
pub mod logging;

/// Date-related utilities for formatting and parsing.
pub mod date {
    use crate::error::{IdsError, Result};
    use chrono::NaiveDate;

    /// Formats a date as a string in the specified format.
    ///
    /// # Parameters
    ///
    /// * `date` - The date to format
    /// * `format` - The format string to use (defaults to "%Y-%m-%d")
    ///
    /// # Returns
    ///
    /// A string containing the formatted date.
    ///
    /// # Errors
    ///
    /// This function will not error, but will return a placeholder string
    /// if the date is None.
    #[must_use] pub fn format_date(date: Option<NaiveDate>, format: Option<&str>) -> String {
        let format_str = format.unwrap_or("%Y-%m-%d");
        match date {
            Some(d) => d.format(format_str).to_string(),
            None => "N/A".to_string(),
        }
    }

    /// Parses a date string using the `DateHelpers` trait.
    ///
    /// This is a convenience wrapper around the `DateHelpers` trait that
    /// provides a more ergonomic API for date parsing.
    ///
    /// # Parameters
    ///
    /// * `date_str` - The date string to parse
    ///
    /// # Returns
    ///
    /// A Result containing the parsed date, or an error if parsing failed.
    pub fn parse_date(date_str: &str) -> Result<NaiveDate> {
        // Try to parse date in format 'YYYY-MM-DD'
        NaiveDate::parse_from_str(date_str, "%Y-%m-%d").map_err(|e| {
            IdsError::invalid_date(format!("Failed to parse date '{date_str}': {e}"))
        })
    }

    /// Parses a year string into an i32.
    ///
    /// # Parameters
    ///
    /// * `year_str` - The year string to parse
    ///
    /// # Returns
    ///
    /// A Result containing the parsed year, or an error if parsing failed.
    pub fn parse_year(year_str: &str) -> Result<i32> {
        year_str.parse::<i32>().map_err(|e| {
            IdsError::invalid_format(format!("Failed to parse year '{year_str}': {e}"))
        })
    }
}

/// String utilities for common string manipulations.
pub mod string {
    /// Sanitizes a string for use as an identifier, replacing invalid characters with underscores.
    ///
    /// # Parameters
    ///
    /// * `input` - The string to sanitize
    ///
    /// # Returns
    ///
    /// A sanitized string that can be used as an identifier.
    #[must_use] pub fn sanitize_identifier(input: &str) -> String {
        input
            .chars()
            .map(|c| {
                if c.is_alphanumeric() || c == '_' {
                    c
                } else {
                    '_'
                }
            })
            .collect()
    }

    /// Truncates a string to the specified length, adding an ellipsis if truncated.
    ///
    /// # Parameters
    ///
    /// * `input` - The string to truncate
    /// * `max_length` - The maximum length
    ///
    /// # Returns
    ///
    /// A truncated string, with an ellipsis if truncated.
    #[must_use] pub fn truncate(input: &str, max_length: usize) -> String {
        if input.len() <= max_length {
            input.to_string()
        } else {
            format!("{}...", &input[0..max_length.saturating_sub(3)])
        }
    }
}
</file>

<file path="src/config.rs">
#[derive(Debug, Clone)]
pub struct Config {
    pub output_dir: String,
    pub log_level: String,
    // Add other common configuration
}
</file>

<file path="src/lib.rs">
//! # IDS Types
//!
//! Core type definitions and foundational abstractions for the IDS-RS workspace.
//!
//! This crate serves as the foundation for the entire IDS-RS system, providing:
//!
//! - Common data types and models for epidemiological research
//! - Trait definitions used across the codebase
//! - Error handling patterns and standardization
//! - Storage abstractions for different data backends
//! - Utilities for working with Arrow data
//!
//! ## Getting Started
//!
//! The easiest way to get started is to import the prelude module, which
//! provides all commonly used types and traits:
//!
//! ```rust
//! use types::prelude::*;
//!
//! // Create a data store
//! let mut store = DataStore::new();
//!
//! // Work with covariates
//! let education = EducationBuilder::new("higher")
//!     .with_years(16.0)
//!     .build();
//!
//! let demographics = DemographicsBuilder::new(2, 101, "nuclear")
//!     .with_age(42)
//!     .with_gender("M")
//!     .build();
//!
//! // Combine them using the builder pattern
//! let combined_covariate = CovariateBuilder::new()
//!     .with_education(education)
//!     .with_demographics(demographics)
//!     .build();
//! ```
//!
//! ## Core Components
//!
//! - **Models**: Data structures for demographic, health, and registry data
//! - **Traits**: Interfaces for covariate processing, data access, and storage
//! - **Error Handling**: Standardized error types and propagation patterns
//! - **Storage**: Abstractions for data storage and retrieval
//! - **Arrow Utilities**: Helpers for working with Apache Arrow data format
//!
//! ## Feature Flags
//!
//! The following feature flags will be available in future releases:
//!
//! - `arrow-integration` - Integration with Apache Arrow (enabled by default)
//! - `serde-support` - Serialization/deserialization via serde (enabled by default)
//! - `chrono-nightly` - Enables nightly chrono features for improved date handling
//! - `polars-integration` - Integration with the polars `DataFrame` library
//! - `logging` - Logging functionality (enabled by default)

// Core public modules
pub mod error;
pub mod models;
pub mod prelude;
pub mod storage;
pub mod traits;
pub mod utils;

// Internal modules - considered implementation details
// Only public for backward compatibility
// To maintain backward compatibility while encouraging use of the newer APIs,
// these modules are exported with #[doc(hidden)] to discourage their use.
#[doc(hidden)]
pub use storage::arrow;
#[doc(hidden)]
pub mod config;
#[doc(hidden)]
pub mod family;
#[doc(hidden)]
pub mod store;
#[doc(hidden)]
pub mod translation;

// Re-export essential types at the crate root
// These are the most commonly used types that users will need
pub use self::error::{IdsError, Result};
pub use self::models::{Covariate, CovariateType, CovariateValue, TimeVaryingValue};
pub use self::models::{Pnr, PnrPool};
#[cfg(feature = "arrow-integration")]
pub use self::storage::arrow::ArrowBackend;
pub use self::store::DataStore;
pub use self::traits::{DateHelpers, Store};

// Type aliases for backward compatibility
#[doc(hidden)]
pub type OldFamilyRelations = family::relations::FamilyRelations;
</file>

<file path="src/prelude.rs">
//! Convenient imports for common types and traits.
//!
//! This module re-exports the most commonly used types and traits from the crate,
//! allowing users to import everything they need with a single import statement.
//!
//! # Examples
//!
//! ```
//! use types::prelude::*;
//!
//! // Create a data store
//! let mut store = DataStore::new();
//!
//! // Create and use covariates
//! let education = EducationBuilder::new("higher")
//!     .with_years(16.0)
//!     .build();
//! ```
//!
//! ## Feature-gated imports
//!
//! Some imports are only available when specific features are enabled:
//!
//! ```
//! use types::prelude::*;
//!
//! // Arrow integration (requires 'arrow-integration' feature)
//! # #[cfg(feature = "arrow-integration")]
//! let arrow_backend = ArrowBackend::new();
//!
//! // Logging utilities (requires 'logging' feature)
//! # #[cfg(feature = "logging")]
//! utils::logging::init_logger().unwrap();
//! ```

// Error handling
pub use crate::error::{ErrorContext, IdsError, Result};
pub use crate::{bail, ensure, try_with_context};

// Core data models
pub use crate::models::{Covariate, CovariateType, CovariateValue, TimeVaryingValue};

// Builder types
pub use crate::models::covariate::builders::{
    DemographicsBuilder, EducationBuilder, IncomeBuilder, OccupationBuilder,
};

// PNR and Family
pub use crate::models::family::FamilyRelations;
pub use crate::models::{FamilyInfo, ParentPair, PersonInfo, Pnr, PnrPool};

// Storage and backends
pub use crate::store::DataStore;
pub use crate::traits::access::Backend;

// Arrow integration (only when arrow-integration feature is enabled)
#[cfg(feature = "arrow-integration")]
pub use crate::storage::arrow::{ArrowAccess, ArrowBackend, ArrowValue};

// TimeVaryingBackend (only when serde-support feature is enabled)
pub use crate::store::TimeVaryingBackend;

// Traits
pub use crate::traits::{Cacheable, CovariateProcessor, DateHelpers, FamilyAccess, Store};

// Legacy traits have been removed in this version

// Utilities
pub use crate::utils::date::{format_date, parse_date, parse_year};
pub use crate::utils::string::{sanitize_identifier, truncate};

// Logging utilities (only when logging feature is enabled)
#[cfg(feature = "logging")]
pub use crate::{log_debug, log_error, log_info, log_warn};

// Common external types
pub use chrono::{Datelike, NaiveDate};
pub use hashbrown::HashMap;

/// Commonly used modules namespace.
///
/// This allows users to access specific modules directly through the prelude:
/// ```
/// use types::prelude::*;
/// use types::prelude::models::covariate::builders::EducationBuilder;
/// ```
pub mod modules {
    pub use crate::error;
    pub use crate::models;
    pub use crate::storage;
    pub use crate::traits;
    pub use crate::utils;
}
</file>

<file path="Cargo.toml">
[package]
name = "types"
version.workspace = true
edition.workspace = true
authors.workspace = true
description.workspace = true

[features]
default = ["arrow-integration", "serde-support", "logging"]
arrow-integration = ["arrow", "arrow-array", "arrow-schema", "arrow-select", "parquet"]
serde-support = ["serde", "serde_json"]
chrono-nightly = [] # Temporarily disabled due to workspace dependency conflicts
polars-integration = ["polars"]
logging = ["log"]
parallel-processing = ["num_cpus"]
parallel = ["parallel-processing"] # Alias for parallel-processing

[dependencies]
# Core dependencies (always included)
hashbrown.workspace = true
chrono.workspace = true
thiserror.workspace = true
anyhow.workspace = true
color-eyre = "0.6.2"
dashmap.workspace = true
rand.workspace = true
csv.workspace = true
lasso = { version = "0.7.2", features = ["multi-threaded"] }  # String interning support for performance

# Optional dependencies
arrow = { workspace = true, optional = true }
arrow-array = { workspace = true, optional = true }
arrow-schema = { workspace = true, optional = true }
arrow-select = { workspace = true, optional = true }
parquet = { workspace = true, optional = true }
serde = { workspace = true, optional = true }
serde_json = { workspace = true, optional = true }
log = { workspace = true, optional = true }
num_cpus = { version = "1.16.0", optional = true }
polars = { version = "0.28", optional = true }
parking_lot.workspace = true
ahash = { version = "0.8.11", features = ["serde", "runtime-rng"] }

[dev-dependencies]
criterion = "0.5"
</file>

</files>
